<!DOCTYPE html><html><div class="item-title">
        Item 86
      </div> <div class="item-details"><div><b>git_comments:</b> <ol></ol></div><div><b>git_commits:</b> <ol><li><div><div><b>summary:</b> SOLR-1674: speed up analysis tests (thanks Robert Muir!)
                </div><div><b>message:</b> SOLR-1674: speed up analysis tests (thanks Robert Muir!)

git-svn-id: https://svn.apache.org/repos/asf/lucene/solr/trunk@921427 13f79535-47bb-0310-9956-ffa450edef68

                </div></div></li></ol></div><div><b>github_issues:</b> <ol></ol></div><div><b>github_issues_comments:</b> <ol></ol></div><div><b>github_pulls:</b> <ol></ol></div><div><b>github_pulls_comments:</b> <ol></ol></div><div><b>github_pulls_reviews:</b> <ol></ol></div><div><b>jira_issues:</b> <ol><li><div><div><b>summary:</b> improve analysis tests, cut over to new API
                </div><div><b>description:</b> This patch
* converts all analysis tests to use the new tokenstream api
* converts most tests to use the more stringent assertion mechanisms from lucene
* adds new tests to improve coverage

Most bugs found by more stringent testing have been fixed, with the exception of SynonymFilter.
The problems with this filter are more serious, the previous tests were essentially a no-op.
The new tests for SynonymFilter test the current behavior, but have FIXMEs with what I think the old test wanted to expect in the comments.


                </div></div></li></ol></div><div><b>jira_issues_comments:</b> <ol><li><div><div><b>body:</b> here is an updated patch.
I think I managed to resolve some problems with synonymfilter, especially the recursion tests (I believe they were simply typos and there isnt a bug), and the position increments (this was a problem in the tests)

so in my opinion, the only problem left is SOLR-1670, the repeat problem.
                </div><div><b>label:</b> documentation
                </div></div></li><li><div>
                Hello, I see Uwe has commented on SOLR-1657 that he would help convert tokenstreams to the new api, but he needs this patch (the tests) applied first.

Is it possible for someone to take a look at this patch to get things moving along? its only tests, no source code changes.
              </div></li><li><div>
                I think TestCapitalizationFilter and TestMultiWordSynonyms need to be brought back up to trunk? A quick patch attempt is giving me problems. 
              </div></li><li><div>
                this is because you use $Id$. its not my fault... 
              </div></li><li><div>
                Thats BS - they are fixable in the patch ;)

I hate those damn $id tags - every time ... I'll fix them.
              </div></li><li><div>
                I sent an email... if no one cares about these $id$ tags then when i get back from vacation i will gladly volunteer to submit a patch to remove them :)

A quick workaround is to change them back to $Id$ in your local, then apply the patch...
              </div></li><li><div>
                Fixed a small issue with protWords.txt not matching prowrods.txt on unix systems.

If there are no objections I will commit this beautiful addition to our analysis tests soon.
              </div></li><li><div>
                All tests pass after renaming protWords.txt to protwords.txt. Unfortunately, this is too big to review in detail right now but I trust Robert to do the right thing :)

bq. If there are no objections I will commit this beautiful addition to our analysis tests soon.

+1
              </div></li><li><div>
                Thanks a lot Robert! Test contributions are rare and exciting!
              </div></li><li><div><div><b>body:</b> hmm it appears i may have slowed down the junit tests with the previous patch, unfortunately.

attached is a patch to speed them up... (maybe not necessary, but they were very very slow on my laptop)

                </div><div><b>label:</b> test
                </div></div></li><li><div>
                Hmmm, isn't it a bug that this passes?
    assertTokenizesTo(map, "a b", new String[] { "ab", "ab", "ab"  });

w/o the 1670 fix, we get "ab/ab/ab" (repeated tokens all at the same position).  That's not the same as three "ab" tokens in a row.

Also, we seem to have lost matching flexibility with overlapping tokens.  "a/aa" should be the same as "aa/a", but if you change the order of overlapping tokens now, the tests fail.

Didn't ya guys like my a/aa syntax to indicate overlapping tokens?  It certainly made it faster for me to write the original testcases :-)
              </div></li><li><div>
                Robert is on holiday I think - will reopen for now.
              </div></li><li><div>
                {quote}
Hmmm, isn't it a bug that this passes?

w/o the 1670 fix, we get "ab/ab/ab" (repeated tokens all at the same position). That's not the same as three "ab" tokens in a row. 
{quote}

The tests pass because it "ab", "ab", "ab". If we want to validate pos incs, we should change the test to:

{code}
assertTokenizesTo(map, "a b", 
  new String[] { "ab", "ab", "ab" },
  new int [] { 1, 0, 0 });
{code}

this way the posIncs are tested too.

{quote}
Also, we seem to have lost matching flexibility with overlapping tokens. "a/aa" should be the same as "aa/a", but if you change the order of overlapping tokens now, the tests fail.
{quote}

This "flexibility" caused things such as SOLR-1670, SOLR-1667, SOLR-1662, and SOLR-1660. When I switched to less "flexible" tests, these bugs were found. So sorry to see it go.

              </div></li><li><div>
                I've committed the speed up patch, thanks Robert!

Leaving open for posInc tests
              </div></li><li><div>
                
Correcting Fix Version based on CHANGES.txt, see this thread for more details...

http://mail-archives.apache.org/mod_mbox/lucene-dev/201005.mbox/%3Calpine.DEB.1.10.1005251052040.24672@radix.cryptio.net%3
              </div></li><li><div>
                Going to close this if no one objects...
              </div></li><li><div>
                i'd still like to add posinc tests for some of these tokenstreams,
but also other ones in the analyzers module too (e.g. ones from lucene contrib).

i'll set 3.2 for now.
              </div></li><li><div>
                Bulk move 4.4 issues to 4.5 and 5.0
              </div></li><li><div>
                Move issue to Solr 4.9.
              </div></li></ol></div></div></html>