<!DOCTYPE html><html><div class="item-title">
        Item 328
      </div> <div class="item-details"><div><b>git_comments:</b> <ol></ol></div><div><b>git_commits:</b> <ol><li><div><div><b>summary:</b> Revert "HAWQ-1458. The maximum value of guc share_input_scan_wait_lockfile_timeout should be greater than the default value."
                </div><div><b>message:</b> Revert "HAWQ-1458. The maximum value of guc share_input_scan_wait_lockfile_timeout should be greater than the default value."

This reverts commit 7df7f96f2c07b41a481d03833e0a1e6106c27e34.

                </div></div></li></ol></div><div><b>github_issues:</b> <ol></ol></div><div><b>github_issues_comments:</b> <ol></ol></div><div><b>github_pulls:</b> <ol></ol></div><div><b>github_pulls_comments:</b> <ol></ol></div><div><b>github_pulls_reviews:</b> <ol></ol></div><div><b>jira_issues:</b> <ol><li><div><div><b>summary:</b> Shared Input Scan QE hung in shareinput_reader_waitready().
                </div><div><b>description:</b> The stack is as below:
```
4/13/17 6:12:32 AM PDT: stack of postgres process (pid 108464) on test4:
4/13/17 6:12:32 AM PDT: Thread 2 (Thread 0x7f7ca0c7b700 (LWP 108465)):
4/13/17 6:12:32 AM PDT: #0  0x00000032214df283 in poll () from /lib64/libc.so.6
4/13/17 6:12:32 AM PDT: #1  0x000000000097e110 in rxThreadFunc ()
4/13/17 6:12:32 AM PDT: #2  0x0000003221807aa1 in start_thread () from /lib64/libpthread.so.0
4/13/17 6:12:32 AM PDT: #3  0x00000032214e8aad in clone () from /lib64/libc.so.6
4/13/17 6:12:32 AM PDT: Thread 1 (Thread 0x7f7cc5d48920 (LWP 108464)):
4/13/17 6:12:32 AM PDT: #0  0x00000032214e1523 in select () from /lib64/libc.so.6
4/13/17 6:12:32 AM PDT: #1  0x000000000069baaf in shareinput_reader_waitready ()
4/13/17 6:12:32 AM PDT: #2  0x000000000069be0d in ExecSliceDependencyShareInputScan ()
4/13/17 6:12:32 AM PDT: #3  0x000000000066eb40 in ExecSliceDependencyNode ()
4/13/17 6:12:32 AM PDT: #4  0x000000000066eaa5 in ExecSliceDependencyNode ()
4/13/17 6:12:32 AM PDT: #5  0x000000000066eaa5 in ExecSliceDependencyNode ()
4/13/17 6:12:32 AM PDT: #6  0x000000000066af41 in ExecutePlan ()
4/13/17 6:12:32 AM PDT: #7  0x000000000066bafa in ExecutorRun ()
4/13/17 6:12:32 AM PDT: #8  0x00000000007f52aa in PortalRun ()
4/13/17 6:12:32 AM PDT: #9  0x00000000007eb044 in exec_mpp_query ()
4/13/17 6:12:32 AM PDT: #10 0x00000000007effb4 in PostgresMain ()
4/13/17 6:12:32 AM PDT: #11 0x00000000007a04f0 in ServerLoop ()
4/13/17 6:12:32 AM PDT: #12 0x00000000007a32b9 in PostmasterMain ()
4/13/17 6:12:32 AM PDT: #13 0x00000000004a52b9 in main ()
```
                </div><div><b>label:</b> code-design
                </div></div></li><li><div><div><b>summary:</b> Shared Input Scan QE hung in shareinput_reader_waitready().
                </div><div><b>description:</b> The stack is as below:
```
4/13/17 6:12:32 AM PDT: stack of postgres process (pid 108464) on test4:
4/13/17 6:12:32 AM PDT: Thread 2 (Thread 0x7f7ca0c7b700 (LWP 108465)):
4/13/17 6:12:32 AM PDT: #0  0x00000032214df283 in poll () from /lib64/libc.so.6
4/13/17 6:12:32 AM PDT: #1  0x000000000097e110 in rxThreadFunc ()
4/13/17 6:12:32 AM PDT: #2  0x0000003221807aa1 in start_thread () from /lib64/libpthread.so.0
4/13/17 6:12:32 AM PDT: #3  0x00000032214e8aad in clone () from /lib64/libc.so.6
4/13/17 6:12:32 AM PDT: Thread 1 (Thread 0x7f7cc5d48920 (LWP 108464)):
4/13/17 6:12:32 AM PDT: #0  0x00000032214e1523 in select () from /lib64/libc.so.6
4/13/17 6:12:32 AM PDT: #1  0x000000000069baaf in shareinput_reader_waitready ()
4/13/17 6:12:32 AM PDT: #2  0x000000000069be0d in ExecSliceDependencyShareInputScan ()
4/13/17 6:12:32 AM PDT: #3  0x000000000066eb40 in ExecSliceDependencyNode ()
4/13/17 6:12:32 AM PDT: #4  0x000000000066eaa5 in ExecSliceDependencyNode ()
4/13/17 6:12:32 AM PDT: #5  0x000000000066eaa5 in ExecSliceDependencyNode ()
4/13/17 6:12:32 AM PDT: #6  0x000000000066af41 in ExecutePlan ()
4/13/17 6:12:32 AM PDT: #7  0x000000000066bafa in ExecutorRun ()
4/13/17 6:12:32 AM PDT: #8  0x00000000007f52aa in PortalRun ()
4/13/17 6:12:32 AM PDT: #9  0x00000000007eb044 in exec_mpp_query ()
4/13/17 6:12:32 AM PDT: #10 0x00000000007effb4 in PostgresMain ()
4/13/17 6:12:32 AM PDT: #11 0x00000000007a04f0 in ServerLoop ()
4/13/17 6:12:32 AM PDT: #12 0x00000000007a32b9 in PostmasterMain ()
4/13/17 6:12:32 AM PDT: #13 0x00000000004a52b9 in main ()
```
                </div></div></li><li><div><div><b>summary:</b> Shared Input Scan QE hung in shareinput_reader_waitready().
                </div><div><b>description:</b> The stack is as below:
```
4/13/17 6:12:32 AM PDT: stack of postgres process (pid 108464) on test4:
4/13/17 6:12:32 AM PDT: Thread 2 (Thread 0x7f7ca0c7b700 (LWP 108465)):
4/13/17 6:12:32 AM PDT: #0  0x00000032214df283 in poll () from /lib64/libc.so.6
4/13/17 6:12:32 AM PDT: #1  0x000000000097e110 in rxThreadFunc ()
4/13/17 6:12:32 AM PDT: #2  0x0000003221807aa1 in start_thread () from /lib64/libpthread.so.0
4/13/17 6:12:32 AM PDT: #3  0x00000032214e8aad in clone () from /lib64/libc.so.6
4/13/17 6:12:32 AM PDT: Thread 1 (Thread 0x7f7cc5d48920 (LWP 108464)):
4/13/17 6:12:32 AM PDT: #0  0x00000032214e1523 in select () from /lib64/libc.so.6
4/13/17 6:12:32 AM PDT: #1  0x000000000069baaf in shareinput_reader_waitready ()
4/13/17 6:12:32 AM PDT: #2  0x000000000069be0d in ExecSliceDependencyShareInputScan ()
4/13/17 6:12:32 AM PDT: #3  0x000000000066eb40 in ExecSliceDependencyNode ()
4/13/17 6:12:32 AM PDT: #4  0x000000000066eaa5 in ExecSliceDependencyNode ()
4/13/17 6:12:32 AM PDT: #5  0x000000000066eaa5 in ExecSliceDependencyNode ()
4/13/17 6:12:32 AM PDT: #6  0x000000000066af41 in ExecutePlan ()
4/13/17 6:12:32 AM PDT: #7  0x000000000066bafa in ExecutorRun ()
4/13/17 6:12:32 AM PDT: #8  0x00000000007f52aa in PortalRun ()
4/13/17 6:12:32 AM PDT: #9  0x00000000007eb044 in exec_mpp_query ()
4/13/17 6:12:32 AM PDT: #10 0x00000000007effb4 in PostgresMain ()
4/13/17 6:12:32 AM PDT: #11 0x00000000007a04f0 in ServerLoop ()
4/13/17 6:12:32 AM PDT: #12 0x00000000007a32b9 in PostmasterMain ()
4/13/17 6:12:32 AM PDT: #13 0x00000000004a52b9 in main ()
```
                </div></div></li><li><div><div><b>summary:</b> Shared Input Scan QE hung in shareinput_reader_waitready().
                </div><div><b>description:</b> The stack is as below:
```
4/13/17 6:12:32 AM PDT: stack of postgres process (pid 108464) on test4:
4/13/17 6:12:32 AM PDT: Thread 2 (Thread 0x7f7ca0c7b700 (LWP 108465)):
4/13/17 6:12:32 AM PDT: #0  0x00000032214df283 in poll () from /lib64/libc.so.6
4/13/17 6:12:32 AM PDT: #1  0x000000000097e110 in rxThreadFunc ()
4/13/17 6:12:32 AM PDT: #2  0x0000003221807aa1 in start_thread () from /lib64/libpthread.so.0
4/13/17 6:12:32 AM PDT: #3  0x00000032214e8aad in clone () from /lib64/libc.so.6
4/13/17 6:12:32 AM PDT: Thread 1 (Thread 0x7f7cc5d48920 (LWP 108464)):
4/13/17 6:12:32 AM PDT: #0  0x00000032214e1523 in select () from /lib64/libc.so.6
4/13/17 6:12:32 AM PDT: #1  0x000000000069baaf in shareinput_reader_waitready ()
4/13/17 6:12:32 AM PDT: #2  0x000000000069be0d in ExecSliceDependencyShareInputScan ()
4/13/17 6:12:32 AM PDT: #3  0x000000000066eb40 in ExecSliceDependencyNode ()
4/13/17 6:12:32 AM PDT: #4  0x000000000066eaa5 in ExecSliceDependencyNode ()
4/13/17 6:12:32 AM PDT: #5  0x000000000066eaa5 in ExecSliceDependencyNode ()
4/13/17 6:12:32 AM PDT: #6  0x000000000066af41 in ExecutePlan ()
4/13/17 6:12:32 AM PDT: #7  0x000000000066bafa in ExecutorRun ()
4/13/17 6:12:32 AM PDT: #8  0x00000000007f52aa in PortalRun ()
4/13/17 6:12:32 AM PDT: #9  0x00000000007eb044 in exec_mpp_query ()
4/13/17 6:12:32 AM PDT: #10 0x00000000007effb4 in PostgresMain ()
4/13/17 6:12:32 AM PDT: #11 0x00000000007a04f0 in ServerLoop ()
4/13/17 6:12:32 AM PDT: #12 0x00000000007a32b9 in PostmasterMain ()
4/13/17 6:12:32 AM PDT: #13 0x00000000004a52b9 in main ()
```
                </div></div></li><li><div><div><b>summary:</b> Shared Input Scan QE hung in shareinput_reader_waitready().
                </div><div><b>description:</b> The stack is as below:
```
4/13/17 6:12:32 AM PDT: stack of postgres process (pid 108464) on test4:
4/13/17 6:12:32 AM PDT: Thread 2 (Thread 0x7f7ca0c7b700 (LWP 108465)):
4/13/17 6:12:32 AM PDT: #0  0x00000032214df283 in poll () from /lib64/libc.so.6
4/13/17 6:12:32 AM PDT: #1  0x000000000097e110 in rxThreadFunc ()
4/13/17 6:12:32 AM PDT: #2  0x0000003221807aa1 in start_thread () from /lib64/libpthread.so.0
4/13/17 6:12:32 AM PDT: #3  0x00000032214e8aad in clone () from /lib64/libc.so.6
4/13/17 6:12:32 AM PDT: Thread 1 (Thread 0x7f7cc5d48920 (LWP 108464)):
4/13/17 6:12:32 AM PDT: #0  0x00000032214e1523 in select () from /lib64/libc.so.6
4/13/17 6:12:32 AM PDT: #1  0x000000000069baaf in shareinput_reader_waitready ()
4/13/17 6:12:32 AM PDT: #2  0x000000000069be0d in ExecSliceDependencyShareInputScan ()
4/13/17 6:12:32 AM PDT: #3  0x000000000066eb40 in ExecSliceDependencyNode ()
4/13/17 6:12:32 AM PDT: #4  0x000000000066eaa5 in ExecSliceDependencyNode ()
4/13/17 6:12:32 AM PDT: #5  0x000000000066eaa5 in ExecSliceDependencyNode ()
4/13/17 6:12:32 AM PDT: #6  0x000000000066af41 in ExecutePlan ()
4/13/17 6:12:32 AM PDT: #7  0x000000000066bafa in ExecutorRun ()
4/13/17 6:12:32 AM PDT: #8  0x00000000007f52aa in PortalRun ()
4/13/17 6:12:32 AM PDT: #9  0x00000000007eb044 in exec_mpp_query ()
4/13/17 6:12:32 AM PDT: #10 0x00000000007effb4 in PostgresMain ()
4/13/17 6:12:32 AM PDT: #11 0x00000000007a04f0 in ServerLoop ()
4/13/17 6:12:32 AM PDT: #12 0x00000000007a32b9 in PostmasterMain ()
4/13/17 6:12:32 AM PDT: #13 0x00000000004a52b9 in main ()
```
                </div></div></li></ol></div><div><b>jira_issues_comments:</b> <ol><li><div><div><b>body:</b> I'd suggest providing more details. Just a stack seems to be too simple for a lot of people do not have the background of this issue.
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                [~abai] Do you have steps to reproduce this issue?
              </div></li><li><div>
                More descriptions about this issue:
When run a shared input scan query, QE may hung in function of shareinput_reader_waitready() sometimes.
The main logic of shared input scan code is that :
{code}
 For readiness, the shared node will write xslice of 'a' into the pipe.
 For each share, there is just one ready writer.  Once sharer starts write
 it need to write all xslice copies of 'a'.

 For sharer, it need to check for ready to read (using select), because read
 is blocking.  Once sharer got 'a', it write 'b' back to shared.

 For done, the shared is the only reader. Each sharer will writer 'z' back to shared.
Shared (using select) to check the total number of 'z' is same as the number of sharer. 
{code}

The root cause of the issue is that when the sharer(reader) is waiting for the shared(writer) to write ‘a’ to pipe
while the shared(writer) process has quit, so the sharer will block forever.

The reproduction steps are:
{code}
Step 1: Prepare schema and data using attached olap_setup.sql

Step 2: 'set gp_cte_sharing = true;'

Step 3: Run below OLAP grouping query
-- OLAP query involving MAX() function
SELECT sale.vn,sale.cn,sale.dt,GROUPING(sale.vn), TO_CHAR(COALESCE(MAX(DISTINCT floor(sale.vn+sale.qty)),0),'99999999.9999999'),TO_CHAR(COALESCE(VAR_SAMP(floor(sale.pn/sale.prc)),0),'99999999.9999999'),TO_CHAR(COALESCE(COUNT(floor(sale.qty+sale.prc)),0),'99999999.9999999')
FROM sale,customer,vendor
WHERE sale.cn=customer.cn AND sale.vn=vendor.vn
GROUP BY ROLLUP((sale.prc),(sale.vn,sale.vn),(sale.pn,sale.pn),(sale.dt),(sale.qty,sale.vn,sale.qty)),ROLLUP((sale.pn),(sale.vn,sale.pn),(sale.qty)),(),sale.cn HAVING COALESCE(VAR_POP(sale.cn),0) &gt;= 45.5839785564113;
{code}

Notes: It's a random issue, not occur each time.


              </div></li></ol></div></div></html>