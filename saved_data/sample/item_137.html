<!DOCTYPE html><html><div class="item-title">
        Item 137
      </div> <div class="item-details"><div><b>git_comments:</b> <ol></ol></div><div><b>git_commits:</b> <ol><li><div><div><b>summary:</b> Revert "HADOOP-15996.  Improved Kerberos username mapping strategy in Hadoop."
                </div><div><b>message:</b> Revert "HADOOP-15996.  Improved Kerberos username mapping strategy in Hadoop."

This reverts commit af589262c885367e36bb4d3a6236b239d855c9e1.

                </div></div></li></ol></div><div><b>github_issues:</b> <ol></ol></div><div><b>github_issues_comments:</b> <ol></ol></div><div><b>github_pulls:</b> <ol></ol></div><div><b>github_pulls_comments:</b> <ol></ol></div><div><b>github_pulls_reviews:</b> <ol></ol></div><div><b>jira_issues:</b> <ol><li><div><div><b>summary:</b> Plugin interface to support more complex usernames in Hadoop
                </div><div><b>description:</b> Hadoop does not allow support of @ character in username in recent security mailing list vote to revert HADOOP-12751.&nbsp; Hadoop auth_to_local rule must match to authorize user to login to Hadoop cluster.&nbsp; This design does not work well in multi-realm environment where identical username between two realms&nbsp;do not map to the same user.&nbsp; There is also possibility that lossy regex can incorrectly map users.&nbsp; In the interest of supporting multi-realms, it maybe preferred to pass principal name without rewrite to uniquely&nbsp;distinguish users.&nbsp; This&nbsp;jira is to revisit if Hadoop can support full principal names without rewrite and&nbsp;provide a plugin to&nbsp;override Hadoop's default implementation of auth_to_local for multi-realm use case.
                </div></div></li></ol></div><div><b>jira_issues_comments:</b> <ol><li><div><div><b>body:</b> I think there are 3 types of plugin to be created.
 # "system" -&gt; using the native Kerberos Java interface to determine auth_to_local rules specified in krb5.conf and apply these according to MIT/Heimdal documentation. Use this in case Java 8 is available
 # "compatible" -&gt; Follows MIT/Heimdal evaluation, but rules are specified in Hadoop configuration. This is for Java 7 support, see below.
 # "old_hadoop" (or "hadoop", "legacy") use the current implementation

(aside from maybe "custom" if we ant to support that).

For "system" most of the ground work is already in place, but there are a few things to consider.
 * Hadoop already uses the native Kerberos interface in KerberosUtil, it only needs a extension (new method) to support accessing the right information
 * While Kerberos 5 MIT/Heimdal both support multiple default realms (default_realm can actually list multiple realms) Hadoop and Java 7 don't
 * Java 7 picks up the first auth_to_local specification and returns it as a String separated by " ". There is no way to determine if this actually the auth_to_local belonging to the realm we want to evaluate for without changing a field&nbsp;from private to public (in Java 8 it is possible without resorting to this).&nbsp;
 * We cannot 'copy'&nbsp;the Java 8 version as it is under GPL
 * Some parsing needs to be done in order to split the rules properly when returned from Java 7

Ie. if we don't want to resort to declaring a private field public we cannot guarantee security in Java 7 and it will be hard anyway. Therefore, I think we should have "system" only available to java 8 users, thus Hadoop &gt;= 3.

This can be managed without additional dependencies as all required are part of the JDK.

&nbsp;

&nbsp;

&nbsp;
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                Java 7 is EOL in April 2015.  I am not sure new development make sense for Hadoop 2.x to support this feature.  I would drop "compatible" from the list, and drop Hadoop 2.x support from this JIRA.

The plugin design needs to have ability to daisy chain plugins.  A possible lookup order would be:

# verify kerberos tgt
# check account identity remapping
# check ACL lists (proxyuser or service acl)

Plugin must protect all network entrances that lead to UserGroupInformation logic.  The plugin may be activated by AuthenticationFilter or rpc entry points.
              </div></li><li><div>
                Ah ok. HADOOP-12751 was available on 2.x , so this is why I suggested 'compatible'.&nbsp;

What do you think the scope of the plugin interface needs to be? Your point #1 seems broader than I anticipated.

We could also consider a 'native' plugin available when hadoop-native is installed that uses the C-api. JAVA's kerberos interface deviates from MIT/Heimdal in some areas. It would also offload complexities of properly dealing with auth_to_local rules.
              </div></li><li><div>
                AuthenticationHandler interface has "authenticate" method, which does the work for resolving client principal name from HTTP request Authentication header using JDK gssapi libraries in KerberosAuthenticationHandler.  #1 is met without code change.  I was looking for the sequence of the flow to ensure correct ordering.
Part two is to call into system "auth_to_local" or Hadoop "auth_to_local" as part of "runWithPrincipal" method to resolve KerberosName.  We can add a configuration parameter to decide which KerberosName implementation to use or encapsulate the logic in KerberosName class?
Part three is also added to "runWithPrincipal" method to reject disallowed KerberosName early.


              </div></li><li><div><div><b>body:</b> Gotcha.

I think it makes sense to make the configuration in&nbsp;KerberosAuthenticationHandler. Can we be sure KerberosName is not used directly? (I did a quick scan of Hive it uses UGI so I assume it doesn't use it directly then? I wasn't thorough though). Zookeeper has its own pre HADOOP-12751 implementation.

The reasons why HADOOP-12751 was not configurable in the first place was due to the fact KerberosName does not have any awareness of configuration.

&nbsp;
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                I have added a rudimentary patch that supports using krb5.conf. Its quite simple. This raises the question do we really want to go "full plugin" (i.e. load an arbitrary class) or do we want to support multiple implementations in the current KerberosName?
              </div></li><li><div>
                It is nice to encapsulate the logic in KerberosName to reduce incompatibility.  Can we implement a callback class in getShortName() method to fork the necessary implementations.  The default implementation guard against NoMatchingRule, and the multi-realm implementation load and apply rules in krb5.conf.  The plugin class can be activated by hadoop.security.kerberos.name.policy.class Configuration.  If multiple classes are specified, the callback must evaluate in the listed order.  This arrangement allows to write ACL check plugin to work with multi-realm implementation.  Thoughts?
              </div></li><li><div><div><b>body:</b> Personally, I am not convinced of using a real plugin style system. That’s a kind of complexity and possible ambiguity that I wouldn’t want in core/security. If ACLs are the target I would make that non-ambiguous and call it “hadoop.security.usernames_acl” or something like that. I suggest staying away from making 'auth_to_local' more complex than it already is.

Is there really a use case to make the plugins stackable?

The patch I just added makes the bahavior configurable without being too invasive (imho). It could easily be extended to "system", which then has all three use cases I listed earlier. Do we envision more?
                </div><div><b>label:</b> code-design
                </div></div></li><li><div><div><b>body:</b> [~bolke] - I can certainly see this being a reasonable outcome of discussion on this JIRA. I also can see a benefit to have distinct plugins or profiles here where the semantics can be clearly articulated and documented and maintained.

Continuing the existing pattern of more config knobs to tweak in different combinations that can end up with unexpected results may be something we want to avoid.

If there is any desire to continue discussion and brainstorming around a plugin mechanism here then the current patch should probably be broken out as a separate JIRA as&nbsp;a new and possibly future config based approach.

This then allows us to refactor&nbsp;the new code from that patch&nbsp;into plugins if that is the direction we want&nbsp;and doesn't lose track of this JIRA discussion.

I will start reviewing your patch here to make sure that it is a simple config setting to switch between semantics and that it is legacy by default. We can move discussion of the patch into a separate JIRA as needed.

Let's make sure that the differences between the two settings are fully described - so that admins know exactly what they are setting. From there we can determine what to put in docs and in READMEs.
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                [~bolke] {quote}Is there really a use case to make the plugins stackable?{quote}

Ranger might be interested to implement a control plugin fend off unauthorized kerberos principal based on ACL in Ranger.  I also agree that fixed number permutation is more secure.  Perhaps we can make sure that loadable plugin is only coming from hadoop common package name to ensure the plugin implementation is controlled by Hadoop community?

              </div></li><li><div>
                | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 13s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 4 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 19s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 18m 47s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 37s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m  1s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 51s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 44s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 21s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 34s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  9s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  4s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m  9s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 14m  9s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 47s{color} | {color:orange} hadoop-common-project: The patch generated 7 new + 241 unchanged - 0 fixed = 248 total (was 241) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 43s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 17s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 38s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 36s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 56s{color} | {color:green} hadoop-auth in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m  1s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 45s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 99m 51s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.util.TestDiskCheckerWithDiskIo |
|   | hadoop.util.TestReadWriteDiskValidator |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:8f97d6f |
| JIRA Issue | HADOOP-15996 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12952401/0001-HADOOP-15996-Make-auth-to-local-configurable.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux 5ef5f4caac75 4.4.0-138-generic #164-Ubuntu SMP Tue Oct 2 17:16:02 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / e815fd9 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_181 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/15677/artifact/out/diff-checkstyle-hadoop-common-project.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/15677/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/15677/testReport/ |
| Max. process+thread count | 1676 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common U: hadoop-common-project |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/15677/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.


              </div></li><li><div>
                The failed test doesn't seem like related to 001 patch.  The feature works same as HADOOP-12751.  I will let others comment if ACL check needs to be applied as part of this JIRA to block unauthorized kerberos principals.
              </div></li><li><div>
                [~bolke] Something is missing in the patch.  setRuleMechanism doesn't seem to be initialized correctly by Hadoop daemons.  When I set core-site.xml to include config:

{code}
    &lt;property&gt;
      &lt;name&gt;hadoop.security.auth_to_local.mechanism&lt;/name&gt;
      &lt;value&gt;compat&lt;/value&gt;
    &lt;/property&gt;
{code}

I still get failures with no matching rule error:
{code}
Server Error&lt;/pre&gt;&lt;/p&gt;&lt;h3&gt;Caused by:&lt;/h3&gt;&lt;pre&gt;org.apache.hadoop.security.authentication.util.KerberosName$NoMatchingRule: No rules applied to lol@EXAMPLE.COM
	at org.apache.hadoop.security.authentication.util.KerberosName.getShortName(KerberosName.java:419)
	at org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.runWithPrincipal(KerberosAuthenticationHandler.java:350)
	at org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.access$000(KerberosAuthenticationHandler.java:64)
	at org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler$2.run(KerberosAuthenticationHandler.java:302)
	at org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler$2.run(KerberosAuthenticationHandler.java:299)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.authenticate(KerberosAuthenticationHandler.java:298)
	at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:536)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.apache.hadoop.security.http.CrossOriginFilter.doFilter(CrossOriginFilter.java:98)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1613)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.eclipse.jetty.server.Server.handle(Server.java:539)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:748)
{code}
              </div></li><li><div>
                I double check. Do you know where to look? I thought I put it at the right place place, but maybe I missed where the properties are read. Can fix tomorrow. 
              </div></li><li><div>
                [~bolke] KerberosAuthenticationHandler is initialized using RULE_MECHANISM, which is "kerberos.evaluation".  AuthenticationFilter initialization chain does not explicitly set config properties that maps hadoop.security.auth_to_local.mechanism to kerberos.evaluation.  Therefore, it is always default to LEGACY in Hadoop daemons.
              </div></li><li><div><div><b>body:</b> [~eyang] I'm having some trouble understanding how that mapping happens. I'm following the same pattern as 'NAME_RULES' and that doesn't have an explicit mapping. At least not one that I can find.

[~lmccay] -Let me know where I can add documentation and I am happy to do so.- Found it, and will be amended in the next version of the patch.

&nbsp;
                </div><div><b>label:</b> documentation
                </div></div></li><li><div><div><b>body:</b> 0002 patch version cleans up the code a little bit and adds / fixes documentation

&nbsp;

[~eyang] I'm still a bit puzzled why it is not picked up in your config. Tests do cover the 'mapping' (see TestUsergroupInformation). Did you recompile hadoop-common as well? Setting the mapping happens in HadoopKerberosName as happens with NAME_RULES.

&nbsp;

[~lmccay] Documentation corrected and updated. PTAL.
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 15s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 4 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 20m 38s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 52s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m  1s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 47s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m 16s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 18s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 25s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 10s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  9s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m  7s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 14m  7s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  1m  2s{color} | {color:orange} hadoop-common-project: The patch generated 7 new + 241 unchanged - 0 fixed = 248 total (was 241) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 41s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 6 line(s) that end in whitespace. Use git apply --whitespace=fix &lt;&lt;patch_file&gt;&gt;. Refer https://git-scm.com/docs/git-apply {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m  9s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 35s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 26s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 50s{color} | {color:green} hadoop-auth in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 44s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 38s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}103m 29s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:8f97d6f |
| JIRA Issue | HADOOP-15996 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12952710/0002-HADOOP-15996-Make-auth-to-local-configurable.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux a1a6217af632 4.4.0-134-generic #160~14.04.1-Ubuntu SMP Fri Aug 17 11:07:07 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / f659485 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_181 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/15686/artifact/out/diff-checkstyle-hadoop-common-project.txt |
| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/15686/artifact/out/whitespace-eol.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/15686/testReport/ |
| Max. process+thread count | 1474 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common U: hadoop-common-project |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/15686/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.


              </div></li><li><div>
                [~bolke] UserGroupInformation class initialization can happen later than KerberosAuthenticationHandler getting called to authenticate a remote client because jetty startup and web application context initialization may result in several web containers, each holds its own copy of UserGroupInformation class.   Some of which KerberosAuthenticationHandler is called without UserGroupInformation initialization.

It might be possible to ensure the rule mechanism is setup in HttpServer2 initSpnego method for each of the web application context to receive the same KerberosName setting.
              </div></li><li><div><div><b>body:</b> [~eyang]&nbsp;Ok thanks for that I will have a look. I'm still a bit confused why a NAME_RULE&nbsp;reference cannot be found then, cause I assume you want to have a proper conversion also at early initialization. I followed the same pattern.&nbsp;

I can see if we want to set the mechanism earlier and rules will be set later, but I did think I caught all those.
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                [~eyang] So I did investigate the initSpnego approach and some backtracking in the code. From what I can see is that 'AUTH_TO_LOCAL' rules are only initialized when UserGroupInformation.setConfiguration is called. In the name node initialization the following happens in 'initalize':

&nbsp;
{code:java}
UserGroupInformation.setConfiguration(conf);
server.initSpnego(conf, hostName, usernameConfKey, keytabConfKey);
&nbsp;
{code}
In case you find an orphan (couldn't find it yet) `initSpnego` (i.e. without UserGroupInformation) `auth_to_local` rules will also not be set (=null). As the rule mechanism only kicks in when rules are evaluated and the mechanism does get set when the rules are being set I have trouble understanding your stack trace.

What I will do is attach a patch that does the mapping from ` hadoop.security.auth_to_local.mechanism` as a try out, but I really like to understand why that would solve the whole issue.
              </div></li><li><div>
                new patch
              </div></li><li><div>
                adds initialization of the mechanism in
{code:java}
initSpnego{code}
to ensure it it is initialized for all servers. We should carefully check if this has the desired effect and no side effects.
              </div></li><li><div>
                [~bolke] The latest patch works for YARN REST API, but it fails on hdfs api and hdfs ipc calls.  It looks like when UserGroupinformation instance is constructed via doAs or reflection, then rule mechanism is not set.  Here are some stack trace that shows the calling stack using 0003 patch:

Running: hdfs dfs -ls /
{code}
2018-12-22 19:16:39,598 WARN ipc.Client: Couldn't setup connection for lol@EXAMPLE.COM to eyang-1.example.com/172.01.111.17:9000
java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1817)
	at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:361)
	at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:617)
	at org.apache.hadoop.ipc.Client$Connection.access$2300(Client.java:411)
	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:804)
	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:800)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1876)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:800)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:903)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy10.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1665)
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1582)
	at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1579)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1594)
	at org.apache.hadoop.fs.Globber.getFileStatus(Globber.java:65)
	at org.apache.hadoop.fs.Globber.doGlob(Globber.java:294)
	at org.apache.hadoop.fs.Globber.glob(Globber.java:149)
	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:2015)
	at org.apache.hadoop.fs.shell.PathData.expandAsGlob(PathData.java:353)
	at org.apache.hadoop.fs.shell.Command.expandArgument(Command.java:250)
	at org.apache.hadoop.fs.shell.Command.expandArguments(Command.java:233)
	at org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:104)
	at org.apache.hadoop.fs.shell.Command.run(Command.java:177)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:327)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)
	at org.apache.hadoop.fs.FsShell.main(FsShell.java:390)
ls: DestHost:destPort eyang-1.openstacklocal:9000 , LocalHost:localPort eyang-1.openstacklocal/172.26.111.17:0. Failed on local exception: java.io.IOException: Couldn't setup connection for lol@EXAMPLE.COM to eyang-1.openstacklocal/172.01.111.17:9000
{code}

Running: curl --negotiate -u : http://eyang-1.example.com:50070/webhdfs/v1/
{code}
org.apache.hadoop.security.authentication.util.KerberosName$NoMatchingRule: No rules applied to lol@EXAMPLE.COM
	at org.apache.hadoop.security.authentication.util.KerberosName.getShortName(KerberosName.java:419)
	at org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.runWithPrincipal(KerberosAuthenticationHandler.java:350)
	at org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.access$000(KerberosAuthenticationHandler.java:64)
	at org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler$2.run(KerberosAuthenticationHandler.java:302)
	at org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler$2.run(KerberosAuthenticationHandler.java:299)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.authenticate(KerberosAuthenticationHandler.java:298)
	at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:536)
	at org.apache.hadoop.hdfs.web.AuthFilter.doFilter(AuthFilter.java:90)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.apache.hadoop.security.http.CrossOriginFilter.doFilter(CrossOriginFilter.java:98)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1614)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.eclipse.jetty.server.Server.handle(Server.java:539)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:748)
{code}

It looks like the problem might be difficult to solve by trying to cover all initialization entrance.  There could be user code base that we can not cover the initialization.  Maybe there is a way to make sure KerberosName retrieve rule mechanism from UserGroupInformation's copy of conf object to ensure the initialization did happen without side step UserGroupInformation configuration?
              </div></li><li><div>
                [~eyang] thanks for the stack trace. I'm trying to setup my own full testing env, but currently being on a low bandwidth connection makes this a bit challenge.

Still this remains suspicious: KerberosName (and HadoopKerberosName) start out with "null" rules. Obviously, in your &nbsp;environment these get set somewhere. This either happens by UserGroupInformation.setConfiguration, HadoopKerberosName.setConfiguration or (Hadoop)KerberosName.setRules . There is no other way as there is no explicit mapping from "hadoop.security.auth_to_local" to "kerberos.name.rules" otherwise.

I'll look into your suggestion in the meantime.

&nbsp;
              </div></li><li><div><div><b>body:</b> [~eyang] I think I fixed the issue, fortunately simpler than your suggestion by adding a check for setting to null (and refusing to do so) equal to setRules in KerberosAuthenticationHandler. I saw orphan calls (no setRules combination) to setRuleMechanism with LEGACY while it was set to compat.

Please note also that I have made the "setRuleMechanism" more strict. If getShortName is called and the mechanism has not been set it will throw&nbsp;an exception. It guards against not being initialized, but the default setting now only exists in HadoopKerberosName. Is that sufficient?

I removed the initSpnego addition as well as I think this will fix it.

I tested HDFS busy with yarn.
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 12s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 4 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 20s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 20m 49s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m  8s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m  1s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 48s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m  5s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 15s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 25s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 10s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 10s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 11s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 14m 11s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  1m  1s{color} | {color:orange} hadoop-common-project: The patch generated 6 new + 269 unchanged - 0 fixed = 275 total (was 269) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 43s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 14s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 39s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 25s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  2m 57s{color} | {color:red} hadoop-auth in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 14s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 41s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}103m 41s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.security.authentication.client.TestKerberosAuthenticator |
|   | hadoop.security.authentication.util.TestKerberosName |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:8f97d6f |
| JIRA Issue | HADOOP-15996 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12952987/0001-Make-allowing-or-configurable.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux af34a7ecb914 4.4.0-134-generic #160~14.04.1-Ubuntu SMP Fri Aug 17 11:07:07 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 686fcd4 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_181 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/15689/artifact/out/diff-checkstyle-hadoop-common-project.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/15689/artifact/out/patch-unit-hadoop-common-project_hadoop-auth.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/15689/testReport/ |
| Max. process+thread count | 1509 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common U: hadoop-common-project |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/15689/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.


              </div></li><li><div><div><b>body:</b> Latest patch:
 * Logs warning when mechanism has not been set and defaults to 'legacy' in that case for backwards compatibility (no exception anymore)
 * Extra test to guard against setting "null" values for rules and mechanism
 * KerberosName.apply now takes two arguments principal and mechanism
 * updated some tests to set mechanism appropriately

&nbsp;
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                [~bolke] Thank you for the patch 0005 seems to work correctly with toggle flag to switch between the two modes.  It would be good to name the patch filename as defined in the [contribution guideline|https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute#HowToContribute-Namingyourpatch].  This will ensure the pre-commit test is testing the latest patch correctly.

I don't have a problem with the current approach instead of security mailing list suggested plugin interface.  However, I will let others comment if additional refinement is required before we commit.  Thank you

              </div></li><li><div>
                [~eyang] Thanks. Done.

[~lmccay] [~stevel@apache.org] comments?
              </div></li><li><div>
                | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 12s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 5 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 22s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 20m 43s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 56s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m  1s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 47s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m 11s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 25s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 23s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 10s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 14s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 16m  1s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 16m  1s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  1m  0s{color} | {color:orange} hadoop-common-project: The patch generated 6 new + 277 unchanged - 0 fixed = 283 total (was 277) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 48s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 1 line(s) that end in whitespace. Use git apply --whitespace=fix &lt;&lt;patch_file&gt;&gt;. Refer https://git-scm.com/docs/git-apply {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 15s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 36s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 28s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 57s{color} | {color:green} hadoop-auth in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m 23s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 40s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}106m 45s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:8f97d6f |
| JIRA Issue | HADOOP-15996 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12953165/0005-HADOOP-15996-Make-auth-to-local-configurable.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux 031c0d54a4b4 4.4.0-134-generic #160~14.04.1-Ubuntu SMP Fri Aug 17 11:07:07 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / d8f670f |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_181 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/15697/artifact/out/diff-checkstyle-hadoop-common-project.txt |
| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/15697/artifact/out/whitespace-eol.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/15697/testReport/ |
| Max. process+thread count | 1381 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common U: hadoop-common-project |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/15697/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.


              </div></li><li><div>
                I am out my depth here so don't expect approval from me. Ed Yang has taken the lead.

* Why "compat" as the name? (a) we don't need something quite so terse and (b) assuming its short for "compatible", I'm left looking at it wondering "how is this different from "legacy"? If it's about MIT, how about "mit"/"MIT"?
* If someone is running a cluster and hasn't set a policy, is every single one of their apps going to be adding a log message telling them off? And how many times per app? This may seem minor, but every time something which is not actually a problem gets turned into a log@warn, somebody sees it and worries.


test: what happens a wrong value is set as the rule mechanism?

TestUserGroupInformation

* keep with the static imports of specific fields, given someone has started that way
* \{{testConstructorFailures}}. If the exception doesn't match, rethrow the full exception, possibly as the cause of a raised assertion. Preserves the stack trace.
              </div></li><li><div><div><b>body:</b> [~stevel@apache.org]

The issue is that Hadoop is in compatible mode&nbsp;not even entirely MIT. In MIT (and also Heimdal) you cannot match an arbitrary realm and you need to configure them explicitly. This way you cannot end up transforming users from FOO to local user names just because you had a rule nullifying&nbsp;*any* realm. Obviously it guards against user mistakes and is more secure. This is how it works in MIT. (I need to double check this, as MITs documentation is ambiguous here, Heimdal is pretty explicit about it).
{code:java}
 EXAMPLE.COM = {
   kdc = localhost:_KDC_PORT_
   auth_to_local = {
     RULE:[2:$1](johndoe)s/^.*$/guest/
     RULE:[2:$1;$2](^.*;admin$)s/;admin$//
     RULE:[2:$2](root)
     DEFAULT
   }
}

YAHOO.COM = {
 auth_to_local = {
   RULE:[1:$1@$0](.*@YAHOO\\.COM)s/@.*// 
 }
}  {code}
In Hadoop you can mix those.&nbsp;
{code:java}
auth_to_local = RULE:[2:$1](johndoe)s/^.*$/guest/
 RULE:[2:$1;$2](^.*;admin$)s/;admin$//
 RULE:[1:$1@$0](.*@YAHOO\\.COM)s/@.*// 
 RULE:[2:$2](root)
 DEFAULT{code}
Hence why it is called compatible. I'm working on a "system" version that takes krb5.conf and does fully adhere to MIT rules.

I'm fine with using "compatible".

*Verbosity*

I'm a bit in doubt here. Obviously it can log quite often on the other hand forcing the user to make an explicit choice is probably good here. Also, the 'legacy' version is logging an *error*&nbsp;on every non simple name (equal&nbsp;to the current state after the revert). What do&nbsp;you suggest?

*Check on incorrect setting*

Good point, I'll add some validation.

&nbsp;
                </div><div><b>label:</b> documentation
                </div></div></li><li><div><div><b>body:</b> I don't understand the explanation of the compatibility name as it seems that you are saying it isn't really compatible with anything. :)

I did have the same question when I was initially looking at the patch but have kept quiet as I was waiting for a patch that worked.

The code still has comments indicating that it is following MIT rules. COMPAT doesn't mean anything. Again, we need to make sure that we&nbsp;clearly articulate what the "legacy" and "compat" behavior&nbsp;differences are. Otherwise, folks won't know why to choose one over the other.

I actually don't like that there are warnings about the default being chosen. The default behavior should be what it always was and only be overridden by an&nbsp;admin explicitly choosing the other.

So, I would say the following should be addressed:
 # Names: "Legacy" implies that it has been replaced by something new. This isn't the case, there is another option to choose and a default. DEFAULT would make sense. "Compat" doesn't mean anything since it isn't fully compatible with any particular thing and really cannot be documented in a way that makes that name meanful. My understanding is that this is an option that was added to accommodate multi-tenancy better. If MIT or MIT-VARIANT doesn't work then make it a name related to its need - MULTI_TENANT or something like that. I lean towards that since it is more easily documented than how it is compatible but not exactly compatible with MIT rules.
 # The following should be changed to not be null by default but DEFAULT and remove all the checks and warnings for it being null.{code}

+ /**

+ * How to evaluate auth_to_local rules + */

+ private static String ruleMechanism = null;

{code}

 # There appear to be checkstyle and whitespace violations added by the patch

&nbsp;
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 22s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 5 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 22s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 21m 56s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 16m 19s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m  2s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 52s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m  1s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 25s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 24s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 10s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 12s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 58s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 15m 58s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  1m  0s{color} | {color:orange} hadoop-common-project: The patch generated 6 new + 277 unchanged - 0 fixed = 283 total (was 277) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 43s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 1 line(s) that end in whitespace. Use git apply --whitespace=fix &lt;&lt;patch_file&gt;&gt;. Refer https://git-scm.com/docs/git-apply {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m  8s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 30s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 26s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 20s{color} | {color:green} hadoop-auth in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 16s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 39s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}108m 14s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.security.ssl.TestSSLFactory |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:8f97d6f |
| JIRA Issue | HADOOP-15996 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12953171/HADOOP-15996.0005.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux ad3e693a6c3f 4.4.0-138-generic #164~14.04.1-Ubuntu SMP Fri Oct 5 08:56:16 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / d8f670f |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_191 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/15700/artifact/out/diff-checkstyle-hadoop-common-project.txt |
| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/15700/artifact/out/whitespace-eol.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/15700/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/15700/testReport/ |
| Max. process+thread count | 1467 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common U: hadoop-common-project |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/15700/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.


              </div></li><li><div>
                | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 11s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 5 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 10s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 21m  2s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 52s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m  2s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 45s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m 15s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 14s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 24s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 10s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 11s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 15s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 14m 15s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  1m  0s{color} | {color:orange} hadoop-common-project: The patch generated 6 new + 277 unchanged - 0 fixed = 283 total (was 277) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 45s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 1 line(s) that end in whitespace. Use git apply --whitespace=fix &lt;&lt;patch_file&gt;&gt;. Refer https://git-scm.com/docs/git-apply {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 58s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 43s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 25s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m  0s{color} | {color:green} hadoop-auth in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 38s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 38s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}103m 50s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:8f97d6f |
| JIRA Issue | HADOOP-15996 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12953172/HADOOP-15996.0006.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux 55f54fa69edf 4.4.0-134-generic #160~14.04.1-Ubuntu SMP Fri Aug 17 11:07:07 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / d8f670f |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_181 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/15701/artifact/out/diff-checkstyle-hadoop-common-project.txt |
| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/15701/artifact/out/whitespace-eol.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/15701/testReport/ |
| Max. process+thread count | 1483 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common U: hadoop-common-project |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/15701/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.


              </div></li><li><div><div><b>body:</b> [~stevel@apache.org] {quote}If someone is running a cluster and hasn't set a policy, is every single one of their apps going to be adding a log message telling them off? And how many times per app?{quote}

The warning message should not happen unless the user application has somehow created the KerberosName object without core-default.xml in the classpath.  It's guarding against code running in custom environment that may not have Hadoop configuration object initialized in the expected order.  This should not happen in Hadoop itself, but it could be possible if third party application does things differently than Hadoop.

[~lmccay] {quote}I don't understand the explanation of the compatibility name as it seems that you are saying it isn't really compatible with anything.{quote}

Compatible mode is referring to how auth_to_local rule works that is compatible with MIT kerberos as a utility function.  Legacy mode represents Hadoop original implementation using auth_to_local as firewall rules.  The naming only make sense to people that can distinguish the semantic difference between legacy Hadoop Kerberos auth_to_local and MIT Kerberos auth_to_local definitions.  This is not multi-realm specific, and calling it multi-realm specific flag may create more confusion from the intend of using auth_to_local as firewall rules or not.  

"system" mode is also proposed to use auth_to_local rules directly from krb5.conf.  Rule mechanism types are important to show the clarity of the modes.  Maybe we can call it, "passive" = compat, "enforce" = legacy, "os" = system to make this easier to discern the different types?
                </div><div><b>label:</b> code-design
                </div></div></li><li><div><div><b>body:</b> [~bolke] - then make the names be what they are. Compat is just not meaningful. Make it&nbsp;DEFAULT and MIT or HADOOP and MIT- OS for system makes sense or SYSTEM would work too. Again, the semantic differences need to be articulated and documented very clearly.

There is no reason to print a warning for the default mechanism being used but folks do need to be able to determine what the default semantics are easily.

&nbsp;
                </div><div><b>label:</b> documentation
                </div></div></li><li><div>
                [~lmccay]
{quote}[~bolke] - then make the names be what they are. Compat is just not meaningful. Make it&nbsp;DEFAULT and MIT or HADOOP and MIT- OS for system makes sense or SYSTEM would work too. Again, the semantic differences need to be articulated and documented very clearly.
{quote}
-I'll go for "hadoop", "MIT_like", "system" (if that is ok). MIT_like as it better covers that Hadoop still does&nbsp;deviate from MIT.-&nbsp;

I'll go for "Hadoop", "MIT", "system". I just double checked and MIT actually does allow foreign realms inside the another realms specification. It depends on the kerberos context of the authentication which one it chooses. Hadoop always assumes default realm.
{quote}There is no reason to print a warning for the default mechanism being used but folks do need to be able to determine what the default semantics are easily.
{quote}
Warning will be removed from HadoopKerberosName (next version of patch). I'd like to keep a 'null' check. It should only turn up when people make use of KerberosName directly and makes debugging for us and for the user&nbsp;easier. I actually spent quite some time on this patch (see above) as I did not use a null check earlier and there was not enough direct debug information available to pin point the issue.

[~stevel@apache.org]
{quote}TestUserGroupInformation
{quote}
*

&nbsp;
{quote}keep with the static imports of specific fields, given someone has started that way
{quote} * 
{quote}{{testConstructorFailures}}. If the exception doesn't match, rethrow the full exception, possibly as the cause of a raised assertion. Preserves the stack trace.
{quote}

Will do.&nbsp;
              </div></li><li><div><div><b>body:</b> [~stevel@apache.org]&nbsp;
{quote}{{testConstructorFailures}}. If the exception doesn't match, rethrow the full exception, possibly as the cause of a raised assertion. Preserves the stack trace.
{quote}
Can you be a bit more specific? I think all places where I added extra code do rethrow the exception, but maybe I misunderstand you.

&nbsp;
                </div><div><b>label:</b> code-design
                </div></div></li><li><div><div><b>body:</b> * Addressed all outstanding comments afaik.
 * Documentation updated and examples corrected
                </div><div><b>label:</b> documentation
                </div></div></li><li><div>
                | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 22s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 5 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 21m 11s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 35s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m  2s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 48s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m 10s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 17s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 27s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 10s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 19s{color} | {color:red} hadoop-auth in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 28s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} compile {color} | {color:red}  0m 29s{color} | {color:red} root in the patch failed. {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red}  0m 29s{color} | {color:red} root in the patch failed. {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 50s{color} | {color:orange} hadoop-common-project: The patch generated 7 new + 276 unchanged - 1 fixed = 283 total (was 277) {color} |
| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 20s{color} | {color:red} hadoop-auth in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 30s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  1s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:red}-1{color} | {color:red} shadedclient {color} | {color:red}  0m 30s{color} | {color:red} patch has errors when building and testing our client artifacts. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 17s{color} | {color:red} hadoop-auth in the patch failed. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 18s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  2s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 19s{color} | {color:red} hadoop-auth in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 29s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 23s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 64m  7s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:8f97d6f |
| JIRA Issue | HADOOP-15996 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12953316/HADOOP-15996.0007.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux 2d47f9806d04 4.4.0-138-generic #164~14.04.1-Ubuntu SMP Fri Oct 5 08:56:16 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / e9a005d |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_191 |
| findbugs | v3.1.0-RC1 |
| mvninstall | https://builds.apache.org/job/PreCommit-HADOOP-Build/15709/artifact/out/patch-mvninstall-hadoop-common-project_hadoop-auth.txt |
| mvninstall | https://builds.apache.org/job/PreCommit-HADOOP-Build/15709/artifact/out/patch-mvninstall-hadoop-common-project_hadoop-common.txt |
| compile | https://builds.apache.org/job/PreCommit-HADOOP-Build/15709/artifact/out/patch-compile-root.txt |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/15709/artifact/out/patch-compile-root.txt |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/15709/artifact/out/diff-checkstyle-hadoop-common-project.txt |
| mvnsite | https://builds.apache.org/job/PreCommit-HADOOP-Build/15709/artifact/out/patch-mvnsite-hadoop-common-project_hadoop-auth.txt |
| mvnsite | https://builds.apache.org/job/PreCommit-HADOOP-Build/15709/artifact/out/patch-mvnsite-hadoop-common-project_hadoop-common.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/15709/artifact/out/patch-findbugs-hadoop-common-project_hadoop-auth.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/15709/artifact/out/patch-findbugs-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/15709/artifact/out/patch-unit-hadoop-common-project_hadoop-auth.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/15709/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/15709/testReport/ |
| Max. process+thread count | 305 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common U: hadoop-common-project |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/15709/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.


              </div></li><li><div>
                | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 23s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 5 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 11s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 22m 10s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 18m 48s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 59s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 46s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m 17s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 15s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 25s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 11s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 11s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 55s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 14m 55s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  1m  2s{color} | {color:orange} hadoop-common-project: The patch generated 7 new + 276 unchanged - 1 fixed = 283 total (was 277) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 44s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:red}-1{color} | {color:red} shadedclient {color} | {color:red} 11m 58s{color} | {color:red} patch has errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 32s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 26s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  3m 22s{color} | {color:red} hadoop-auth in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  7m  3s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 38s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}108m 32s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.security.authentication.client.TestKerberosAuthenticator |
|   | hadoop.io.file.tfile.TestVLong |
|   | hadoop.util.TestApplicationClassLoader |
|   | hadoop.io.file.tfile.TestTFileByteArrays |
|   | hadoop.fs.TestAvroFSInput |
|   | hadoop.fs.viewfs.TestViewFileSystemDelegation |
|   | hadoop.fs.TestDefaultUri |
|   | hadoop.fs.viewfs.TestFcPermissionsLocalFs |
|   | hadoop.fs.viewfs.TestViewFsURIs |
|   | hadoop.fs.shell.TestCopy |
|   | hadoop.fs.shell.TestCopyFromLocal |
|   | hadoop.fs.shell.TestPathData |
|   | hadoop.ha.TestHealthMonitor |
|   | hadoop.fs.TestGetFileBlockLocations |
|   | hadoop.fs.contract.rawlocal.TestRawlocalContractSetTimes |
|   | hadoop.http.TestHttpServer |
|   | hadoop.security.token.delegation.web.TestDelegationTokenAuthenticationHandlerWithMocks |
|   | hadoop.fs.TestChecksumFileSystem |
|   | hadoop.crypto.key.TestKeyProviderFactory |
|   | hadoop.security.authorize.TestProxyUsers |
|   | hadoop.security.token.delegation.web.TestDelegationTokenManager |
|   | hadoop.fs.TestHarFileSystemBasics |
|   | hadoop.io.TestSetFile |
|   | hadoop.fs.contract.rawlocal.TestRawlocalContractDelete |
|   | hadoop.fs.contract.localfs.TestLocalFSContractSeek |
|   | hadoop.fs.contract.rawlocal.TestRawlocalContractPathHandle |
|   | hadoop.fs.TestTruncatedInputBug |
|   | hadoop.fs.TestFSMainOperationsLocalFileSystem |
|   | hadoop.fs.contract.localfs.TestLocalFSContractSetTimes |
|   | hadoop.fs.TestPath |
|   | hadoop.util.TestGenericOptionsParser |
|   | hadoop.metrics2.sink.TestRollingFileSystemSink |
|   | hadoop.security.TestRaceWhenRelogin |
|   | hadoop.crypto.key.TestKeyShell |
|   | hadoop.io.file.tfile.TestTFile |
|   | hadoop.fs.sftp.TestSFTPFileSystem |
|   | hadoop.fs.contract.rawlocal.TestRawlocalContractAppend |
|   | hadoop.ipc.TestProtoBufRPCCompatibility |
|   | hadoop.fs.viewfs.TestViewfsFileStatus |
|   | hadoop.fs.TestTrash |
|   | hadoop.fs.TestLocalDirAllocator |
|   | hadoop.security.alias.TestCredShell |
|   | hadoop.ipc.TestIdentityProviders |
|   | hadoop.ipc.TestIPCServerResponder |
|   | hadoop.fs.TestFileContextResolveAfs |
|   | hadoop.io.TestMapFile |
|   | hadoop.fs.shell.TestCopyPreserveFlag |
|   | hadoop.cli.TestCLI |
|   | hadoop.crypto.key.TestKeyProviderCryptoExtension |
|   | hadoop.fs.TestFsShellCopy |
|   | hadoop.io.file.tfile.TestTFileSplit |
|   | hadoop.ipc.TestAsyncIPC |
|   | hadoop.fs.TestFsShell |
|   | hadoop.io.TestBloomMapFile |
|   | hadoop.fs.shell.find.TestName |
|   | hadoop.io.TestSecureIOUtils |
|   | hadoop.fs.contract.localfs.TestLocalFSContractOpen |
|   | hadoop.io.file.tfile.TestTFileComparators |
|   | hadoop.fs.contract.localfs.TestLocalFSContractMkdir |
|   | hadoop.crypto.TestCryptoStreamsForLocalFS |
|   | hadoop.fs.shell.TestTextCommand |
|   | hadoop.fs.shell.TestCount |
|   | hadoop.io.file.tfile.TestTFileStreams |
|   | hadoop.fs.viewfs.TestViewFsTrash |
|   | hadoop.ipc.TestRPCServerShutdown |
|   | hadoop.fs.viewfs.TestFcCreateMkdirLocalFs |
|   | hadoop.fs.contract.rawlocal.TestRawlocalContractMkdir |
|   | hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal |
|   | hadoop.fs.contract.localfs.TestLocalFSContractRename |
|   | hadoop.fs.contract.localfs.TestLocalFSContractDelete |
|   | hadoop.fs.viewfs.TestFcMainOperationsLocalFs |
|   | hadoop.ipc.TestRPCWaitForProxy |
|   | hadoop.ha.TestZKFailoverController |
|   | hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem |
|   | hadoop.security.token.TestDtUtilShell |
|   | hadoop.fs.TestRawLocalFileSystemContract |
|   | hadoop.security.authorize.TestAccessControlList |
|   | hadoop.security.ssl.TestSSLFactory |
|   | hadoop.fs.shell.find.TestPrint0 |
|   | hadoop.io.TestSequenceFile |
|   | hadoop.io.nativeio.TestNativeIO |
|   | hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays |
|   | hadoop.fs.viewfs.TestViewFileSystemDelegationTokenSupport |
|   | hadoop.security.TestUserFromEnv |
|   | hadoop.security.TestFixKerberosTicketOrder |
|   | hadoop.io.file.tfile.TestTFileUnsortedByteArrays |
|   | hadoop.fs.shell.TestXAttrCommands |
|   | hadoop.ipc.TestMiniRPCBenchmark |
|   | hadoop.fs.shell.find.TestIname |
|   | hadoop.io.file.tfile.TestTFileSeek |
|   | hadoop.io.TestSequenceFileSync |
|   | hadoop.fs.TestLocalFSFileContextCreateMkdir |
|   | hadoop.crypto.key.TestKeyProviderDelegationTokenExtension |
|   | hadoop.ipc.TestRPC |
|   | hadoop.fs.TestFcLocalFsUtil |
|   | hadoop.fs.TestStat |
|   | hadoop.fs.contract.rawlocal.TestRawlocalContractSeek |
|   | hadoop.ipc.TestProtoBufRpc |
|   | hadoop.fs.http.TestHttpFileSystem |
|   | hadoop.fs.shell.find.TestFind |
|   | hadoop.util.TestDiskChecker |
|   | hadoop.fs.TestLocalFSFileContextMainOperations |
|   | hadoop.security.TestKDiag |
|   | hadoop.io.TestSequenceFileAppend |
|   | hadoop.util.TestBasicDiskValidator |
|   | hadoop.fs.contract.localfs.TestLocalFSContractGetFileStatus |
|   | hadoop.security.alias.TestCredentialProviderFactory |
|   | hadoop.ipc.TestIPC |
|   | hadoop.fs.contract.localfs.TestLocalFSContractAppend |
|   | hadoop.ipc.TestMultipleProtocolServer |
|   | hadoop.fs.viewfs.TestChRootedFs |
|   | hadoop.security.token.delegation.TestZKDelegationTokenSecretManager |
|   | hadoop.fs.TestFsShellReturnCode |
|   | hadoop.fs.TestLocalFsFCStatistics |
|   | hadoop.io.file.tfile.TestTFileNoneCodecsStreams |
|   | hadoop.fs.TestSymlinkLocalFSFileContext |
|   | hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem |
|   | hadoop.fs.contract.localfs.TestLocalFSContractLoaded |
|   | hadoop.security.TestUGIWithMiniKdc |
|   | hadoop.fs.shell.find.TestPrint |
|   | hadoop.fs.contract.rawlocal.TestRawlocalContractOpen |
|   | hadoop.io.file.tfile.TestTFileComparator2 |
|   | hadoop.ipc.TestSaslRPC |
|   | hadoop.util.TestRunJar |
|   | hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs |
|   | hadoop.fs.TestLocalFileSystemPermission |
|   | hadoop.security.TestJNIGroupsMapping |
|   | hadoop.ipc.TestRPCCallBenchmark |
|   | hadoop.fs.shell.TestMove |
|   | hadoop.fs.shell.TestLs |
|   | hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays |
|   | hadoop.ha.TestHealthMonitorWithDedicatedHealthAddress |
|   | hadoop.security.TestKDiagNoKDC |
|   | hadoop.fs.viewfs.TestViewFsConfig |
|   | hadoop.fs.contract.localfs.TestLocalFSContractCreate |
|   | hadoop.fs.TestListFiles |
|   | hadoop.fs.contract.rawlocal.TestRawlocalContractRename |
|   | hadoop.security.TestUserGroupInformation |
|   | hadoop.security.authorize.TestServiceAuthorization |
|   | hadoop.fs.TestFsShellTouch |
|   | hadoop.fs.TestFileUtil |
|   | hadoop.fs.contract.localfs.TestLocalFSContractMultipartUploader |
|   | hadoop.security.TestDoAsEffectiveUser |
|   | hadoop.fs.TestFcLocalFsPermission |
|   | hadoop.util.TestNodeHealthScriptRunner |
|   | hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays |
|   | hadoop.ha.TestZKFailoverControllerStress |
|   | hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem |
|   | hadoop.fs.contract.rawlocal.TestRawlocalContractCreate |
|   | hadoop.fs.viewfs.TestChRootedFileSystem |
|   | hadoop.fs.TestFileContext |
|   | hadoop.ipc.TestReuseRpcConnections |
|   | hadoop.security.token.delegation.web.TestWebDelegationToken |
|   | hadoop.fs.viewfs.TestViewFsLocalFs |
|   | hadoop.util.TestJsonSerialization |
|   | hadoop.security.TestProxyUserFromEnv |
|   | hadoop.fs.TestLocalFileSystem |
|   | hadoop.io.TestSequenceFileSerialization |
|   | hadoop.fs.contract.rawlocal.TestRawlocalContractGetFileStatus |
|   | hadoop.io.TestArrayFile |
|   | hadoop.conf.TestConfiguration |
|   | hadoop.fs.shell.TestAclCommands |
|   | hadoop.fs.TestFilterFs |
|   | hadoop.ipc.TestProtoBufRpcServerHandoff |
|   | hadoop.security.TestSecurityUtil |
|   | hadoop.fs.TestFsShellList |
|   | hadoop.fs.TestFileContextDeleteOnExit |
|   | hadoop.security.TestUGILoginFromKeytab |
|   | hadoop.io.file.tfile.TestTFileSeqFileComparison |
|   | hadoop.io.compress.TestCodec |
|   | hadoop.log.TestLogLevel |
|   | hadoop.security.TestLdapGroupsMapping |
|   | hadoop.fs.TestSymlinkLocalFSFileSystem |
|   | hadoop.ipc.TestServer |
|   | hadoop.ipc.TestRpcServerHandoff |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:8f97d6f |
| JIRA Issue | HADOOP-15996 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12953321/HADOOP-15996.0008.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux 38896ee2249f 4.4.0-138-generic #164~14.04.1-Ubuntu SMP Fri Oct 5 08:56:16 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / e9a005d |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_191 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/15710/artifact/out/diff-checkstyle-hadoop-common-project.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/15710/artifact/out/patch-unit-hadoop-common-project_hadoop-auth.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/15710/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/15710/testReport/ |
| Max. process+thread count | 1585 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common U: hadoop-common-project |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/15710/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.


              </div></li><li><div>
                It seems the patch is still using "legacy" - isn't this supposed to be "hadoop" now?

If not, then I don't understand what the difference between legacy and hadoop is.

&nbsp;
              </div></li><li><div>
                [~lmccay] it should be 'Hadoop' and not legacy. I missed a spot, sorry. I'm on a dev environment I don't typically use.
              </div></li><li><div>
                | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 17s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 5 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 13s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 20m 22s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 30s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m  1s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 47s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m  8s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 16s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 26s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 11s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 10s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 50s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 14m 50s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  1m  2s{color} | {color:orange} hadoop-common-project: The patch generated 7 new + 276 unchanged - 1 fixed = 283 total (was 277) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 46s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m  7s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 39s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 26s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  3m 20s{color} | {color:red} hadoop-auth in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 42s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 37s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}105m  6s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.security.authentication.client.TestKerberosAuthenticator |
|   | hadoop.security.ssl.TestSSLFactory |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:8f97d6f |
| JIRA Issue | HADOOP-15996 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12953327/HADOOP-15996.0009.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux 9b86a0f1bd23 4.4.0-138-generic #164~14.04.1-Ubuntu SMP Fri Oct 5 08:56:16 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / e9a005d |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_191 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/15711/artifact/out/diff-checkstyle-hadoop-common-project.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/15711/artifact/out/patch-unit-hadoop-common-project_hadoop-auth.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/15711/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/15711/testReport/ |
| Max. process+thread count | 1629 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common U: hadoop-common-project |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/15711/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.


              </div></li><li><div>
                | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  7m 38s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 5 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 19s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 20m 40s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 58s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m  2s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 46s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m  4s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 21s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 25s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 10s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  8s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 14s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 14m 14s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  1m  1s{color} | {color:orange} hadoop-common-project: The patch generated 7 new + 276 unchanged - 1 fixed = 283 total (was 277) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 43s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m  5s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 31s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 24s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 59s{color} | {color:green} hadoop-auth in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  7m 48s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 40s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}110m  8s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.security.ssl.TestSSLFactory |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:8f97d6f |
| JIRA Issue | HADOOP-15996 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12953336/HADOOP-15996.0010.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux ab019ea67d24 4.4.0-134-generic #160~14.04.1-Ubuntu SMP Fri Aug 17 11:07:07 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / e9a005d |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_191 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/15712/artifact/out/diff-checkstyle-hadoop-common-project.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/15712/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/15712/testReport/ |
| Max. process+thread count | 1486 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common U: hadoop-common-project |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/15712/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.


              </div></li><li><div>
                Failing tests are unrelated as far as I can determine. 
              </div></li><li><div>
                I uploaded again the number 10 patch as 11 without any modification to test the git url migration.  (This was the most recent, good patch.)

Sorry for the additional noise (an additional precommit report is expected here soon...)
              </div></li><li><div>
                | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 5 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 11s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 20m 13s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 35s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m  2s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 47s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m 15s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 17s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 26s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 11s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 10s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 52s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 14m 52s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  1m  2s{color} | {color:orange} hadoop-common-project: The patch generated 7 new + 276 unchanged - 1 fixed = 283 total (was 277) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 45s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 10s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 32s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 26s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 20s{color} | {color:green} hadoop-auth in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 21s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 39s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}104m 46s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.security.ssl.TestSSLFactory |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:8f97d6f |
| JIRA Issue | HADOOP-15996 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12953349/HADOOP-15996.0011.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux 9df9f3fce7d5 4.4.0-138-generic #164~14.04.1-Ubuntu SMP Fri Oct 5 08:56:16 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / eee29ed |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_191 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/15713/artifact/out/diff-checkstyle-hadoop-common-project.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/15713/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/15713/testReport/ |
| Max. process+thread count | 1717 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common U: hadoop-common-project |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/15713/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.


              </div></li><li><div>
                TestSSLFactory unit test failure seems to be related to JDK version.  It doesn't happen on older JDK (1.8.0_151).  Patch 10 works correctly for me.  TestUserGroupInformation.java line 903 has incorrect indentation.  Other than that it looks good to me.
              </div></li><li><div>
                [~eyang] good catch, I should never have touched that line. Is fixed now in the latest version of this patch.
              </div></li><li><div>
                | (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  8m 21s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 5 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 21s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m 46s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 16m  8s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 48s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 38s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 10s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  6s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 17s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  8s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  3s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 44s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 13m 44s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 52s{color} | {color:orange} hadoop-common-project: The patch generated 6 new + 277 unchanged - 0 fixed = 283 total (was 277) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 32s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 25s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 20s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 15s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 52s{color} | {color:green} hadoop-auth in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m  1s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 32s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}105m 36s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.security.ssl.TestSSLFactory |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:8f97d6f |
| JIRA Issue | HADOOP-15996 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12953382/HADOOP-15996.0012.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  |
| uname | Linux 87db7ee2f69c 4.4.0-138-generic #164-Ubuntu SMP Tue Oct 2 17:16:02 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / eee29ed |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_191 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/15715/artifact/out/diff-checkstyle-hadoop-common-project.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/15715/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/15715/testReport/ |
| Max. process+thread count | 1601 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common U: hadoop-common-project |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/15715/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.


              </div></li><li><div>
                +1 for patch 12.  I will commit patch 12 by Jan 4th if no objections.
              </div></li><li><div>
                Patch 12 looks good to me as well.&nbsp;

Here is my +1.

[~daryn] - can you please take a look at this as you very clearly represent the "Hadoop" mode in this change.

[~owen.omalley] - it would be good to have your eyes on it as well.
              </div></li><li><div>
                [~bolke] Thank you for the patch.  

There is no objections in the past 3 days.  I commit this change to branch-3.1, branch-3.2 and trunk.  [~sunilg] [~wangda] Please make sure 3.2.0 and 3.1.2 releases include this change.  Thanks
              </div></li><li><div>
                SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #15707 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/15707/])
HADOOP-15996.  Improved Kerberos username mapping strategy in Hadoop.    (eyang: rev d43af8b3db4743b4b240751b6f29de6c20cfd6e5)
* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/CommonConfigurationKeysPublic.java
* (edit) hadoop-common-project/hadoop-common/src/site/markdown/SecureMode.md
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestKDiag.java
* (edit) hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/util/TestKerberosName.java
* (edit) hadoop-common-project/hadoop-auth/src/main/java/org/apache/hadoop/security/authentication/util/KerberosName.java
* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/KDiag.java
* (edit) hadoop-common-project/hadoop-common/src/main/resources/core-default.xml
* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/http/HttpServer2.java
* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/HadoopKerberosName.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestUserGroupInformation.java
* (edit) hadoop-common-project/hadoop-auth/src/main/java/org/apache/hadoop/security/authentication/server/KerberosAuthenticationHandler.java
* (edit) hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/client/TestKerberosAuthenticator.java
* (edit) hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/server/TestKerberosAuthenticationHandler.java

              </div></li><li><div>
                [~lmccay], apologies that I didn't see your review request since&nbsp;I've been on vacation for many weeks. &nbsp;Will do an after the fact review today.
              </div></li><li><div>
                [~daryn] - welcome back and Happy New Year!

It would be really good if you could take a look - be warned that there is an rc for 3.2.0 which includes it.

Thanks!
              </div></li></ol></div></div></html>