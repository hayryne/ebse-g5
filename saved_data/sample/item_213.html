<!DOCTYPE html><html><div class="item-title">
        Item 213
      </div> <div class="item-details"><div><b>git_comments:</b> <ol><li><div>
                 Execute a task while the Api Throws errors
              </div></li><li><div>
                 Disable the ApiException
              </div></li><li><div>
                 A mock kube_client that throws errors when making a pod
              </div></li><li><div>
                 Execute the task without errors should empty the queue
              </div></li><li><div>
                 When a quota is exceeded this is the ApiException we get
              </div></li></ol></div><div><b>git_commits:</b> <ol><li><div><div><b>summary:</b> [AIRFLOW-2966] Catch ApiException in the Kubernetes Executor (#4209)
                </div><div><b>message:</b> [AIRFLOW-2966] Catch ApiException in the Kubernetes Executor (#4209)

Creating a pod that exceeds a namespace's resource quota throws an
ApiException. This change catches the exception and the task is
re-queued inside the Executor instead of killing the scheduler.
                </div></div></li></ol></div><div><b>github_issues:</b> <ol></ol></div><div><b>github_issues_comments:</b> <ol></ol></div><div><b>github_pulls:</b> <ol><li><div><div><b>title:</b> [AIRFLOW-2966] Catch ApiException in the Kubernetes Executor
                </div><div><b>body:</b> ### Description

Creating a pod that exceeds a namespace's resource quota throws an ApiException. This change catches the exception and the task is re-queued inside the Executor instead of killing the scheduler.

`click 7.0` was recently released but `flask-appbuilder 1.11.1 has requirement click==6.7`. I have pinned `click==6.7` to make the dependencies resolve.

### Tests

This adds a single test `TestKubernetesExecutor. test_run_next_exception` that covers this single scenario. Without the changes this test fails when the ApiException is not caught. 

This is the first test case for the `KubernetesExecutor`,  so I needed to add the `[kubernetes]` section to `default_test.cfg` so that the `KubernetesExecutor` can be built without exceptions.

Jira ticket: https://issues.apache.org/jira/browse/AIRFLOW-2966


                </div></div></li><li><div><div><b>title:</b> [AIRFLOW-2966] Catch ApiException in the Kubernetes Executor
                </div><div><b>body:</b> ### Description

Creating a pod that exceeds a namespace's resource quota throws an ApiException. This change catches the exception and the task is re-queued inside the Executor instead of killing the scheduler.

`click 7.0` was recently released but `flask-appbuilder 1.11.1 has requirement click==6.7`. I have pinned `click==6.7` to make the dependencies resolve.

### Tests

This adds a single test `TestKubernetesExecutor. test_run_next_exception` that covers this single scenario. Without the changes this test fails when the ApiException is not caught. 

This is the first test case for the `KubernetesExecutor`,  so I needed to add the `[kubernetes]` section to `default_test.cfg` so that the `KubernetesExecutor` can be built without exceptions.

Jira ticket: https://issues.apache.org/jira/browse/AIRFLOW-2966


                </div></div></li><li><div><div><b>title:</b> [AIRFLOW-2966] Catch ApiException in the Kubernetes Executor
                </div><div><b>body:</b> ### Description

Creating a pod that exceeds a namespace's resource quota throws an ApiException. This change catches the exception and the task is re-queued inside the Executor instead of killing the scheduler.

`click 7.0` was recently released but `flask-appbuilder 1.11.1 has requirement click==6.7`. I have pinned `click==6.7` to make the dependencies resolve.

### Tests

This adds a single test `TestKubernetesExecutor. test_run_next_exception` that covers this single scenario. Without the changes this test fails when the ApiException is not caught. 

This is the first test case for the `KubernetesExecutor`,  so I needed to add the `[kubernetes]` section to `default_test.cfg` so that the `KubernetesExecutor` can be built without exceptions.

Jira ticket: https://issues.apache.org/jira/browse/AIRFLOW-2966


                </div></div></li><li><div><div><b>title:</b> [AIRFLOW-2966] Catch ApiException in the Kubernetes Executor
                </div><div><b>body:</b> ### Description

Creating a pod that exceeds a namespace's resource quota throws an ApiException. This change catches the exception and the task is re-queued inside the Executor instead of killing the scheduler.

`click 7.0` was recently released but `flask-appbuilder 1.11.1 has requirement click==6.7`. I have pinned `click==6.7` to make the dependencies resolve.

### Tests

This adds a single test `TestKubernetesExecutor. test_run_next_exception` that covers this single scenario. Without the changes this test fails when the ApiException is not caught. 

This is the first test case for the `KubernetesExecutor`,  so I needed to add the `[kubernetes]` section to `default_test.cfg` so that the `KubernetesExecutor` can be built without exceptions.

Jira ticket: https://issues.apache.org/jira/browse/AIRFLOW-2966


                </div></div></li></ol></div><div><b>github_pulls_comments:</b> <ol><li><div>
                @Fokko This is a resubmission of #3960, which was reverted when it broke the CI on master. This was due to the refactoring of the task instance key in PR #3994, which was not included in the PR #3960 tests, but got merged to master first.

              </div></li><li><div>
                # [Codecov](https://codecov.io/gh/apache/incubator-airflow/pull/4209?src=pr&amp;el=h1) Report
&gt; Merging [#4209](https://codecov.io/gh/apache/incubator-airflow/pull/4209?src=pr&amp;el=desc) into [master](https://codecov.io/gh/apache/incubator-airflow/commit/94d19707d7f3563bb48868c2d6442c3da923da20?src=pr&amp;el=desc) will **increase** coverage by `&lt;.01%`.
&gt; The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/apache/incubator-airflow/pull/4209/graphs/tree.svg?width=650&amp;token=WdLKlKHOAU&amp;height=150&amp;src=pr)](https://codecov.io/gh/apache/incubator-airflow/pull/4209?src=pr&amp;el=tree)

```diff
@@            Coverage Diff             @@
##           master    #4209      +/-   ##
==========================================
+ Coverage    77.7%   77.71%   +&lt;.01%     
==========================================
  Files         199      199              
  Lines       16317    16317              
==========================================
+ Hits        12679    12680       +1     
+ Misses       3638     3637       -1
```


| [Impacted Files](https://codecov.io/gh/apache/incubator-airflow/pull/4209?src=pr&amp;el=tree) | Coverage Δ | |
|---|---|---|
| [airflow/models.py](https://codecov.io/gh/apache/incubator-airflow/pull/4209/diff?src=pr&amp;el=tree#diff-YWlyZmxvdy9tb2RlbHMucHk=) | `92.33% &lt;0%&gt; (+0.04%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/apache/incubator-airflow/pull/4209?src=pr&amp;el=continue).
&gt; **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
&gt; `Δ = absolute &lt;relative&gt; (impact)`, `ø = not affected`, `? = missing data`
&gt; Powered by [Codecov](https://codecov.io/gh/apache/incubator-airflow/pull/4209?src=pr&amp;el=footer). Last update [94d1970...b4365c4](https://codecov.io/gh/apache/incubator-airflow/pull/4209?src=pr&amp;el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).

              </div></li></ol></div><div><b>github_pulls_reviews:</b> <ol></ol></div><div><b>jira_issues:</b> <ol><li><div><div><b>summary:</b> KubernetesExecutor + namespace quotas kills scheduler if the pod can't be launched
                </div><div><b>description:</b> When running Airflow in Kubernetes with the KubernetesExecutor and resource quota's set on the namespace Airflow is deployed in. If the scheduler tries to launch a pod into the namespace that exceeds the namespace limits it gets an ApiException, and crashes the scheduler.

This stack trace is an example of the ApiException from the kubernetes client:
{code:java}
[2018-08-27 09:51:08,516] {pod_launcher.py:58} ERROR - Exception when attempting to create Namespaced Pod.
Traceback (most recent call last):
File "/src/apache-airflow/airflow/contrib/kubernetes/pod_launcher.py", line 55, in run_pod_async
resp = self._client.create_namespaced_pod(body=req, namespace=pod.namespace)
File "/usr/local/lib/python3.6/site-packages/kubernetes/client/apis/core_v1_api.py", line 6057, in create_namespaced_pod
(data) = self.create_namespaced_pod_with_http_info(namespace, body, **kwargs)
File "/usr/local/lib/python3.6/site-packages/kubernetes/client/apis/core_v1_api.py", line 6142, in create_namespaced_pod_with_http_info
collection_formats=collection_formats)
File "/usr/local/lib/python3.6/site-packages/kubernetes/client/api_client.py", line 321, in call_api
_return_http_data_only, collection_formats, _preload_content, _request_timeout)
File "/usr/local/lib/python3.6/site-packages/kubernetes/client/api_client.py", line 155, in __call_api
_request_timeout=_request_timeout)
File "/usr/local/lib/python3.6/site-packages/kubernetes/client/api_client.py", line 364, in request
body=body)
File "/usr/local/lib/python3.6/site-packages/kubernetes/client/rest.py", line 266, in POST
body=body)
File "/usr/local/lib/python3.6/site-packages/kubernetes/client/rest.py", line 222, in request
raise ApiException(http_resp=r)
kubernetes.client.rest.ApiException: (403)
Reason: Forbidden
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'b00e2cbb-bdb2-41f3-8090-824aee79448c', 'Content-Type': 'application/json', 'Date': 'Mon, 27 Aug 2018 09:51:08 GMT', 'Content-Length': '410'})
HTTP response body: {"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"pods \"podname-ec366e89ef934d91b2d3ffe96234a725\" is forbidden: exceeded quota: compute-resources, requested: limits.memory=4Gi, used: limits.memory=6508Mi, limited: limits.memory=10Gi","reason":"Forbidden","details":{"name":"podname-ec366e89ef934d91b2d3ffe96234a725","kind":"pods"},"code":403}{code}
&nbsp;

I would expect the scheduler to catch the Exception and at least mark the task as failed, or better yet retry the task later.

&nbsp;

&nbsp;
                </div></div></li></ol></div><div><b>jira_issues_comments:</b> <ol><li><div><div><b>body:</b> Colleague of John here. Some additional info:
 * Updated to 1.10.0 and retried, same issue remains
 * Last observation in the log (not mentioned above):

{{[2018-08-30 12:19:46,967] \{jobs.py:1585} INFO - Exited execute loop}}

In the Pod I can see 2 other threads remaining, but they don't seem to do anything.

{{$ ps -ef}}

{{airflow 16 1 0 12:19 ? 00:00:02 /usr/local/bin/python /usr/local/bin/airflow scheduler -n -1}}
 {{airflow 38 16 0 12:19 ? 00:00:00 /usr/local/bin/python /usr/local/bin/airflow scheduler -n -1}}

The Pod is stuck but does not exit. So we need to kill it by hand.

If we increase the quota on the namespace, nothing happens to the scheduler.

&nbsp;

Steps to reproduce:

Set a Pod quotum on your namespace. First count the current number of pods and set it to that value.
{code:java}
apiVersion: v1
kind: ResourceQuota
metadata:
  name: compute-resources
spec:
  hard:
    pods: "4"{code}
&nbsp;Then try to schedule a task.

&nbsp;
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                johnhofman opened a new pull request #3960: [AIRFLOW-2966] Catch ApiException in the Kubernetes Executor
URL: https://github.com/apache/incubator-airflow/pull/3960
 
 
   ### Description
   
   Creating a pod that exceeds a namespace's resource quota throws an ApiException. This change catches the exception and the task is re-queued inside the Executor instead of killing the scheduler.
   
   `click 7.0` was recently released but `flask-appbuilder 1.11.1 has requirement click==6.7`. I have pinned `click==6.7` to make the dependencies resolve.
   
   ### Tests
   
   This adds a single test `TestKubernetesExecutor. test_run_next_exception` that covers this single scenario. Without the changes this test fails when the ApiException is not caught. 
   
   This is the first test case for the `KubernetesExecutor`,  so I needed to add the `[kubernetes]` section to `default_test.cfg` so that the `KubernetesExecutor` can be built without exceptions.
   

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org

              </div></li><li><div>
                Fokko closed pull request #3960: [AIRFLOW-2966] Catch ApiException in the Kubernetes Executor
URL: https://github.com/apache/incubator-airflow/pull/3960
 
 
   

This is a PR merged from a forked repository.
As GitHub hides the original diff on merge, it is displayed below for
the sake of provenance:

As this is a foreign pull request (from a fork), the diff is supplied
below (as it won't show otherwise due to GitHub magic):

diff --git a/airflow/config_templates/default_test.cfg b/airflow/config_templates/default_test.cfg
index f9279cce54..2630a60ce4 100644
--- a/airflow/config_templates/default_test.cfg
+++ b/airflow/config_templates/default_test.cfg
@@ -125,3 +125,6 @@ hide_sensitive_variable_fields = True
 elasticsearch_host =
 elasticsearch_log_id_template = {{dag_id}}-{{task_id}}-{{execution_date}}-{{try_number}}
 elasticsearch_end_of_log_mark = end_of_log
+
+[kubernetes]
+dags_volume_claim = default
diff --git a/airflow/contrib/executors/kubernetes_executor.py b/airflow/contrib/executors/kubernetes_executor.py
index de1f9f4235..f9e350d303 100644
--- a/airflow/contrib/executors/kubernetes_executor.py
+++ b/airflow/contrib/executors/kubernetes_executor.py
@@ -599,8 +599,14 @@ def sync(self):
             last_resource_version, session=self._session)
 
         if not self.task_queue.empty():
-            key, command, kube_executor_config = self.task_queue.get()
-            self.kube_scheduler.run_next((key, command, kube_executor_config))
+            task = self.task_queue.get()
+
+            try:
+                self.kube_scheduler.run_next(task)
+            except ApiException:
+                self.log.exception('ApiException when attempting ' +
+                                   'to run task, re-queueing.')
+                self.task_queue.put(task)
 
     def _change_state(self, key, state, pod_id):
         if state != State.RUNNING:
diff --git a/tests/contrib/executors/test_kubernetes_executor.py b/tests/contrib/executors/test_kubernetes_executor.py
index c203e18d5c..905beeec40 100644
--- a/tests/contrib/executors/test_kubernetes_executor.py
+++ b/tests/contrib/executors/test_kubernetes_executor.py
@@ -18,10 +18,13 @@
 import re
 import string
 import random
+from urllib3 import HTTPResponse
 from datetime import datetime
 
 try:
+    from kubernetes.client.rest import ApiException
     from airflow.contrib.executors.kubernetes_executor import AirflowKubernetesScheduler
+    from airflow.contrib.executors.kubernetes_executor import KubernetesExecutor
     from airflow.contrib.kubernetes.worker_configuration import WorkerConfiguration
 except ImportError:
     AirflowKubernetesScheduler = None
@@ -81,6 +84,7 @@ class TestKubernetesWorkerConfiguration(unittest.TestCase):
     Tests that if dags_volume_subpath/logs_volume_subpath configuration
     options are passed to worker pod config
     """
+
     def setUp(self):
         if AirflowKubernetesScheduler is None:
             self.skipTest("kubernetes python package is not installed")
@@ -152,5 +156,61 @@ def test_worker_environment_when_dags_folder_specified(self):
         self.assertEqual(dags_folder, env['AIRFLOW__CORE__DAGS_FOLDER'])
 
 
+class TestKubernetesExecutor(unittest.TestCase):
+    """
+    Tests if an ApiException from the Kube Client will cause the task to
+    be rescheduled.
+    """
+    @unittest.skipIf(AirflowKubernetesScheduler is None,
+                     'kubernetes python package is not installed')
+    @mock.patch('airflow.contrib.executors.kubernetes_executor.KubernetesJobWatcher')
+    @mock.patch('airflow.contrib.executors.kubernetes_executor.get_kube_client')
+    def test_run_next_exception(self, mock_get_kube_client, mock_kubernetes_job_watcher):
+
+        # When a quota is exceeded this is the ApiException we get
+        r = HTTPResponse()
+        r.body = {
+            "kind": "Status",
+            "apiVersion": "v1",
+            "metadata": {},
+            "status": "Failure",
+            "message": "pods \"podname\" is forbidden: " +
+            "exceeded quota: compute-resources, " +
+            "requested: limits.memory=4Gi, " +
+            "used: limits.memory=6508Mi, " +
+            "limited: limits.memory=10Gi",
+            "reason": "Forbidden",
+            "details": {"name": "podname", "kind": "pods"},
+            "code": 403},
+        r.status = 403
+        r.reason = "Forbidden"
+
+        # A mock kube_client that throws errors when making a pod
+        mock_kube_client = mock.patch('kubernetes.client.CoreV1Api', autospec=True)
+        mock_kube_client.create_namespaced_pod = mock.MagicMock(
+            side_effect=ApiException(http_resp=r))
+        mock_get_kube_client.return_value = mock_kube_client
+
+        kubernetesExecutor = KubernetesExecutor()
+        kubernetesExecutor.start()
+
+        # Execute a task while the Api Throws errors
+        kubernetesExecutor.execute_async(key=('dag', 'task', datetime.utcnow()),
+                                         command='command', executor_config={})
+        kubernetesExecutor.sync()
+        kubernetesExecutor.sync()
+
+        mock_kube_client.create_namespaced_pod.assert_called()
+        self.assertFalse(kubernetesExecutor.task_queue.empty())
+
+        # Disable the ApiException
+        mock_kube_client.create_namespaced_pod.side_effect = None
+
+        # Execute the task without errors should empty the queue
+        kubernetesExecutor.sync()
+        mock_kube_client.create_namespaced_pod.assert_called()
+        self.assertTrue(kubernetesExecutor.task_queue.empty())
+
+
 if __name__ == '__main__':
     unittest.main()


 

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org

              </div></li><li><div>
                johnhofman opened a new pull request #4209: [AIRFLOW-2966] Catch ApiException in the Kubernetes Executor
URL: https://github.com/apache/incubator-airflow/pull/4209
 
 
   ### Description
   
   Creating a pod that exceeds a namespace's resource quota throws an ApiException. This change catches the exception and the task is re-queued inside the Executor instead of killing the scheduler.
   
   `click 7.0` was recently released but `flask-appbuilder 1.11.1 has requirement click==6.7`. I have pinned `click==6.7` to make the dependencies resolve.
   
   ### Tests
   
   This adds a single test `TestKubernetesExecutor. test_run_next_exception` that covers this single scenario. Without the changes this test fails when the ApiException is not caught. 
   
   This is the first test case for the `KubernetesExecutor`,  so I needed to add the `[kubernetes]` section to `default_test.cfg` so that the `KubernetesExecutor` can be built without exceptions.
   
   Jira ticket: https://issues.apache.org/jira/browse/AIRFLOW-2966
   
   

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org

              </div></li><li><div>
                Fokko closed pull request #4209: [AIRFLOW-2966] Catch ApiException in the Kubernetes Executor
URL: https://github.com/apache/incubator-airflow/pull/4209
 
 
   

This is a PR merged from a forked repository.
As GitHub hides the original diff on merge, it is displayed below for
the sake of provenance:

As this is a foreign pull request (from a fork), the diff is supplied
below (as it won't show otherwise due to GitHub magic):

diff --git a/airflow/config_templates/default_test.cfg b/airflow/config_templates/default_test.cfg
index 6baec130b3..f0a467894d 100644
--- a/airflow/config_templates/default_test.cfg
+++ b/airflow/config_templates/default_test.cfg
@@ -126,3 +126,6 @@ hide_sensitive_variable_fields = True
 elasticsearch_host =
 elasticsearch_log_id_template = {{dag_id}}-{{task_id}}-{{execution_date}}-{{try_number}}
 elasticsearch_end_of_log_mark = end_of_log
+
+[kubernetes]
+dags_volume_claim = default
diff --git a/airflow/contrib/executors/kubernetes_executor.py b/airflow/contrib/executors/kubernetes_executor.py
index e23ff96402..6c1bd222b9 100644
--- a/airflow/contrib/executors/kubernetes_executor.py
+++ b/airflow/contrib/executors/kubernetes_executor.py
@@ -607,8 +607,14 @@ def sync(self):
             last_resource_version, session=self._session)
 
         if not self.task_queue.empty():
-            key, command, kube_executor_config = self.task_queue.get()
-            self.kube_scheduler.run_next((key, command, kube_executor_config))
+            task = self.task_queue.get()
+
+            try:
+                self.kube_scheduler.run_next(task)
+            except ApiException:
+                self.log.exception('ApiException when attempting ' +
+                                   'to run task, re-queueing.')
+                self.task_queue.put(task)
 
     def _change_state(self, key, state, pod_id):
         if state != State.RUNNING:
diff --git a/tests/contrib/executors/test_kubernetes_executor.py b/tests/contrib/executors/test_kubernetes_executor.py
index c203e18d5c..1307e500cf 100644
--- a/tests/contrib/executors/test_kubernetes_executor.py
+++ b/tests/contrib/executors/test_kubernetes_executor.py
@@ -18,10 +18,13 @@
 import re
 import string
 import random
+from urllib3 import HTTPResponse
 from datetime import datetime
 
 try:
+    from kubernetes.client.rest import ApiException
     from airflow.contrib.executors.kubernetes_executor import AirflowKubernetesScheduler
+    from airflow.contrib.executors.kubernetes_executor import KubernetesExecutor
     from airflow.contrib.kubernetes.worker_configuration import WorkerConfiguration
 except ImportError:
     AirflowKubernetesScheduler = None
@@ -81,6 +84,7 @@ class TestKubernetesWorkerConfiguration(unittest.TestCase):
     Tests that if dags_volume_subpath/logs_volume_subpath configuration
     options are passed to worker pod config
     """
+
     def setUp(self):
         if AirflowKubernetesScheduler is None:
             self.skipTest("kubernetes python package is not installed")
@@ -152,5 +156,62 @@ def test_worker_environment_when_dags_folder_specified(self):
         self.assertEqual(dags_folder, env['AIRFLOW__CORE__DAGS_FOLDER'])
 
 
+class TestKubernetesExecutor(unittest.TestCase):
+    """
+    Tests if an ApiException from the Kube Client will cause the task to
+    be rescheduled.
+    """
+    @unittest.skipIf(AirflowKubernetesScheduler is None,
+                     'kubernetes python package is not installed')
+    @mock.patch('airflow.contrib.executors.kubernetes_executor.KubernetesJobWatcher')
+    @mock.patch('airflow.contrib.executors.kubernetes_executor.get_kube_client')
+    def test_run_next_exception(self, mock_get_kube_client, mock_kubernetes_job_watcher):
+
+        # When a quota is exceeded this is the ApiException we get
+        r = HTTPResponse()
+        r.body = {
+            "kind": "Status",
+            "apiVersion": "v1",
+            "metadata": {},
+            "status": "Failure",
+            "message": "pods \"podname\" is forbidden: " +
+            "exceeded quota: compute-resources, " +
+            "requested: limits.memory=4Gi, " +
+            "used: limits.memory=6508Mi, " +
+            "limited: limits.memory=10Gi",
+            "reason": "Forbidden",
+            "details": {"name": "podname", "kind": "pods"},
+            "code": 403},
+        r.status = 403
+        r.reason = "Forbidden"
+
+        # A mock kube_client that throws errors when making a pod
+        mock_kube_client = mock.patch('kubernetes.client.CoreV1Api', autospec=True)
+        mock_kube_client.create_namespaced_pod = mock.MagicMock(
+            side_effect=ApiException(http_resp=r))
+        mock_get_kube_client.return_value = mock_kube_client
+
+        kubernetesExecutor = KubernetesExecutor()
+        kubernetesExecutor.start()
+
+        # Execute a task while the Api Throws errors
+        try_number = 1
+        kubernetesExecutor.execute_async(key=('dag', 'task', datetime.utcnow(), try_number),
+                                         command='command', executor_config={})
+        kubernetesExecutor.sync()
+        kubernetesExecutor.sync()
+
+        mock_kube_client.create_namespaced_pod.assert_called()
+        self.assertFalse(kubernetesExecutor.task_queue.empty())
+
+        # Disable the ApiException
+        mock_kube_client.create_namespaced_pod.side_effect = None
+
+        # Execute the task without errors should empty the queue
+        kubernetesExecutor.sync()
+        mock_kube_client.create_namespaced_pod.assert_called()
+        self.assertTrue(kubernetesExecutor.task_queue.empty())
+
+
 if __name__ == '__main__':
     unittest.main()


 

----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on GitHub and use the
URL above to go to the specific comment.
 
For queries about this service, please contact Infrastructure at:
users@infra.apache.org

              </div></li></ol></div></div></html>