<!DOCTYPE html><html><div class="item-title">
        Item 125
      </div> <div class="item-details"><div><b>git_comments:</b> <ol></ol></div><div><b>git_commits:</b> <ol><li><div><div><b>summary:</b> svn merge -c 1392466 FIXES: HADOOP-8851. Use -XX:+HeapDumpOnOutOfMemoryError JVM option in the forked tests. Contributed by Ivan A. Veselovsky.
                </div><div><b>message:</b> svn merge -c 1392466 FIXES: HADOOP-8851. Use -XX:+HeapDumpOnOutOfMemoryError JVM option in the forked tests. Contributed by Ivan A. Veselovsky.


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.23@1392521 13f79535-47bb-0310-9956-ffa450edef68

                </div></div></li></ol></div><div><b>github_issues:</b> <ol></ol></div><div><b>github_issues_comments:</b> <ol></ol></div><div><b>github_pulls:</b> <ol></ol></div><div><b>github_pulls_comments:</b> <ol></ol></div><div><b>github_pulls_reviews:</b> <ol></ol></div><div><b>jira_issues:</b> <ol><li><div><div><b>summary:</b> Use -XX:+HeapDumpOnOutOfMemoryError JVM option in the forked tests
                </div><div><b>description:</b> This can help to reveal the cause of issue in the event of OOME in tests.
Suggested patch attached.
                </div></div></li></ol></div><div><b>jira_issues_comments:</b> <ol><li><div>
                Submitting so precommit build runs
              </div></li><li><div>
                {color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12546707/HADOOP-8851-vs-trunk.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1527//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1527//console

This message is automatically generated.
              </div></li><li><div>
                This is the change in pom.xml maven config, it should not require new or modified tests.
              </div></li><li><div><div><b>body:</b> Hi Ivan, can you comment on what testing you've done of this patch? Did you perhaps modify a test to artificially induce an OOME and then observe that the heap dump showed up in the test output? For that matter, where does the heap dump show up? On the console? In some test output file?
                </div><div><b>label:</b> test
                </div></div></li><li><div>
                For example, add the following test:

  /**
   * Test to OOME: with the -XX:+HeapDumpOnOutOfMemoryError option the mem dump should be created by the JVM.   
   * @throws Exception
   */
  public void testOOME() throws Exception {
    final List&lt;Object&gt; list = new LinkedList&lt;Object&gt;();
    while (true) {
      Object placeHolder = new HashMap&lt;Object,Object&gt;();
      list.add(placeHolder);
    }
  }

Typical output will look like the following:
-----
Running org.apache.hadoop.fs.permission.TestStickyBit
java.lang.OutOfMemoryError: Java heap space
Dumping heap to java_pid14838.hprof ...
Heap dump file created [1515333529 bytes in 21.641 secs]
Tests run: 4, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 85.68 sec &lt;&lt;&lt; FAILURE!
-----

The heap dump (this is a huge binary file) will be named java_pid&lt;process_pid&gt;.hprof, and will be created by JVM in the current directory of the test run process (e.g. .../hadoop-common/hadoop-hdfs-project/hadoop-hdfs/ in my case). The heap dump can be opened and investigated with almost any profiler, including NetBeans.

Note, however, that the "-XX" ( http://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html ) are HostSpot options, they may not work on other JVM implementations. 
But, afaik, most of the testing is done on Orecle's JVMs 1.6.0_XX, so the option will work and will be helpful in case of OOME problems. 
As experience shows, if there are no OOMEs, this option does not appear to introduce any problems or performance penalties.
              </div></li><li><div>
                If you're using Jenkins (Hudson) builds, also it's good idea to save **/*.hprof artifacts to protect the memory dumps from being deleted upon the workspace cleanup. 
              </div></li><li><div>
                Thanks a lot for the info, Ivan, and for testing out the patch. I've also just tested out this option with OpenJDK and confirmed that it works similarly to the Sun JDK.

I'm going to go ahead and commit this shortly.
              </div></li><li><div>
                I've just committed this to trunk and branch-2.

Thanks a lot for the contribution, Ivan.
              </div></li><li><div>
                Integrated in Hadoop-Hdfs-trunk-Commit #2861 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Commit/2861/])
    HADOOP-8851. Use -XX:+HeapDumpOnOutOfMemoryError JVM option in the forked tests. Contributed by Ivan A. Veselovsky. (Revision 1392466)

     Result = SUCCESS
atm : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;view=rev&amp;rev=1392466
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-project/pom.xml

              </div></li><li><div>
                Integrated in Hadoop-Common-trunk-Commit #2798 (See [https://builds.apache.org/job/Hadoop-Common-trunk-Commit/2798/])
    HADOOP-8851. Use -XX:+HeapDumpOnOutOfMemoryError JVM option in the forked tests. Contributed by Ivan A. Veselovsky. (Revision 1392466)

     Result = SUCCESS
atm : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;view=rev&amp;rev=1392466
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-project/pom.xml

              </div></li><li><div>
                Integrated in Hadoop-Mapreduce-trunk-Commit #2820 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Commit/2820/])
    HADOOP-8851. Use -XX:+HeapDumpOnOutOfMemoryError JVM option in the forked tests. Contributed by Ivan A. Veselovsky. (Revision 1392466)

     Result = FAILURE
atm : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;view=rev&amp;rev=1392466
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-project/pom.xml

              </div></li><li><div>
                I pulled this into branch-0.23 too
              </div></li><li><div>
                Integrated in Hadoop-Hdfs-0.23-Build #392 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Build/392/])
    svn merge -c 1392466 FIXES: HADOOP-8851. Use -XX:+HeapDumpOnOutOfMemoryError JVM option in the forked tests. Contributed by Ivan A. Veselovsky. (Revision 1392521)

     Result = UNSTABLE
bobby : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;view=rev&amp;rev=1392521
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-project/pom.xml

              </div></li><li><div>
                Integrated in Hadoop-Hdfs-trunk #1183 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1183/])
    HADOOP-8851. Use -XX:+HeapDumpOnOutOfMemoryError JVM option in the forked tests. Contributed by Ivan A. Veselovsky. (Revision 1392466)

     Result = SUCCESS
atm : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;view=rev&amp;rev=1392466
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-project/pom.xml

              </div></li><li><div>
                Integrated in Hadoop-Mapreduce-trunk #1214 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1214/])
    HADOOP-8851. Use -XX:+HeapDumpOnOutOfMemoryError JVM option in the forked tests. Contributed by Ivan A. Veselovsky. (Revision 1392466)

     Result = FAILURE
atm : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;view=rev&amp;rev=1392466
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-project/pom.xml

              </div></li></ol></div></div></html>