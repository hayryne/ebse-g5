<!DOCTYPE html><html><div class="item-title">
        Item 199
      </div> <div class="item-details"><div><b>git_comments:</b> <ol><li><div>
                *
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 
              </div></li><li><div>
                *
 * The primary key of a record. Note that the value used in the primary key must be single-value.
 
              </div></li></ol></div><div><b>git_commits:</b> <ol><li><div><div><b>summary:</b> Add the primary key reading from the GenericRow (#6102)
                </div><div><b>message:</b> Add the primary key reading from the GenericRow (#6102)

Part of a series of PRs for #4261
                </div></div></li></ol></div><div><b>github_issues:</b> <ol><li><div><div><b>title:</b> implement upsert support on pinot
                </div><div><b>body:</b> Pinot is a distributed real-time OLAP engine that can provide second-level data freshness by ingesting kafka events and capacity to manage months of historical data load from various data sources such as HDFS, schemaless, etc. However, Pinot right now mostly functions as an append-only storage system. It doesn’t allow modify/delete of existing records with the exception of overriding all data within a time range with offline tables. This limits the applicability of pinot system due to a lot of use-cases requiring updates to their data due to the nature of their events or needs for data correction/backfill. In order to extend the capacity of pinot and serve more use-cases, we are going to implement the upsert features in Pinot which allows users to update existing records in Pinot tables with its kafka data input stream.

Some initial requirements for the upsert projects:

1. Only support for full update to pinot event

2. Only support for Kafka-compatible queue ingestion model

3. Single pinot server/table can handle 10k/sec ingestion message rate

4. Each pinot server can handle 1 Billion records or 1TB storage

5. Ingestion latency overhead compared to non-upsert model &lt; 1min

6. Query latency overhead compared to non-upsert model &lt; 50%

7. Data retention &lt; 2 weeks

                </div><div><b>label:</b> code-design
                </div></div></li><li><div><div><b>title:</b> implement upsert support on pinot
                </div><div><b>body:</b> Pinot is a distributed real-time OLAP engine that can provide second-level data freshness by ingesting kafka events and capacity to manage months of historical data load from various data sources such as HDFS, schemaless, etc. However, Pinot right now mostly functions as an append-only storage system. It doesn’t allow modify/delete of existing records with the exception of overriding all data within a time range with offline tables. This limits the applicability of pinot system due to a lot of use-cases requiring updates to their data due to the nature of their events or needs for data correction/backfill. In order to extend the capacity of pinot and serve more use-cases, we are going to implement the upsert features in Pinot which allows users to update existing records in Pinot tables with its kafka data input stream.

Some initial requirements for the upsert projects:

1. Only support for full update to pinot event

2. Only support for Kafka-compatible queue ingestion model

3. Single pinot server/table can handle 10k/sec ingestion message rate

4. Each pinot server can handle 1 Billion records or 1TB storage

5. Ingestion latency overhead compared to non-upsert model &lt; 1min

6. Query latency overhead compared to non-upsert model &lt; 50%

7. Data retention &lt; 2 weeks

                </div><div><b>label:</b> documentation
                </div></div></li><li><div><div><b>title:</b> implement upsert support on pinot
                </div><div><b>body:</b> Pinot is a distributed real-time OLAP engine that can provide second-level data freshness by ingesting kafka events and capacity to manage months of historical data load from various data sources such as HDFS, schemaless, etc. However, Pinot right now mostly functions as an append-only storage system. It doesn’t allow modify/delete of existing records with the exception of overriding all data within a time range with offline tables. This limits the applicability of pinot system due to a lot of use-cases requiring updates to their data due to the nature of their events or needs for data correction/backfill. In order to extend the capacity of pinot and serve more use-cases, we are going to implement the upsert features in Pinot which allows users to update existing records in Pinot tables with its kafka data input stream.

Some initial requirements for the upsert projects:

1. Only support for full update to pinot event

2. Only support for Kafka-compatible queue ingestion model

3. Single pinot server/table can handle 10k/sec ingestion message rate

4. Each pinot server can handle 1 Billion records or 1TB storage

5. Ingestion latency overhead compared to non-upsert model &lt; 1min

6. Query latency overhead compared to non-upsert model &lt; 50%

7. Data retention &lt; 2 weeks

                </div><div><b>label:</b> documentation
                </div></div></li><li><div><div><b>title:</b> implement upsert support on pinot
                </div><div><b>body:</b> Pinot is a distributed real-time OLAP engine that can provide second-level data freshness by ingesting kafka events and capacity to manage months of historical data load from various data sources such as HDFS, schemaless, etc. However, Pinot right now mostly functions as an append-only storage system. It doesn’t allow modify/delete of existing records with the exception of overriding all data within a time range with offline tables. This limits the applicability of pinot system due to a lot of use-cases requiring updates to their data due to the nature of their events or needs for data correction/backfill. In order to extend the capacity of pinot and serve more use-cases, we are going to implement the upsert features in Pinot which allows users to update existing records in Pinot tables with its kafka data input stream.

Some initial requirements for the upsert projects:

1. Only support for full update to pinot event

2. Only support for Kafka-compatible queue ingestion model

3. Single pinot server/table can handle 10k/sec ingestion message rate

4. Each pinot server can handle 1 Billion records or 1TB storage

5. Ingestion latency overhead compared to non-upsert model &lt; 1min

6. Query latency overhead compared to non-upsert model &lt; 50%

7. Data retention &lt; 2 weeks

                </div></div></li><li><div><div><b>title:</b> implement upsert support on pinot
                </div><div><b>body:</b> Pinot is a distributed real-time OLAP engine that can provide second-level data freshness by ingesting kafka events and capacity to manage months of historical data load from various data sources such as HDFS, schemaless, etc. However, Pinot right now mostly functions as an append-only storage system. It doesn’t allow modify/delete of existing records with the exception of overriding all data within a time range with offline tables. This limits the applicability of pinot system due to a lot of use-cases requiring updates to their data due to the nature of their events or needs for data correction/backfill. In order to extend the capacity of pinot and serve more use-cases, we are going to implement the upsert features in Pinot which allows users to update existing records in Pinot tables with its kafka data input stream.

Some initial requirements for the upsert projects:

1. Only support for full update to pinot event

2. Only support for Kafka-compatible queue ingestion model

3. Single pinot server/table can handle 10k/sec ingestion message rate

4. Each pinot server can handle 1 Billion records or 1TB storage

5. Ingestion latency overhead compared to non-upsert model &lt; 1min

6. Query latency overhead compared to non-upsert model &lt; 50%

7. Data retention &lt; 2 weeks

                </div></div></li><li><div><div><b>title:</b> implement upsert support on pinot
                </div><div><b>body:</b> Pinot is a distributed real-time OLAP engine that can provide second-level data freshness by ingesting kafka events and capacity to manage months of historical data load from various data sources such as HDFS, schemaless, etc. However, Pinot right now mostly functions as an append-only storage system. It doesn’t allow modify/delete of existing records with the exception of overriding all data within a time range with offline tables. This limits the applicability of pinot system due to a lot of use-cases requiring updates to their data due to the nature of their events or needs for data correction/backfill. In order to extend the capacity of pinot and serve more use-cases, we are going to implement the upsert features in Pinot which allows users to update existing records in Pinot tables with its kafka data input stream.

Some initial requirements for the upsert projects:

1. Only support for full update to pinot event

2. Only support for Kafka-compatible queue ingestion model

3. Single pinot server/table can handle 10k/sec ingestion message rate

4. Each pinot server can handle 1 Billion records or 1TB storage

5. Ingestion latency overhead compared to non-upsert model &lt; 1min

6. Query latency overhead compared to non-upsert model &lt; 50%

7. Data retention &lt; 2 weeks

                </div></div></li><li><div><div><b>title:</b> implement upsert support on pinot
                </div><div><b>body:</b> Pinot is a distributed real-time OLAP engine that can provide second-level data freshness by ingesting kafka events and capacity to manage months of historical data load from various data sources such as HDFS, schemaless, etc. However, Pinot right now mostly functions as an append-only storage system. It doesn’t allow modify/delete of existing records with the exception of overriding all data within a time range with offline tables. This limits the applicability of pinot system due to a lot of use-cases requiring updates to their data due to the nature of their events or needs for data correction/backfill. In order to extend the capacity of pinot and serve more use-cases, we are going to implement the upsert features in Pinot which allows users to update existing records in Pinot tables with its kafka data input stream.

Some initial requirements for the upsert projects:

1. Only support for full update to pinot event

2. Only support for Kafka-compatible queue ingestion model

3. Single pinot server/table can handle 10k/sec ingestion message rate

4. Each pinot server can handle 1 Billion records or 1TB storage

5. Ingestion latency overhead compared to non-upsert model &lt; 1min

6. Query latency overhead compared to non-upsert model &lt; 50%

7. Data retention &lt; 2 weeks

                </div></div></li></ol></div><div><b>github_issues_comments:</b> <ol><li><div><div><b>body:</b> summary on 1st discussion of upsert design (May 15th):

1. @Jackie-Jiang points out that current design of rewriting queries for upsert table is problematic as this cause too much overhead in pinot query process with so many or-conditions. We should look into method to reduce the query overhead in upsert table

2. We should look into message delivery from coordinator service to pinot server. @Jackie-Jiang proposed methods on re-using existing download API on coordinator service to deliver messages from coordinator to server for unified API.

3. How to handle kafka topic partition change. @mcvsubbu suggested that we should look into how to handle accidental expand of kafka topic if that happens.
                </div><div><b>label:</b> code-design
                </div></div></li><li><div><div><b>body:</b> @jamesyfshao can you add a pointer to your design doc in this issue? thanks
                </div><div><b>label:</b> documentation
                </div></div></li><li><div><div><b>body:</b> &gt; @jamesyfshao can you add a pointer to your design doc in this issue? thanks

please use this design doc for now https://docs.google.com/document/d/1SFFir7ByxCff-aVYxQeTHpNhPXeP5q7P4g_6O2iNGgU/edit. We might have permission issue for new ppl as it is still WIP to keep the discussion more organized. Once it is more close to "ready" state I will put it on apache site
                </div><div><b>label:</b> documentation
                </div></div></li><li><div>
                It has been a while since the upsert work started. We'd like to reflect on the challenges encountered, share some learnings and also a [revisit on the upsert design](https://docs.google.com/document/d/1qljEMndPMxbbKtjlVn9mn2toz7Qrk0TGQsHLfI--7h8/edit#heading=h.lsfmyoyyxtgt). 

              </div></li><li><div>
                Added the docs at https://docs.pinot.apache.org/basics/data-import/upsert
              </div></li></ol></div><div><b>github_pulls:</b> <ol><li><div><div><b>title:</b> Add the primary key reading from the GenericRow
                </div><div><b>body:</b> ## Description
Part of a series of PRs for #4261
Check this [doc](https://docs.google.com/document/d/1qljEMndPMxbbKtjlVn9mn2toz7Qrk0TGQsHLfI--7h8/edit#heading=h.lsfmyoyyxtgt) out for the new design

Related to https://github.com/apache/incubator-pinot/pull/6096

                </div></div></li><li><div><div><b>title:</b> Add the primary key reading from the GenericRow
                </div><div><b>body:</b> ## Description
Part of a series of PRs for #4261
Check this [doc](https://docs.google.com/document/d/1qljEMndPMxbbKtjlVn9mn2toz7Qrk0TGQsHLfI--7h8/edit#heading=h.lsfmyoyyxtgt) out for the new design

Related to https://github.com/apache/incubator-pinot/pull/6096

                </div></div></li><li><div><div><b>title:</b> Add the primary key reading from the GenericRow
                </div><div><b>body:</b> ## Description
Part of a series of PRs for #4261
Check this [doc](https://docs.google.com/document/d/1qljEMndPMxbbKtjlVn9mn2toz7Qrk0TGQsHLfI--7h8/edit#heading=h.lsfmyoyyxtgt) out for the new design

Related to https://github.com/apache/incubator-pinot/pull/6096

                </div></div></li><li><div><div><b>title:</b> Add the primary key reading from the GenericRow
                </div><div><b>body:</b> ## Description
Part of a series of PRs for #4261
Check this [doc](https://docs.google.com/document/d/1qljEMndPMxbbKtjlVn9mn2toz7Qrk0TGQsHLfI--7h8/edit#heading=h.lsfmyoyyxtgt) out for the new design

Related to https://github.com/apache/incubator-pinot/pull/6096

                </div></div></li><li><div><div><b>title:</b> Add the primary key reading from the GenericRow
                </div><div><b>body:</b> ## Description
Part of a series of PRs for #4261
Check this [doc](https://docs.google.com/document/d/1qljEMndPMxbbKtjlVn9mn2toz7Qrk0TGQsHLfI--7h8/edit#heading=h.lsfmyoyyxtgt) out for the new design

Related to https://github.com/apache/incubator-pinot/pull/6096

                </div></div></li><li><div><div><b>title:</b> Add the primary key reading from the GenericRow
                </div><div><b>body:</b> ## Description
Part of a series of PRs for #4261
Check this [doc](https://docs.google.com/document/d/1qljEMndPMxbbKtjlVn9mn2toz7Qrk0TGQsHLfI--7h8/edit#heading=h.lsfmyoyyxtgt) out for the new design

Related to https://github.com/apache/incubator-pinot/pull/6096

                </div></div></li><li><div><div><b>title:</b> Add the primary key reading from the GenericRow
                </div><div><b>body:</b> ## Description
Part of a series of PRs for #4261
Check this [doc](https://docs.google.com/document/d/1qljEMndPMxbbKtjlVn9mn2toz7Qrk0TGQsHLfI--7h8/edit#heading=h.lsfmyoyyxtgt) out for the new design

Related to https://github.com/apache/incubator-pinot/pull/6096

                </div></div></li><li><div><div><b>title:</b> Add the primary key reading from the GenericRow
                </div><div><b>body:</b> ## Description
Part of a series of PRs for #4261
Check this [doc](https://docs.google.com/document/d/1qljEMndPMxbbKtjlVn9mn2toz7Qrk0TGQsHLfI--7h8/edit#heading=h.lsfmyoyyxtgt) out for the new design

Related to https://github.com/apache/incubator-pinot/pull/6096

                </div></div></li><li><div><div><b>title:</b> Add the primary key reading from the GenericRow
                </div><div><b>body:</b> ## Description
Part of a series of PRs for #4261
Check this [doc](https://docs.google.com/document/d/1qljEMndPMxbbKtjlVn9mn2toz7Qrk0TGQsHLfI--7h8/edit#heading=h.lsfmyoyyxtgt) out for the new design

Related to https://github.com/apache/incubator-pinot/pull/6096

                </div></div></li><li><div><div><b>title:</b> Add the primary key reading from the GenericRow
                </div><div><b>body:</b> ## Description
Part of a series of PRs for #4261
Check this [doc](https://docs.google.com/document/d/1qljEMndPMxbbKtjlVn9mn2toz7Qrk0TGQsHLfI--7h8/edit#heading=h.lsfmyoyyxtgt) out for the new design

Related to https://github.com/apache/incubator-pinot/pull/6096

                </div></div></li><li><div><div><b>title:</b> Add the primary key reading from the GenericRow
                </div><div><b>body:</b> ## Description
Part of a series of PRs for #4261
Check this [doc](https://docs.google.com/document/d/1qljEMndPMxbbKtjlVn9mn2toz7Qrk0TGQsHLfI--7h8/edit#heading=h.lsfmyoyyxtgt) out for the new design

Related to https://github.com/apache/incubator-pinot/pull/6096

                </div></div></li></ol></div><div><b>github_pulls_comments:</b> <ol><li><div>
                @Jackie-Jiang thanks for the review. Comments addressed.
              </div></li><li><div>
                @Jackie-Jiang done. Thanks for taking another look
              </div></li></ol></div><div><b>github_pulls_reviews:</b> <ol><li><div>
                Cache `primaryKeyColumns.size()` into a local variable
              </div></li><li><div>
                Suggest renaming it to `values`
              </div></li><li><div>
                Suggest renaming it to `_values`
              </div></li><li><div>
                Add some javadoc stating that the values should be SV (MV values won't work for equals and hashcode)
              </div></li><li><div>
                Yes. Table config shall validate this.
              </div></li><li><div>
                (nit)
```suggestion
    int numPrimaryKeyColumns = primaryKeyColumns.size();
    Object[] values = new Object[numPrimaryKeyColumns];
    for (int i = 0; i &lt; numPrimaryKeyColumns; i++) {
```
              </div></li><li><div>
                (nit)
```suggestion
  public PrimaryKey(Object[] values) {
    _values = values;
```
              </div></li></ol></div><div><b>jira_issues:</b> <ol></ol></div><div><b>jira_issues_comments:</b> <ol></ol></div></div></html>