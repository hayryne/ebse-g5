<!DOCTYPE html><html><div class="item-title">
        Item 62
      </div> <div class="item-details"><div><b>git_comments:</b> <ol><li><div>
                *
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 
              </div></li><li><div>
                * Simple tests to ensure this factory is working 
              </div></li></ol></div><div><b>git_commits:</b> <ol><li><div><div><b>summary:</b> LUCENE-2413: consolidate RemoveDuplicatesTokenFilter to contrib/analyzers
                </div><div><b>message:</b> LUCENE-2413: consolidate RemoveDuplicatesTokenFilter to contrib/analyzers

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@940788 13f79535-47bb-0310-9956-ffa450edef68

                </div></div></li></ol></div><div><b>github_issues:</b> <ol></ol></div><div><b>github_issues_comments:</b> <ol></ol></div><div><b>github_pulls:</b> <ol></ol></div><div><b>github_pulls_comments:</b> <ol></ol></div><div><b>github_pulls_reviews:</b> <ol></ol></div><div><b>jira_issues:</b> <ol><li><div><div><b>summary:</b> Consolidate all (Solr's &amp; Lucene's) analyzers into modules/analysis
                </div><div><b>description:</b> We've been wanting to do this for quite some time now...  I think, now that Solr/Lucene are merged, and we're looking at opening an unstable line of development for Solr/Lucene, now is the right time to do it.

A standalone module for all analyzers also empowers apps to separately version the analyzers from which version of Solr/Lucene they use, possibly enabling us to remove Version entirely from the analyzers.

We should also do LUCENE-2309 (decouple, as much as possible, indexer from the analysis API), but I don't think that issue needs to block this consolidation.

Once we do this, there is one place where our users can find all the analyzers that Solr/Lucene provide.
                </div></div></li></ol></div><div><b>jira_issues_comments:</b> <ol><li><div>
                Does consolidation include contrib/icu, too?

Otherwise we still suffer from similar problems, such as you need this filter in contrib/icu to standardize your width differences in CJK text, 
GreekLowerCaseFilter and such that are not really necessary and can be satisfied with case folding, etc.
(and really NFKC_Casefold in my opinion should just replace LowerCaseFilter in every single last one of these analyzers)

              </div></li><li><div>
                Robert: +1
              </div></li><li><div>
                bq. Does consolidation include contrib/icu, too?

+1
              </div></li><li><div>
                bq. Does consolidation include contrib/icu, too?

+1

Especially if we really go the route of individually packaging artifacts for &amp; releasing each component separately.
              </div></li><li><div>
                I played with this issue enough already to realize its gonna be a pain, huge svn movements and lots of changes.

so here's a patch that moves the PorterStemmer to contrib/analyzers... (under the 'en' pkg)... its a start.

I would like to commit tomorrow unless anyone objects.
              </div></li><li><div>
                +1 to doing this in as-baby-steps as we can :)
              </div></li><li><div>
                committed LUCENE-2413_porter.patch revision 940459.
              </div></li><li><div>
                attached is a patch to move ISOLatin1AccentFilter and ASCIIFoldingFilter to contrib (under miscellaneous).

I hacked the analyzing queryparser's test to avoid a dependency 
on contrib analyzers, but gonna need a 'TestAnalyzer' soon.

would like to commit soon unless there are objections
              </div></li><li><div>
                committed LUCENE-2413_folding.patch revision 940591.
              </div></li><li><div>
                Here my patch for LengthFilter and PerFieldAnalyzerWrapper.
              </div></li><li><div>
                Thanks Uwe, the help is appreciated!
              </div></li><li><div><div><b>body:</b> attached is a patch for TeeSink, it moves it to contrib/analyzers/sinks

I moved the test in TestIW (seems to really be unrelated to IW) as-is to 
the TeeSinkTest, it appears from the JIRA issue etc that this is simply 
testing that end() is implemented correctly in TeeSink, and there is 
already a separate test for end() in TestIW.

                </div><div><b>label:</b> test
                </div></div></li><li><div>
                Committed LUCENE-2413-PFAW+LF.patch revision: 940632
              </div></li><li><div>
                Committed LUCENE-2413_teesink.patch revision 940633
              </div></li><li><div>
                attached is a patch that moves some high-level charfilter functionality to contrib/analyzers
so MappingCharFilter,BaseCharFilter,NormalizeCharMap -&gt; o.a.l.analysis.charfilter
              </div></li><li><div>
                Committed LUCENE-2413-charfilter.patch revision 940676.
              </div></li><li><div>
                patch for commongrams(query)filter
              </div></li><li><div>
                Committed LUCENE-2413_commongrams.patch revision 940761.
              </div></li><li><div>
                htmlstripcharfilter -&gt; o.a.l.charfilter.htmlstripcharfilter
              </div></li><li><div>
                Committed LUCENE-2413_htmlstrip.patch revision 940768.
              </div></li><li><div>
                worddelimiterfilter -&gt; analysis.misc.WordDelimiterFilter
              </div></li><li><div>
                Committed LUCENE-2413_wdf.patch revision 940781.
              </div></li><li><div>
                removeDuplicatesTokenFilter -&gt; misc/
              </div></li><li><div>
                Committed LUCENE-2413_removeDups.patch revision 940788.
              </div></li><li><div><div><b>body:</b> this patch moves pattern-based components (PatternReplaceFilter, PatternTokenizer, PatternReplaceCharFilter)
to analysis.pattern package.

the existing PatternAnalyzer in contrib is marked deprecated in favor of this.

additionally, i removed the commons dependency on PatternTokenizer and improved its performance by reusing a stringbuilder (instead of IOUtils.toString), and by not creating new strings for group-matching.

                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                Committed LUCENE-2413_pattern.patch revision 940813
              </div></li><li><div>
                keepwordfilter,trimfilter,hyphenatedwordsfilter -&gt; misc
              </div></li><li><div>
                Committed LUCENE-2413_keep_hyphen_trim.patch revision 940962.
              </div></li><li><div>
                attached is a patch to move synonymfilter/synonymmap into the analyzers module.

didn't deprecate the synonymfilter/synonymmap from contrib/wordnet quite yet.
              </div></li><li><div>
                Committed LUCENE-2413_synonym.patch revision 942827.
              </div></li><li><div>
                attached is a patch that creates a barebones _TestAnalyzer and _TestTokenizer in src/test

These can be used for running lucene tests, so that more analyzers can be moved to the analyzers module.

I didn't convert all tests to use it, only the easy ones so far.
              </div></li><li><div>
                i renamed the test analyzer to MockAnalyzer/Tokenizer at hossman's suggestion...

all tests pass
              </div></li><li><div>
                Committed LUCENE-2413_testanalyzer.patch revision 943288.

By the way, when reviewing I found some disabled queryparser tests: 
{noformat}
-  public void tesStopwordsParsing() throws Exception {
+  public void testStopwordsParsing() throws Exception {
{noformat}

I will re-enable these tests on the 3x branch too.
              </div></li><li><div>
                attached is a patch (LUCENE-2413_tests2.patcH) that adds a "SIMPLE" mode to MockAnalyzer.
I cut over a lot of tests that were previously using SimpleAnalyzer/LowerCaseTokenizer etc to this.

I also added some basic tests for the MockAnalyzer itself (one day we will want to free it from CharTokenizer, etc)
              </div></li><li><div>
                Committed LUCENE-2413_tests2.patch revision 944677
              </div></li><li><div><div><b>body:</b> attached is some cleanup for the mock analyzers tests.

additionally i added a filter for testing, that removes any terms accepted by a DFA.
So you can use this to emulate stopfilter, keepfilter, lengthfilter, ...
Lots of tests need to test this sorta stuff with posIncs.
                </div><div><b>label:</b> test
                </div></div></li><li><div>
                oops, i forgot to svn add.
heres the corrected patch
              </div></li><li><div><div><b>body:</b> Just thinking about MockFilter:
May this much faster than CharArraySet? If we build a DFA out of the stopwords, like done in the MockFilter, and also minimize it, will the checking for a hit not be much faster? e.g. if the first character of the termBuffer does not match the automaton it gets rejected. CAS always has to calculate the hashCode of the whole string first and then look it up.
I would like to see a comparison with a minimized Automaton vs. CAS for StopFilter. OK, LengthFilter is more performant by just comparing TermLength, but the StopFilter should be much faster.
I propose to pass a Set to the StopFilter and internally it converts it to a minimized Automaton similar to MockFilter.
                </div><div><b>label:</b> code-design
                </div></div></li><li><div><div><b>body:</b> bq. May this much faster than CharArraySet

I ran indexing tests a while ago (reuters) with CharArraySet itself implemented with a DFA, and it was slightly faster, but not much. I think this is because english words are usually not very long (average length=5). For other languages this technique might save some cpu time, but there are some "problems" i imagine

# building an automaton from a list of words is more expensive, although Dawid Weiss has implemented an addition to automaton that does this fast.
# in general building automaton and runautomaton etc is more "heavy" i would think, but Mike Mccandless hacked away a lot of this heaviness when we converted to UTF-32.
# the CharacterRunAutomaton is not optimized right now, we disabled the classmap[] for chars because it consume more RAM. I think if we were to care about performance on char[] we should make it classmap 0x0-0xffff and binary search the rest, or something similar. currently it binarysearches on each input character.

Somewhat related, a while ago i tested this with CharArraySet as a DFA, and opened this issue: LUCENE-2227. But obviously this is not the only way, as this example shows filtering on the dfa itself (and not using chararrayset at all). 

So in general, i have those concerns right now, but maybe in the future once some things are addressed we could at least make an optional stopfilter impl or something similar.

One thing i like about this filter personally, is that rejected terms always get (optionally) the posInc increased... I do not think our existing KeepWord or LengthFilters do this, but maybe i am wrong.

                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                Committed LUCENE-2413_mockfilter.patch 944908.

I think now we can move all tests to this framework and pull all the analyzers out.
              </div></li><li><div><div><b>body:</b> attached is a patch that converts over some more tests... need a break and this was a good stopping point.
                </div><div><b>label:</b> test
                </div></div></li><li><div><div><b>body:</b> attached is a patch cutting over a lot more tests.
                </div><div><b>label:</b> test
                </div></div></li><li><div>
                committed LUCENE-2413_tests3.patch revision 944925
committed LUCENE-2413_test4.patch revision 944966
              </div></li><li><div>
                Attached patch (LUCENE-2413_icu.patch) folds contrib/icu into the analyzers module.

Since it depends on an external lib, i set it up as analyzers-icu.jar
              </div></li><li><div>
                Committed LUCENE-2413_icu.patch revision 946590.
              </div></li><li><div>
                this patch (LUCENE-2413_keyword.patch) moves the keywordmarkerfilter out of core into the module.
              </div></li><li><div>
                Committed LUCENE-2413_keyword.patch revision 946621.
              </div></li><li><div>
                contrib/benchmark's NewShingleAnalyzerTask depends on modules' o.a.l.analysis.shingle.ShingleAnalyzerWrapper - causing cyclic dependency between projects - e.g. when creating separate Eclipse projects for lucene and modules. 
              </div></li><li><div>
                {quote}
contrib/benchmark's NewShingleAnalyzerTask depends on modules' o.a.l.analysis.shingle.ShingleAnalyzerWrapper - causing cyclic dependency between projects - e.g. when creating separate Eclipse projects for lucene and modules.
{quote}

Hi, its not a cyclic dependency, as the analyzers module only depends on core lucene. 

If you want to have separate projects I would make the contribs separate, too, or put everything in one eclipse project (this is what I prefer).

              </div></li><li><div>
                By the way, one idea could be to make benchmark a module itself (the benchmarking module for all lucene/solr related stuff).

I noticed Solr lacks a standard benchmarking suite, and at the same time more benchmarks are being created even for
contribs/modules (highlighter, analyzers)

              </div></li><li><div><div><b>body:</b> attached is a patch that pulls out the rest of lucene's concrete analyzers and puts them in the analyzers module.

in order to do this, I had to rearrange demo. Instead i made it contrib/demo, and this really simplified the build system.

                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                Committed LUCENE-2413_coreAnalyzers.patch revision 948195.
              </div></li><li><div>
                moves CharFilter, CharArraySet, and CharArrayMap
              </div></li><li><div>
                Committed LUCENE-2413_coreUtils.patch revision 948225
              </div></li><li><div>
                I found an unchanged package name in a .alg file in contrib/benchmark, and went looking for more similar issues - this patch fixes the directory references and packages I found that were still pointing to the old locations.
              </div></li><li><div>
                Thanks Steven, committed revision 955203 of your patch.
              </div></li><li><div><div><b>body:</b> patch that moves the phonetic, doublemetaphone, and capitalization filters to the analysis module.

with this patch, all concrete analysis components are consolidated and available to both lucene and solr users. 

I think i would like to close this issue and further, more complicated refactorings  (distancing analysis from indexing, moving factories/abstract classes etc) can be done on their own issues.

                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                Committed revision 957162.
              </div></li></ol></div></div></html>