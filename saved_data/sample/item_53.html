<!DOCTYPE html><html><div class="item-title">
        Item 53
      </div> <div class="item-details"><div><b>git_comments:</b> <ol><li><div>
                 check compatibility:
              </div></li><li><div><div><b>comment:</b> * Expert: create a ParallelAtomicReader based on the provided
   *  readers and storedFieldReaders; when a document is
   *  loaded, only storedFieldsReaders will be used. 
                </div><div><b>label:</b> documentation
                </div></div></li><li><div>
                * Create a ParallelAtomicReader based on the provided
   *  readers; auto-closes the given readers on {@link #close()}. 
              </div></li><li><div>
                 Single instance of this, per ParallelReader instance
              </div></li><li><div>
                * Create a ParallelAtomicReader based on the provided
   *  readers. 
              </div></li><li><div>
                 update fieldToReader map
 NOTE: first reader having a given field "wins":
              </div></li><li><div>
                * An {@link AtomicReader} which reads multiple, parallel indexes.  Each index
 * added must have the same number of documents, but typically each contains
 * different fields. Deletions are taken from the first reader.
 * Each document contains the union of the fields of all documents
 * with the same document number.  When searching, matches for a
 * query term are from the first index added that has the field.
 *
 * &lt;p&gt;This is useful, e.g., with collections that have large fields which
 * change rarely and small fields that change more frequently.  The smaller
 * fields may be re-indexed in a new index and both indexes may be searched
 * together.
 * 
 * &lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; It is up to you to make sure all indexes
 * are created and modified the same way. For example, if you add
 * documents to one index, you need to add the same documents in the
 * same order to the other indexes. &lt;em&gt;Failure to do so will result in
 * undefined behavior&lt;/em&gt;.
 
              </div></li><li><div><div><b>comment:</b>  do this finally so any Exceptions occurred before don't affect refcounts:
                </div><div><b>label:</b> code-design
                </div></div></li><li><div><div><b>comment:</b>  Don't call ensureOpen() here (it could affect performance)
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                 get all vectors
              </div></li><li><div>
                *
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 
              </div></li><li><div>
                 throw the first exception
              </div></li><li><div>
                 check compatibility:
              </div></li><li><div><div><b>comment:</b> * Expert: create a ParallelCompositeReader based on the provided
   *  readers and storedFieldReaders; when a document is
   *  loaded, only storedFieldsReaders will be used. 
                </div><div><b>label:</b> documentation
                </div></div></li><li><div>
                 we simply enable closing of subReaders, to prevent incRefs on subReaders
 -&gt; for synthetic subReaders, close() is never called by our doClose()
              </div></li><li><div>
                * Create a ParallelCompositeReader based on the provided
   *  readers; auto-closes the given readers on {@link #close()}. 
              </div></li><li><div><div><b>comment:</b>  do this finally so any Exceptions occurred before don't affect refcounts:
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                * Create a ParallelCompositeReader based on the provided
   *  readers. 
              </div></li><li><div>
                *
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 
              </div></li><li><div>
                * An {@link CompositeReader} which reads multiple, parallel indexes.  Each index added
 * must have the same number of documents, and exactly the same hierarchical subreader structure,
 * but typically each contains different fields. Deletions are taken from the first reader.
 * Each document contains the union of the fields of all
 * documents with the same document number.  When searching, matches for a
 * query term are from the first index added that has the field.
 *
 * &lt;p&gt;This is useful, e.g., with collections that have large fields which
 * change rarely and small fields that change more frequently.  The smaller
 * fields may be re-indexed in a new index and both indexes may be searched
 * together.
 * 
 * &lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; It is up to you to make sure all indexes
 * are created and modified the same way. For example, if you add
 * documents to one index, you need to add the same documents in the
 * same order to the other indexes. &lt;em&gt;Failure to do so will result in
 * undefined behavior&lt;/em&gt;.
 * A good strategy to create suitable indexes with {@link IndexWriter} is to use
 * {@link LogDocMergePolicy}, as this one does not reorder documents
 * during merging (like {@code TieredMergePolicy}) and triggers merges
 * by number of documents per segment. If you use different {@link MergePolicy}s
 * it might happen that the segment structure of your index is no longer predictable.
 
              </div></li><li><div>
                 hierarchically build the same subreader structure as the first CompositeReader with Parallel*Readers:
              </div></li><li><div>
                 we simply enable closing of subReaders, to prevent incRefs on subReaders
 -&gt; for synthetic subReaders, close() is never
 called by our doClose()
              </div></li><li><div>
                 throw the first exception
              </div></li><li><div>
                 close subreaders, ParallelReader will not change refCounts, but close on its own close
              </div></li><li><div>
                 one document only:
              </div></li><li><div>
                 no main readers
              </div></li><li><div>
                 no stored fields at all
              </div></li><li><div>
                 Fields 1 &amp; 2 in one index, 3 &amp; 4 in other, with ParallelReader:
              </div></li><li><div>
                *
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 
              </div></li><li><div>
                 pass
              </div></li><li><div>
                 expected exception
              </div></li><li><div>
                 subreader structure: (1,2,1) 
              </div></li><li><div>
                 Fields 1-4 indexed together:
              </div></li><li><div>
                 this dir has a different subreader structure (1,1,2);
              </div></li><li><div>
                 check that fields are there
              </div></li><li><div>
                 don't close subreaders, so ParallelReader will increment refcounts
              </div></li><li><div>
                 without overlapping
              </div></li><li><div>
                 with overlapping
              </div></li><li><div>
                 check RefCounts
              </div></li><li><div>
                 two documents:
              </div></li><li><div>
                 close subreaders, ParallelReader will not change refCounts, but close on its own close
              </div></li><li><div>
                 no main readers
              </div></li><li><div>
                 pass
              </div></li><li><div>
                 expected exception
              </div></li><li><div>
                 check that fields are there
              </div></li><li><div>
                 don't close subreaders, so ParallelReader will increment refcounts
              </div></li><li><div>
                 without overlapping
              </div></li><li><div>
                 with overlapping
              </div></li><li><div>
                 check RefCounts
              </div></li><li><div>
                 no stored fields at all
              </div></li><li><div>
                 close subreaders, ParallelReader will not change refCounts, but close on its own close
              </div></li><li><div>
                 no main readers
              </div></li><li><div>
                 pass
              </div></li><li><div>
                 expected exception
              </div></li><li><div>
                 check that fields are there
              </div></li><li><div>
                 don't close subreaders, so ParallelReader will increment refcounts
              </div></li><li><div>
                 without overlapping
              </div></li><li><div>
                 with overlapping
              </div></li><li><div>
                 check RefCounts
              </div></li><li><div>
                 no stored fields at all
              </div></li><li><div>
                 create a copy:
              </div></li><li><div>
                 When unpatched, Lucene crashes here with a NoSuchElementException (caused by ParallelTermEnum)
              </div></li><li><div>
                 assert subreaders were closed
              </div></li><li><div>
                 2nd try with a readerless parallel reader
              </div></li></ol></div><div><b>git_commits:</b> <ol><li><div><div><b>summary:</b> LUCENE-3736: ParallelReader was split into ParallelAtomicReader and ParallelCompositeReader. Lucene 3.x's ParallelReader is now ParallelAtomicReader; but the new composite variant has improved performance as it works on the atomic subreaders.
                </div><div><b>message:</b> LUCENE-3736: ParallelReader was split into ParallelAtomicReader and ParallelCompositeReader. Lucene 3.x's ParallelReader is now ParallelAtomicReader; but the new composite variant has improved performance as it works on the atomic subreaders.

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1242924 13f79535-47bb-0310-9956-ffa450edef68

                </div></div></li></ol></div><div><b>github_issues:</b> <ol></ol></div><div><b>github_issues_comments:</b> <ol></ol></div><div><b>github_pulls:</b> <ol></ol></div><div><b>github_pulls_comments:</b> <ol></ol></div><div><b>github_pulls_reviews:</b> <ol></ol></div><div><b>jira_issues:</b> <ol><li><div><div><b>summary:</b> ParallelReader is now atomic, rename to ParallelAtomicReader and also add a ParallelCompositeReader (that requires LogDocMergePolicy to have identical subreader structure)
                </div><div><b>description:</b> The plan is:
- Move all subreaders to ctor (builder-like API. First build reader-set, then call build)
- Rename ParallelReader to ParallelAtomicReader
- Add a ParallelCompositeReader with same builder API, but taking any CompositeReader-set and checks them that they are aligned (docStarts identical). The subreaders are ParallelAtomicReaders.
                </div></div></li></ol></div><div><b>jira_issues_comments:</b> <ol><li><div>
                Here just my cleanup work in ParallelReader, nothing new. It's as before, only "bugs" (missing open checks) fixed and code violations (synthetic accessors, final fields).

The next step will be to remove the add() methods, as IndexReaders should not be changed after create.

Will work more tomorrow.

The plan is:
- Move all subreaders to ctor (builder-like API. First build reader-set, then call build)
- Rename ParallelReader to ParallelAtomicReader
- Add a ParallelCompositeReader with same builder API, but taking any CompositeReader-set and checks them that they are aligned (docStarts identical). The subreaders are ParallelAtomicReaders.
              </div></li><li><div>
                Attached is a patch implementing the above proposal using the builder pattern. The builder pattern (sorry Robert), is the only nice setup that allows to set properties like ignroing stored fields on the parallel readers, but make the built reader unmodifiable!
              </div></li><li><div><div><b>body:</b> There are som test todos: The tests for parallel readers are very simplistic and have only 2 documents (which is especially stupid for composite readers to test them). We should raise number of documents.
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                New patch with javadocs and imporved tests (to check all builder setting).

I will commit this later!
              </div></li><li><div><div><b>body:</b> {quote}
The builder pattern (sorry Robert), is the only nice setup that allows to set properties like ignroing stored fields on the parallel readers, but make the built reader unmodifiable!
{quote}

I think its probably appropriate here, I think immutability for an indexreader subclass is worth the pain :)

But maybe we don't need it to return itself on add()? I don't think building parallelreaders is like building
Strings, I think it can just return void for add()... (I can't think().of().a().situation().where().this() would help code readability)
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                bq. But maybe we don't need it to return itself on add()? 

+1, I would prefer that add() return void.

Otherwise the patch looks great!
              </div></li><li><div><div><b>body:</b> If you look at the test cases, the code is much less verbose and better readable.

The good thing of the builder pattern (remember the class is actually called "Builder") is that nobody is required to use it). But I prefer to chain calls so I want to have the opportunity to do that.

Returning void of itsself is no difference in bytecode or performance, it just adds a possibility. And everybody expects that when he sees a class named "Builder" with a method build().

I().dont().want().to().start().fights().here().again(), but this time I will not change the patch that forces me to use another pattern i dont like. Code without chaining here looks horrible.

Just
rewrite
the
test
,
you
have
to
declare
an
additional
variable
with
a
very
verbose
name
.

If somebody wants to change this, he can do this in another issue called "remove all builders from Lucene", but then please also rename the methods away from build() and rename the classes.
                </div><div><b>label:</b> code-design
                </div></div></li><li><div><div><b>body:</b> Uwe, its not a big deal to me really... just a suggestion.

so +1 to commit, thanks for cleaning up ParallelReader :)
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                Committed trunk revision: 1241470

CHANGES and MIGRATE will be added in parent issue.
              </div></li><li><div><div><b>body:</b> bq. If you look at the test cases, the code is much less verbose and better readable.

Well, you separated each method call onto a separate line, so, it'd
look basically the same without chaining?  If only all chained API
consumers followed your approach...

To be clear: what I dislike about chaining is it creates ambiguity
in how you write the code that consumes our APIs.
You().can().do().this().  Or, you().
can().
do().
this().  Or maybe you().can().
do().this().

Ambiguity is very bad, especially in open-source dev: it invites
bikeshed wars, harming communities by dividing them, spending precious
time debating what from the outside would seem like trivial
differences.

bq. If somebody wants to change this, he can do this in another issue called "remove all builders from Lucene"

The first API I would fix is IndexWriterConfig; its setters should not
be chainable, because now we get code like this:

{noformat}
IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2).setMergePolicy(newLogMergePolicy()));
{noformat}

Code is already hard enough to read... we should not make it even
harder by enabling big hard-to-read compound expressions like this.

This phenomenon is [unfortunately] human nature, and also well outside
of software development; see
http://en.wikipedia.org/wiki/Parkinson's_Law_of_Triviality ... the
less important the ambiguity the more brutal the bike shed wars will
be.  You see this also in Theodor Geisel ("Dr Seuss")'s delightful
Sneetches (the stars on their stomachs), his Butter Battle Book (which
side to butter the bread on), which end of the egg to crack (the
Lilliputians in Gulliver's Travels), etc.  It's not an uncommon
problem :)

Battles over code styling is a great example of this phenomenon, and
fortunately we long ago adopted a standard for Lucene so we don't
argue (much!) about code style.  There is one way and there is no
(little!) ambiguity left.

So I don't want to add any more chainable methods in Lucene.  It
creates an unnecessary ambiguity and I don't like where that will lead
us.  We should reduce ambiguity whenever we can: there should
generally be one obvious way to do something.

                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                Another question: do we even need a ParallelCompositeReader?  Can't we
have only the Builder, and that returns a MultiReader?

              </div></li><li><div>
                Reopening to address the chained APIs...
              </div></li><li><div>
                bq. Another question: do we even need a ParallelCompositeReader? Can't we
have only the Builder, and that returns a MultiReader?

The problem why we need ParallelCompositeReader is that the refCounting and close logic is different. MultiReader will close/refcount its childs, but the ParallelCompositeReader must close/refcount the parallel sub readers. If you return a simple MultiReader, all tests fail, because something is closing the subreaders of the original parallel Composite/DirectoryReaders (as they are closed by the wrappers), but the original CompositeReaders stay open.

If the parallel readers are DirectoryReaders it goes very bad, as the wrapped SegmentReaders are closed...

The change does the following: It returns a BaseMultiReader of ParallelAtomicReaders that wrap e.g. the SegmentReaders of a DirectoryReader. On close it decRefs or closes the original wrapped DirectoryReader, but does not touch the subreaders. In contrast, a normal MultiReader would close/decRef the inner ParallelAtomicReaders, which itsself cose the SegmentReaders they wrap. The DirectoryReaders would still be open.
              </div></li><li><div>
                Patch, removing the chained APIs; I'd like to commit this soon, if there are no objections.  Otherwise I think we should revert the first commit and continue iterating on this issue until we reach agreement.
              </div></li><li><div>
                Please keep the chained APIs, otherwise please also change all toString() methods in whole Lucene to no longer chain and rename all classes to no longer be called Builder with build() as method. If you keep the class names and disallow chaing you break the pattern and that will confuse people more.

For me the issue is closed as I disagree, somebody else can do this :(
              </div></li><li><div>
                bq. Patch, removing the chained APIs

I disagree!
              </div></li><li><div>
                As i stated earlier on the issue, I agree technically with the builder here, for these reasons:
* its not like Document/Field where we worry about making tons of objects in indexing
* as far as immutable objects for IndexReader subclasses, thats a no-brainer from my perspective.
* we need lots of checks that the 'structure' is the same to support per-segment search.

So the only remaining issue is the style... yes I don't personally like chaining, but I gave my
+1 to the patch, because I thought Uwe's argument was reasonable (its true its not enforced),
and because I don't think its worth arguing over for such an expert API (there are bigger wins
when it comes to cleaning up our APIs).

Personally I am glad to Uwe for all this work, we wanted to fix these issues in ParallelReader 
for a long time (LUCENE-2766). It needed a policeman to do this, for all the checks to be correct,
and good javadocs explaining how to make the composite case work.

So maybe we should just open a separate issue for the style? I just feel we would lose so much
if we went back to what we had before this change, I'd really prefer it not be backed out for
that reason.




              </div></li><li><div><div><b>body:</b> I think the changes here are awesome too -- ParallelReader has been
badly unloved for a long time, so I'm very happy we are improving it
here.

But I don't think we need to have chained APIs to achieve that good
progress.  Chained APIS are dangerous.  We added chained APIs in
IndexWriterConfig and I think that was a mistake... it gave us lots of
not-so-readable code.  We shouldn't encourage that and we shouldn't
add more.

                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                OK I opened LUCENE-3756 to address the chained APIs in IndexWriterConfig.
              </div></li><li><div><div><b>body:</b> If somebody wants to commit the changes, do it. I want to be out of that, as I don't want to be responsible when somebody opens an issue that says "Builder pattern without chaining is broken" (which it is). Do what you want but keep me away from it!

Just a suggestion:
- As noted before, a Builder class with a build() method without chaining violates the pattern, so please rename it!

I unassigned from this issue and will take care of some minor AtomicReaderContext changes (to remove one more utility method from ReaderUtil thats useless, if the API would implement what Javadocs say - I am talking about leaves()).
                </div><div><b>label:</b> code-design
                </div></div></li><li><div><div><b>body:</b> As a comment came up on IRC:

{quote}
[17:21]	mikemccand: well... we could also remove the builder
[17:22]	mikemccand: PR is expert
{quote}

IndexReaders are now unmodifiable and I was able to make numDocs, maxDocs,... all final, so reverting the removal of ParallelReader.add() is not an option. I think Robert and I agree here, the old code was too risky - we should fix all of Lucene 4's API to remove not immutable classes where possible.

We can also move Parallel*Reader to contrib, its very special and seldom used :-) The test in facet module is not really needed (I was about to remove it already).


                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                Mike: Here the updated patch for Lucene trunk, as reverse merging of the revert is impossible :(

It was not a good idea to revert before Steven's change...
              </div></li><li><div>
                Thanks Uwe, I'll start from there and iterate...
              </div></li><li><div>
                OK, I started from Uwe's last patch (thanks!) and then replaced the Builder
construction API with straight (normal) constructors.

This way each PR can be created just like MultiReader for the common
case:

{noformat}
  new ParallelAtomicReader(ir1, ir2)
{noformat}

For the expert case you pass in separate arrays for the "normal"
readers and the "stored fields" readers (and boolean for the
"closeSubReaders").  That means the app must create the arrays, but I
think that's fine (Paralel*Reader is already expert, and that ctor is
extra-expert).

Everything else is the same: we now have ParallelAtomicReader and
ParallelCompositReader, it does all the checking to make sure the passed
in atomic/composite readers are "congruent", etc..

              </div></li><li><div>
                Hi Mike,

I attached a new patch with some obsolete code removed: At the times of the builder, to detect errors early, the subreader checks were also not only inspecting the composite subs but also the leaves. As we now have no separation anymore between Builder.add() and the ctor that does the actual work, we can remove the leaves checks, as the recursive ctor will do the same checks, so its impossible to have different leaf structure.
One check could be added instead: currently only maxDocs of subs are compared, maybe also numDocs.... But also here the check is done by the invoked ctors for the wrapped subreaders already.

Otherwise I am not happy with the telescopic ctor (sorry, builder looked better for the expert case - this is now unreadable).

The good thing is that we could add freedom so storedFieldsReaders can be completely separate. It would be easy to implement: closeSubReaders/parallelReaders arrays would need to be an union of both sets (currently only readers ctor param).

I did not know that Collections.newSetFromMap() is already in 1.6. We should remove the util class MapBackedSet in trunk and replace all occurences by the same code like you did. I opened LUCENE-3764 for that.

One small thing for "safety": MultiReader currently clones the reader arrays to prevent external modification. Both ParallelReaders should do the same. The builder enforced that before as you had no access to the subs and the array was cloned on building (copy from ArrayList-&gt;array).
              </div></li><li><div>
                bq. I attached a new patch with some obsolete code removed

Thanks Uwe!

bq. One check could be added instead: currently only maxDocs of subs are compared, maybe also numDocs.... But also here the check is done by the invoked ctors for the wrapped subreaders already.

OK sounds like we can rely on the invoked ctors to catch this.

bq. Otherwise I am not happy with the telescopic ctor (sorry, builder looked better for the expert case - this is now unreadable).

Well, but the common case is simpler?  And, no longer an API break,
besides the name change.  Ie, you create the PAR/PCR like you do on
3.x.  I think that's the right tradeoff (expert case can be more
work...).

I also don't like the API inconsistency this would start (we don't use
builders to create other IndexReaders).

bq. The good thing is that we could add freedom so storedFieldsReaders can be completely separate. It would be easy to implement: closeSubReaders/parallelReaders arrays would need to be an union of both sets (currently only readers ctor param).

True, actually this would be pretty simple now I think?

bq. One small thing for "safety": MultiReader currently clones the reader arrays to prevent external modification. Both ParallelReaders should do the same. The builder enforced that before as you had no access to the subs and the array was cloned on building (copy from ArrayList-&gt;array).

Ahh, right.

I started from your patch, added the array clones, and added the
missing javadocs... I didn't yet add allowing arbitrary
storedFieldsReaders but I think this wouldn't be so hard...

              </div></li><li><div>
                Patch is incomplete? Maybe you forgot to svn add :-)
              </div></li><li><div>
                bq. Patch is incomplete? Maybe you forgot to svn add

Ugh, indeed, sorry.  Fixed!
              </div></li><li><div>
                Thanks, looks fine. I will look tomorrow into a IdentityHashSet on all readers (storedReaders+readers) and use that for incRef/close. Thats the easiest.

One small improvement for shorter code:

You can add all entries from an array to a collection with:
{code:java}
final Set&lt;CompositeReader&gt; readersSet = Collections.newSetFromMap(new IdentityHashMap&lt;CompositeReader,Boolean&gt;());
Collections.addAll(readersSet, readers);
{code}
(it's just shorter)
              </div></li><li><div>
                Hi Mike,

I found a bug in your implementation of the ParallelCompositeReader ctor, the test did not hit this as stupiditly the number of *vertical* segments was 2, but also the number of *parallel* subreaders! You simply got the validation (was before in the builder at the wrong place) iterate over the wrong set (vertical vs. parallel). I did it like for the atomic ones as a validate method.
              </div></li><li><div><div><b>body:</b> Patch that fixes the bugs in Mike's code and also allows decoupled stored fields readers:
- moved the composite reader checks from the main builder loop (where it was wrongly placed) to a validate method acting only on the top-level readers
- I improved the tests to have a different number of documents, subreaders and parallel readers
- Current limitation is only that at least one "searchable" reader must be there, but there can be 0..infinite stored readers
- toString() shows the unique set of parallel readers, unfortunately unsorted (as hashed set)
- I added one more ctor PR(closeSubReaders, IR subs...), this makes code not separating stored fields readers look better, as closeSubReaders is not an expert option.

Mike, can I take the issue again and commit this? Thanks for the refactoring, but as we now allow separate stored fields and main readers, the missing builder is fine to me - grrrr
                </div><div><b>label:</b> code-design
                </div></div></li><li><div><div><b>body:</b> Minor improvements:
- remove compiler warning because of redundant cast
- rename the reader IdentitySet to be consistent in both impls.

I think it's ready to commit.
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                Ooh, nice catch on that validation bug!

Yes, please feel free to take this one back.  Your last patch looks great; I like the new ctor.  +1 to commit.
              </div></li><li><div><div><b>body:</b> A previous discussion on IRC with Mike:

We think that the numDocs checks are not needed and prevent advanced use cases. The whole ParallelReaders structure simply rely on maxDocs identical - not even hasDeletions need to be checked. It should simply be documented that Parallel*Reader takes the liveDocs/hasDeletions from the first reader and ignores livedocs of other readers. 

In 3.x this was more an issue, but in trunk, where liveDocs are completely separated, there is no need to check numDocs.

The checking of numDocs is also no added safety, because 2 readers can have different liveDocs, but still same numDocs.
                </div><div><b>label:</b> documentation
                </div></div></li><li><div>
                New patch without numDocs checks (added javadocs describing that the deletions are taken from first reader). Also improved the tests to handle empty indexes for both reader variants.

I will commit this later!
              </div></li><li><div>
                Looks great Uwe, thanks!  +1
              </div></li><li><div>
                Committed trunk revision: 1242924

Thanks to all for reviewing!
              </div></li><li><div><div><b>body:</b> Here is a patch that improves test coverage and adds one more check to the composite parallel reader ctor:
If somebody has 2 parallel composite readers, while the first one has atomic subreaders but the other one has composite subreaders (but correct maxDocs), the ctor fails with ClassCastEx.

I will commit this now as test improvement.
                </div><div><b>label:</b> test
                </div></div></li><li><div>
                Committed trunk revision: 1245605
              </div></li><li><div><div><b>body:</b> I committed some minor code cleanups in revision: 1245897
                </div><div><b>label:</b> code-design
                </div></div></li><li><div><div><b>body:</b> Robert also found some bugs in ParallelAtomicReader (in fact it was jenkins). Some fixes should be documented here.
                </div><div><b>label:</b> documentation
                </div></div></li><li><div><div><b>body:</b> This is a patch for ParallelAtomicReader (after the heavy commit of Robert, rev. 1291679), I found some other inconsistencies in some tests. One was already fixed (rev 1291753).

The new implementation builds the ParallelFields instance using the FieldsEnums of the parallel readers, which is much more correct than iterating FieldInfos and checking for indexed fields.

The fieldInfos and fieldToReaderMap is now only used for retrieving stored fields and other global information. Fields is now completely separate.
                </div><div><b>label:</b> code-design
                </div></div></li><li><div><div><b>body:</b> {quote}
(after the heavy commit of Robert, rev. 1291679)
{quote}

Hey, maybe only a medium-heavy commit: i did reply to the jenkins failure with a patch to the list before committing :)

{quote}
The new implementation builds the ParallelFields instance using the FieldsEnums of the parallel readers, which is much more correct than iterating FieldInfos and checking for indexed fields.
{quote}

+1, when debugging i was a little confused not just about how it was built but where in the code... I think this is more intuitive!
                </div><div><b>label:</b> code-design
                </div></div></li><li><div><div><b>body:</b> More simplifications (especially cleaned up the test TestParallelTermEnum).

Also added a separate map for term vectors, to improve speed for large indexes with many fields.
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                Committed trunk revision: 1291889
              </div></li></ol></div></div></html>