<!DOCTYPE html><html><div class="item-title">
        Item 42
      </div> <div class="item-details"><div><b>git_comments:</b> <ol><li><div>
                
 * Licensed to the Apache Software Foundation (ASF) under one or more
 *  contributor license agreements.  The ASF licenses this file to You
 * under the Apache License, Version 2.0 (the "License"); you may not
 * use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.  For additional information regarding
 * copyright in this work, please see the NOTICE file in the top level
 * directory of this distribution.
 
              </div></li><li><div>
                *
     * Get an entity deleted task
     * @param collectionScope
     * @param entityId
     * @param version
     * @return
     
              </div></li><li><div>
                *
     * Get a task for cleaning up latent entity data.  If includeVersion = true, the passed version will be cleaned up as well
     * Otherwise this is a V-1 operation
     *
     * @param scope
     * @param entityId
     * @param version
     * @param includeVersion
     * @return
     
              </div></li><li><div>
                *
     * Get an entityVersionCreatedTask
     * @param scope
     * @param entity
     * @return
     
              </div></li><li><div>
                
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 
              </div></li><li><div>
                *
     * Different implementations
     
              </div></li><li><div>
                *
 * A provider to allow users to configure their queue impl via properties
 
              </div></li><li><div>
                
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 
              </div></li><li><div>
                *
     * Offer the indexoperation message.  Some queues may support not returning the future until ack or fail.
     * Other queues may return the future after ack on the offer.  See the implementation documentation for details.
     * @param operation
     
              </div></li><li><div>
                *
     * Mark these message as failed.  Set the exception in the future on local operation
     *
     * @param messages
     
              </div></li><li><div><div><b>comment:</b> *
 * A temporary interface of our buffer Q to decouple of producer and consumer;
 
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 
              </div></li><li><div>
                *
     * Ack all messages so they do not appear again.  Meant for transactional queues, and may or may not be implemented.
     * This will set the future as done in in memory operations
     *
     * @param messages
     
              </div></li><li><div>
                *
     * Perform a take, potentially blocking until up to takesize is available, or timeout has elapsed.
     * May return less than the take size, but will never return null
     *
     * @param takeSize
     * @param timeout
     * @param timeUnit
     * @return A null safe lid
     
              </div></li><li><div>
                we got something, go process it
              </div></li><li><div>
                
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 
              </div></li><li><div>
                if we have a future ack it
              </div></li><li><div>
                try to add more
              </div></li><li><div>
                *
         * Get the message from our queue
         
              </div></li><li><div>
                nothing to do
              </div></li><li><div>
                *
     * Set our TTL to 1 month.  This is high, but in the event of a bug, we want these entries to get removed
     
              </div></li><li><div>
                now see if the key was there
              </div></li><li><div>
                *
 * This is experimental at best.  Our SQS size limit is a problem.  We shouldn't use this for index operation. Only for
 * performing
 
              </div></li><li><div>
                look up the values
              </div></li><li><div><div><b>comment:</b> pretty print, disabling for speed
            mapper.enable(SerializationFeature.INDENT_OUTPUT);
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 
              </div></li><li><div>
                stop our timer
              </div></li><li><div>
                write to cassandra
              </div></li><li><div>
                signal to SQS
              </div></li><li><div>
                no op, just let it retry after the queue timeout
              </div></li><li><div>
                no op
              </div></li><li><div>
                add all our keys  for a single round trip
              </div></li><li><div>
                * Read the object from Base64 string. 
              </div></li><li><div>
                *
     * The name to put in the map
     
              </div></li><li><div>
                SQS doesn't support more than 10
              </div></li><li><div>
                *
     * The message that subclasses our IndexOperationMessage.  holds a pointer to the original message
     
              </div></li><li><div>
                remove it from the map
              </div></li><li><div>
                the entry was not present in cassandra, ignore this message.  Failure should eventually kick it to
 a DLQ
              </div></li><li><div>
                load them into our response
              </div></li><li><div>
                * Write the object to a Base64 string. 
              </div></li><li><div><div><b>comment:</b> * Hacky, copied from CPEntityManager b/c we can't access it here 
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                *
 * Represent the properties required to build an index request
 
              </div></li><li><div>
                
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 
              </div></li><li><div>
                *
 * Represent the properties required to build an index request
 
              </div></li><li><div>
                *
     * DO NOT DELETE!  Required for Jackson
     
              </div></li><li><div>
                
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 
              </div></li><li><div>
                now get it back
              </div></li><li><div>
                de-index request
              </div></li><li><div>
                get the operations out
              </div></li><li><div>
                now ack the message
              </div></li><li><div>
                wait for it to send to SQS
              </div></li><li><div>
                
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 
              </div></li><li><div>
                *
         * Handle the multiple failure junit trace
         
              </div></li><li><div>
                do this so our test gets marked as ignored.  Not pretty, but it works
              </div></li><li><div>
                *
 * Created in an attempt to mark no aws cred tests as ignored.  Blocked by this issue
 * https://github.com/junit-team/junit/issues/116
 *
 * Until then, simply marks as passed, which is a bit dangerous
 
              </div></li><li><div>
                
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 
              </div></li><li><div>
                *
 * Represents a set of entities
 
              </div></li><li><div>
                *
     * Return true if the set is empty
     * @return
     
              </div></li><li><div>
                *
     * Get the entity from the result set
     * @param field, Return the entity with the field
     * @return
     
              </div></li><li><div>
                *
     * Get the number of entities in this set
     * @return
     
              </div></li><li><div>
                If we're the master, register ourselves and move on, if we're not, wait for the master to come up
              </div></li><li><div><div><b>comment:</b>         install(new MapModule());   TODO, re-enable when index module doesn't depend on queue
        install(new QueueModule());
                </div><div><b>label:</b> requirement
                </div></div></li><li><div>
                TODO: can't we just sub in the getEntityRepair method here so for every read of a uniqueEntityField we can verify it is correct?
              </div></li><li><div>
                not op, we're not migrating properly to this.  Make this an event
        // This check is for testing purposes and for a test that to be able to dynamically turn
        // off and on delete previous versions so that it can test clean-up on read.
        if ( System.getProperty( EVENTS_DISABLED, "false" ).equals( "true" )) {
            return;
        }

        logger.debug("Handling versionCreated for entity {}:{} v {} "
            + "scope\n   name: {}\n   owner: {}\n   app: {}",
            new Object[] {
                entity.getId().getType(),
                entity.getId().getUuid(),
                entity.getVersion(),
                scope.getName(),
                scope.getOwner(),
                scope.getApplication()});

        CpEntityManagerFactory cpemf = (CpEntityManagerFactory)emf;
        final EntityIndex ei = cpemf.getManagerCache().getEntityIndex(scope);






        ei.deletePreviousVersions( entity.getId(), entity.getVersion() );
              </div></li><li><div>
                we can't use our candidate result sets here.  The repair won't happen since we now have orphaned documents in our index
us the EM so the repair process happens
              </div></li><li><div>
                    @Test(timeout=30000)
              </div></li><li><div>
                *
        * Go around EntityManager and execute query directly against Core Persistence.
        * Results may include stale index entries.
        
              </div></li><li><div>
                trigger the repair
              </div></li><li><div>
                put this into the top of the queue, once it's acked we've been flushed
              </div></li><li><div>
                *
     * Takes the change and reloads an entity with all changes applied in this entity applied.
     * The resulting entity from calling load will be the previous version of this entity plus
     * the entity in this object applied to it.
     
              </div></li><li><div>
                *
     * Audit a unique field, and remove any stale entries in the system
     * @param field The field to audit within this collection scope.

    public Observable&lt;Integer&gt; auditUniqueField(final Field field);
     
              </div></li><li><div>
                *
 * Represents a set of entities
 
              </div></li><li><div>
                *
     * Return true if the set is empty
     * @return
     
              </div></li><li><div>
                *
     * Get the entity from the result set
     * @param field, Return the entity with the field
     * @return
     
              </div></li><li><div>
                *
     * Get the number of entities in this set
     * @return
     
              </div></li><li><div>
                now loop through and ensure the entities are there.
              </div></li><li><div>
                Load a entity for each entityId we retrieved.
              </div></li><li><div>
                Short circut if we don't have any uniqueValues from the given fields.
              </div></li><li><div><div><b>comment:</b> bad unique value, delete this, it's inconsistent
                </div><div><b>label:</b> code-design
                </div></div></li><li><div><div><b>comment:</b> TODO: explore making this an Async process
We'll repair it again if we have to
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                else add it to our result set
              </div></li><li><div>
                loop through each field, and construct an entity load
              </div></li><li><div>
                Get back set of unique values that correspond to collection of fields
              </div></li><li><div>
                *
     * Retrieves all entities that correspond to each field given in the Collection.
     * @param fields
     * @return
     
              </div></li><li><div>
                 if it's unique, create a function to validate it and add it to the list of
 concurrent validations
 use write-first then read strategy
              </div></li><li><div>
                *
     * Command group used for realtime user commands
     
              </div></li><li><div>
                allocate our max size, worst case
now get the set of fields back
              </div></li><li><div>
                *
    * Load UniqueValue that matches field from collection or null if that value does not exist.
    *
    * @param colScope Collection scope in which to look for field name/value
    * @param consistencyLevel Consistency level of query
    * @param fields Field name/value to search for
    * @return UniqueValueSet containing fields from the collection that exist in cassandra
    * @throws ConnectionException on error connecting to Cassandra
    
              </div></li><li><div>
                verify no entity returned
              </div></li><li><div>
                write an entity with a unique field
              </div></li><li><div>
                try to load via the unique field, should have triggered repair
              </div></li><li><div>
                user the unique serialization to verify it's been deleted from cassandra
              </div></li><li><div>
                do a mark as one test, and a delete as another
              </div></li><li><div>
                if we add a second field we get a second entity that is the exact same. Is this expected?
              </div></li><li><div>
                use the entity serializationStrategy to remove the entity data.
              </div></li><li><div>
                 final StringField expectedString = new StringField( "yes", "fred", true );
              </div></li><li><div>
                 newEntity.setField( expectedString );
              </div></li><li><div>
                verify the entity is correct.
loadReturned );
              </div></li><li><div>
                *
     * Get the currently configured ReadCL that is more consitent than getReadCL
     * @return
     
              </div></li><li><div>
                *
     * Get a gauge and create it
     * @param clazz
     * @param name
     * @param gauge
     * @return
     
              </div></li><li><div>
                *
     *
     * @param metricClass
     * @param klass
     * @param name
     * @return
     
              </div></li><li><div>
                *
     * Get the values for all the keys.  If a value does not exist, it won't be present in the map
     * @param keys
     * @return
     
              </div></li><li><div>
                *
     * Get strings from the map
     * @param keys
     * @return
     
              </div></li><li><div>
                add it to the entry
              </div></li><li><div>
                *
     * Get multiple values, using the string builder
     * @param scope
     * @param keys
     * @param builder
     * @param &lt;T&gt;
     * @return
     
              </div></li><li><div>
                *
     * Callbacks for performing row operations
     
              </div></li><li><div>
                *
         * Write the key
         * @param keysMutation
         
              </div></li><li><div>
                nothing to return
              </div></li><li><div>
                now get all columns, including the "old row key value"
              </div></li><li><div>
                *
     * Build the results from the row keys
     * @param &lt;T&gt;
     
              </div></li><li><div>
                    /**
     * Create a delete method that deletes by Id. This will delete all documents from ES with the same entity Id,
     * effectively removing all versions of an entity from all index scopes
     * @param entityId The entityId to remove
     */
    public Future deleteAllVersionsOfEntity(final Id entityId );

    /**
     * Takes all the previous versions of the current entity and deletes all previous versions
     * @param id The id to remove
     * @param version The max version to retain
     */
    public Future deletePreviousVersions(final Id id, final UUID version);
              </div></li><li><div>
                *
     * Start the consumer
     
              </div></li><li><div>
                *
     * Stop the consumers
     
              </div></li><li><div>
                *
     * Amount of time in milliseconds to wait when ES rejects our request before retrying.  Provides simple
     * backpressure
     
              </div></li><li><div>
                *
     * The queue implementation to use.  Values come from &lt;class&gt;QueueProvider.Implementations&lt;/class&gt;
     
              </div></li><li><div>
                *
     * Amount of time to wait when reading from the queue in milliseconds
     
              </div></li><li><div>
                *
     * The number of worker threads to consume from the queue
     
              </div></li><li><div>
                *
     * Amount of time to wait when reading from the queue
     
              </div></li><li><div>
                give us 60 seconds to process the message
              </div></li><li><div>
                if this has been serialized, it could be null. don't NPE if it is, there's nothing to ack
              </div></li><li><div>
                *
         * No-op, just disregard it
         
              </div></li><li><div><div><b>comment:</b> TODO T.N., this shouldn't live here. This should live at the UG core tier.  However the RM/EM are an absolute mess, so until they're refactored, this is it's home
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                *
     * Get our index info from ES, but clear our cache first
     * @param aliasType
     * @return
     
              </div></li><li><div>
                only wait 2 seconds max
              </div></li><li><div>
                *
     * Loop throught and start the workers
     
              </div></li><li><div>
                the actively running subscription
              </div></li><li><div>
                send the request off to ES
              </div></li><li><div>
                stop consuming
              </div></li><li><div>
                ack after we process
              </div></li><li><div>
                wire up the gauge of inflight messages
              </div></li><li><div>
                start in the background
              </div></li><li><div>
                collection all the operations into a single stream
              </div></li><li><div>
                take since  we're in flight
              </div></li><li><div>
                name our thread so it's easy to see
              </div></li><li><div>
                *
     * Stop the workers
     
              </div></li><li><div>
                release  so we know we've done processing
              </div></li><li><div>
                *
     * clean up cache
     
              </div></li><li><div><div><b>comment:</b> TODO T.N. Remove this when we move the cursor mapping back to core
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                *
     * Create the SQS client for the specified settings
     
              </div></li><li><div>
                *
     * Get the region
     * @return
     
              </div></li><li><div><div><b>comment:</b> pretty print, disabling for speed
            mapper.enable(SerializationFeature.INDENT_OUTPUT);
                </div><div><b>label:</b> code-design
                </div></div></li><li><div><div><b>comment:</b> the amazon client is not thread safe, we need to create one per queue
                </div><div><b>label:</b> requirement
                </div></div></li><li><div>
                no op, swallow
              </div></li><li><div>
                *
     * Mark tests as ignored if now AWS creds are present
     
              </div></li><li><div>
                 EntityRef ref = em.getAlias( getEntityType(), name );
              </div></li><li><div>
                 usergrid-2389: User defined limit in the query is ignored. Fixed it by following
 usergrid-2389: User defined limit in the query is ignored. Fixed it by adding
              </div></li></ol></div><div><b>git_commits:</b> <ol><li><div><div><b>summary:</b> Merge branch 'two-dot-o' into USERGRID-405
                </div><div><b>message:</b> Merge branch 'two-dot-o' into USERGRID-405

Conflicts:
	stack/core/src/main/java/org/apache/usergrid/corepersistence/CoreModule.java
	stack/core/src/main/java/org/apache/usergrid/corepersistence/events/EntityVersionDeletedHandler.java
	stack/corepersistence/collection/src/main/java/org/apache/usergrid/persistence/collection/EntityCollectionManager.java
	stack/corepersistence/collection/src/main/java/org/apache/usergrid/persistence/collection/guice/CollectionModule.java
	stack/corepersistence/collection/src/main/java/org/apache/usergrid/persistence/collection/impl/EntityCollectionManagerFactoryImpl.java
	stack/corepersistence/collection/src/main/java/org/apache/usergrid/persistence/collection/impl/EntityCollectionManagerImpl.java
	stack/corepersistence/collection/src/main/java/org/apache/usergrid/persistence/collection/impl/EntityDeletedTask.java
	stack/corepersistence/collection/src/main/java/org/apache/usergrid/persistence/collection/impl/EntityVersionCleanupTask.java
	stack/corepersistence/collection/src/main/java/org/apache/usergrid/persistence/collection/serialization/UniqueValueSerializationStrategy.java
	stack/corepersistence/collection/src/main/java/org/apache/usergrid/persistence/collection/serialization/impl/UniqueValueSerializationStrategyImpl.java
	stack/corepersistence/collection/src/main/java/org/apache/usergrid/persistence/collection/util/EntityUtils.java
	stack/corepersistence/collection/src/test/java/org/apache/usergrid/persistence/collection/impl/EntityVersionCleanupTaskTest.java
	stack/corepersistence/graph/src/main/java/org/apache/usergrid/persistence/graph/impl/GraphManagerImpl.java
	stack/corepersistence/map/src/main/java/org/apache/usergrid/persistence/map/MapManager.java
	stack/corepersistence/queryindex/src/test/java/org/apache/usergrid/persistence/index/guice/TestIndexModule.java

                </div></div></li></ol></div><div><b>github_issues:</b> <ol></ol></div><div><b>github_issues_comments:</b> <ol></ol></div><div><b>github_pulls:</b> <ol></ol></div><div><b>github_pulls_comments:</b> <ol></ol></div><div><b>github_pulls_reviews:</b> <ol></ol></div><div><b>jira_issues:</b> <ol><li><div><div><b>summary:</b> Fix hotspot from continuous writes of entities (Shawn)
                </div><div><b>description:</b> Currently, performing a continuous PUT in 2.0 under heavy load causes a hotspot in our cassandra data.  

Cause:

# Under load, entities can be PUT continuously
# Asynchronous cleanups run and delete previous versions
# These versions are retained in cassandra for long periods of time.  This causes severe row bloating before compaction occurs.

Solution:

For entity data, we only care about the current max version.  We should change this column family to store only the maximum data format.  We will need to keep the log of previous versions, so that we can bring ES into a consistent state

                </div></div></li></ol></div><div><b>jira_issues_comments:</b> <ol><li><div>
                I'm going to branch off of 381 since we should only perform this migration once.
              </div></li><li><div>
                Current impl branch
              </div></li><li><div><div><b>body:</b> We also have to create a unique property ledger.  We're going to need to follow the same pattern, however, we can restrict the size of the input, greatly reducing this problem of load since we'll only be storing a single property, not the entire entity.


                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                GitHub user tnine opened a pull request:

    https://github.com/apache/incubator-usergrid/pull/175

    quite ready Usergrid 405

    Merge of USERGRID-405, USERGRID-427, andUSERGRID-381.
    
    Address most of USERGRID-365.


You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/apache/incubator-usergrid USERGRID-405

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/incubator-usergrid/pull/175.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #175
    
----
commit ee676e78ad8f1905a169a027eb97aa7b1dc7aa7a
Author: Shawn Feldman &lt;sfeldman@apache.org&gt;
Date:   2015-01-29T18:46:01Z

    added new entity object for serialization
    
    add new guide interface names
    
    fix compile issues in core persistence
    
    add array field instead of list field
    
    adding proxies to new storage
    
    spacing changes
    
    fixed id problems
    
    remove excess fields
    
    Test are passing
    
    pushing migrations into core persistence
    
    pushing migrations into core persistence
    
    moving dependencies to core persistence
    
    moving dependencies to core persistence
    
    moving dependencies to core persistence
    
    add DataMigrationManagers
    
    Rename Serialization Strategy Proxy
    
    tests passing in core persistence
    
    Refactor Application Entity Group
    
    fixed null issue with index
    
    remove observable

commit fa82c6dc00cbfa58d7f12e56bdc757bdc4ae4b0c
Author: Shawn Feldman &lt;sfeldman@apache.org&gt;
Date:   2015-02-11T17:51:29Z

    add logic to continue alias buildout despite issues removing

commit 29f24a9716086da70d11f3b5d9839280c5ffc650
Author: Todd Nine &lt;tnine@apigee.com&gt;
Date:   2015-02-11T21:18:07Z

    Fixed index alias cache invalidation

commit 4781c4088e282ae1671d590f75fb3546fb8ab944
Author: Shawn Feldman &lt;sfeldman@apache.org&gt;
Date:   2015-02-12T00:16:03Z

    adding condition; not sure this is correct

commit 2f8993af9d1bcdd09153880b3fe317ed4149d899
Author: Shawn Feldman &lt;sfeldman@apache.org&gt;
Date:   2015-02-12T20:15:14Z

    fix tests

commit d439036089ec547648338429e8146073fbf70af0
Author: Shawn Feldman &lt;sfeldman@apache.org&gt;
Date:   2015-02-12T21:01:35Z

    change logging

commit 07f6cfedac9d5394c69c6c62355f6830bb37d2f2
Author: Shawn Feldman &lt;sfeldman@apache.org&gt;
Date:   2015-02-12T21:02:31Z

    remove connections

commit ba189eaf933a6209810f1e72dde80bfe972f288b
Author: Shawn Feldman &lt;sfeldman@apache.org&gt;
Date:   2015-02-12T22:27:55Z

    merged

commit 35b95fd14d1792eb6a51dd9f4a3373d241469fc6
Author: Shawn Feldman &lt;sfeldman@apache.org&gt;
Date:   2015-02-13T16:26:26Z

    fix test

commit f1b0c8d864042ccc0481550ae3a48f4fb5da874e
Author: Shawn Feldman &lt;sfeldman@apache.org&gt;
Date:   2015-02-13T18:32:01Z

    adding generic to prevent casting at low levels

commit 4657c8df7f150f108dfc77af66efd54c034042d3
Author: Shawn Feldman &lt;sfeldman@apache.org&gt;
Date:   2015-02-13T22:04:46Z

    reimplemented filtering for migrations

commit db2585ec2671c4722b97adb88afdc55b54b120cd
Author: Shawn Feldman &lt;sfeldman@apache.org&gt;
Date:   2015-02-13T22:28:01Z

    cp tests passing

commit e5224695202fd5533ea027964f7fc0e515f50678
Author: Shawn Feldman &lt;sfeldman@apache.org&gt;
Date:   2015-02-13T23:04:59Z

    tests passing again

commit 79ec9787c185b3e1a43aba5f456b5568b5735235
Author: Shawn Feldman &lt;sfeldman@apache.org&gt;
Date:   2015-02-16T18:07:55Z

    adding specific migration types

commit dab3ee0f39ca5214c04647953a0783f4fdd692ba
Author: Shawn Feldman &lt;sfeldman@apache.org&gt;
Date:   2015-02-16T18:18:04Z

    test fix

commit eace1cdc4396fe80d3da55639ce4e6932132175c
Author: Shawn Feldman &lt;sfeldman@apache.org&gt;
Date:   2015-02-16T18:18:23Z

    Merge branch 'USERGRID-273' of https://git-wip-us.apache.org/repos/asf/incubator-usergrid into USERGRID-365

commit ed20408b7bfce4d0006c0e084adca0a7e97da34e
Author: Shawn Feldman &lt;sfeldman@apache.org&gt;
Date:   2015-02-16T18:47:01Z

    Move migrations to common interface

commit 59777e5952c31f570273ddc94e5e569bdefad468
Author: Shawn Feldman &lt;sfeldman@apache.org&gt;
Date:   2015-02-16T20:31:44Z

    add routing mapping

commit 90950908019f131f5874f635af7ece235bea2ce1
Author: Shawn Feldman &lt;sfeldman@apache.org&gt;
Date:   2015-02-16T21:57:32Z

    merge 365-273

commit 4e143574640e7ec7bb7e288191f24e816862c9d9
Author: Shawn Feldman &lt;sfeldman@apache.org&gt;
Date:   2015-02-16T21:58:01Z

    Merge branch 'USERGRID-273' of https://git-wip-us.apache.org/repos/asf/incubator-usergrid into USERGRID-365

commit 748636873e7ba480949294e5a4b3fb1f7dafdc2c
Author: Shawn Feldman &lt;sfeldman@apache.org&gt;
Date:   2015-02-16T22:41:26Z

    remove writestart when there is no version

commit 904c5ddff43813b7eb9a273c46b11346853207db
Author: Shawn Feldman &lt;sfeldman@apache.org&gt;
Date:   2015-02-16T22:46:19Z

    add validation for index resource

commit a029041fad4935c41855cab861719da2c1fa7e2f
Author: Shawn Feldman &lt;sfeldman@apache.org&gt;
Date:   2015-02-17T00:27:31Z

    merge 276

commit d2371f99b4b64dda52e9ff7991e0f6144859779e
Author: Todd Nine &lt;tnine@apigee.com&gt;
Date:   2015-02-19T23:04:26Z

    First pass at refactor and re-implementation for new serialization

commit 067e78e303cd35c2c0062221f58fa130ae079455
Author: Todd Nine &lt;tnine@apigee.com&gt;
Date:   2015-02-19T23:35:32Z

    Removed unused synchronous interface
    
    Removed entity repair, no longe relevant
    
    Unique value serialization needs re-work.

commit ffa30962d32023f73ee2253038259af3fa7af2d7
Author: Todd Nine &lt;tnine@apigee.com&gt;
Date:   2015-02-20T02:49:22Z

    WIP overwrite

commit 8c581a48d48fba5cd76dd018a40288cf300164ea
Author: Todd Nine &lt;tnine@apigee.com&gt;
Date:   2015-02-24T00:18:18Z

    Fixed timestamp on write.  Also fixed tests.  Left unsupported interface values to support migration.  We should remove in a +1 release.

commit c2989fc702eeb240956e981de637dca68426a68b
Author: Todd Nine &lt;tnine@apigee.com&gt;
Date:   2015-02-24T04:04:09Z

    Renamed unique serializers to be easier to locate
    
    Added serializer to create row format necessary for unique ledger

commit 9f65a973b0b19d8650bf96ee6b245752d9e3c544
Author: Todd Nine &lt;tnine@apigee.com&gt;
Date:   2015-02-24T22:31:25Z

    Updated tasks and interface for getting unique values

commit 49fa8123d09b8afe8ff3496a1ce7019d26e9eacf
Author: Todd Nine &lt;tnine@apigee.com&gt;
Date:   2015-02-25T01:17:43Z

    Adds test and verifies api works as expected

----

              </div></li><li><div>
                Github user asfgit closed the pull request at:

    https://github.com/apache/incubator-usergrid/pull/175

              </div></li></ol></div></div></html>