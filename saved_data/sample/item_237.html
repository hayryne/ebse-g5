<!DOCTYPE html><html><div class="item-title">
        Item 237
      </div> <div class="item-details"><div><b>git_comments:</b> <ol><li><div>
                *
     * Construct instance of this class.
     *
     * @param aggregatingTrainer Aggregator trainer.
     * @param aggregatingInputMerger Function used to merge submodels outputs into one.
     
              </div></li><li><div>
                * {@inheritDoc} 
              </div></li><li><div>
                *
     * Keep original features using {@link IgniteFunction#identity()} as submodelInput2AggregatingInputConverter.
     *
     * @return This object.
     
              </div></li><li><div><div><b>comment:</b> TODO: IGNITE-10441 -- Look for options to avoid boilerplate overrides.
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 
              </div></li><li><div>
                *
     * Construct instance of this class.
     *
     * @param aggregatingTrainer Aggregator trainer.
     * @param aggregatingInputMerger Function used to merge submodels outputs into one.
     * @param submodelInput2AggregatingInputConverter Function used to convert input of submodel to output of submodel
     * this function is used if user chooses to keep original features.
     
              </div></li><li><div>
                *
 * {@link DatasetTrainer} with same type of input and output of submodels.
 *
 * @param &lt;I&gt; Type of submodels input.
 * @param &lt;O&gt; Type of aggregator model output.
 * @param &lt;AM&gt; Type of aggregator model.
 * @param &lt;L&gt; Type of labels.
 
              </div></li><li><div>
                *
     * Constructs instance of this class.
     
              </div></li><li><div>
                * Aggregating trainer. 
              </div></li><li><div>
                *
     * Specify binary operator used to merge submodels outputs to one.
     *
     * @param merger Binary operator used to merge submodels outputs to one.
     * @return This object.
     
              </div></li><li><div>
                 Make sure there is at least one way for submodel input to propagate to aggregator.
              </div></li><li><div>
                * Operator that merges inputs for aggregating model. 
              </div></li><li><div>
                *
     * Constructs instance of this class.
     *
     * @param aggregatorTrainer Trainer of model used for aggregation of results of submodels.
     * @param aggregatingInputMerger Binary operator used to merge outputs of submodels into one output passed to
     * aggregator model.
     * @param submodelInput2AggregatingInputConverter Function used to convert input of submodel to output of submodel
     * this function is used if user chooses to keep original features.
     
              </div></li><li><div>
                *
     * Get feature extractor which will be used for aggregator trainer from original feature extractor.
     * This method is static to make sure that we will not grab context of instance in serialization.
     *
     * @param featureExtractor Original feature extractor.
     * @param subMdls Submodels.
     * @param &lt;K&gt; Type of upstream keys.
     * @param &lt;V&gt; Type of upstream values.
     * @return Feature extractor which will be used for aggregator trainer from original feature extractor.
     
              </div></li><li><div>
                * {@inheritDoc} 
              </div></li><li><div>
                *
     * Adds submodel trainer along with converters needed on training and inference stages.
     *
     * @param trainer Submodel trainer.
     * @return This object.
     
              </div></li><li><div>
                *
     * Set function used for conversion of {@link Vector} to submodel input. This function is used during
     * building of dataset for training aggregator model. This dataset is augmented with results of submodels
     * applied to {@link Vector}s in original dataset.
     *
     * @param vector2SubmodelInputConverter Function used for conversion of {@link Vector} to submodel input.
     * @return This object.
     
              </div></li><li><div>
                * Function used for conversion of submodel output to {@link Vector}. 
              </div></li><li><div>
                *
 * {@link DatasetTrainer} encapsulating stacking technique for model training.
 * Model produced by this trainer consists of two layers. First layer is a model {@code IS -&gt; IA}.
 * This layer is a "parallel" composition of several "submodels", each of them itself is a model
 * {@code IS -&gt; IA} with their outputs {@code [IA]} merged into single {@code IA}.
 * Second layer is an aggregator model {@code IA -&gt; O}.
 * Training corresponds to this layered structure in the following way:
 * &lt;pre&gt;
 * 1. train models of first layer;
 * 2. train aggregator model on dataset augmented with outputs of first layer models converted to vectors.
 * &lt;/pre&gt;
 * During second step we can choose if we want to keep original features along with converted outputs of first layer
 * models or use only converted results of first layer models. This choice will also affect inference.
 * This class is a most general stacked trainer, there is a {@link StackedVectorDatasetTrainer}: a shortcut version of
 * it with some types and functions specified.
 *
 * @param &lt;IS&gt; Type of submodels input.
 * @param &lt;IA&gt; Type of aggregator input.
 * @param &lt;O&gt; Type of aggregator output.
 * @param &lt;L&gt; Type of labels.
 
              </div></li><li><div>
                * Function transforming input for submodels to input for aggregating model. 
              </div></li><li><div>
                * Function used for conversion of {@link Vector} to submodel input. 
              </div></li><li><div>
                *
     * Create instance of this class.
     *
     * @param aggregatorTrainer Trainer of model used for aggregation of results of submodels.
     * @param aggregatingInputMerger Binary operator used to merge outputs of submodels into one output passed to
     * aggregator model.
     * @param submodelInput2AggregatingInputConverter Function used to convert input of submodel to output of submodel
     * this function is used if user chooses to keep original features.
     * @param submodelsTrainers List of submodel trainers.
     
              </div></li><li><div>
                *
     * &lt;pre&gt;
     * 1. Obtain models produced by running specified tasks;
     * 2. run other specified task on dataset augmented with results of models from step 2.
     * &lt;/pre&gt;
     *
     * @param taskSupplier Function used to generate tasks for first step.
     * @param aggregatorProcessor Function used
     * @param featureExtractor Feature extractor.
     * @param &lt;K&gt; Type of keys in upstream.
     * @param &lt;V&gt; Type of values in upstream.
     * @return {@link StackedModel}.
     
              </div></li><li><div>
                
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 
              </div></li><li><div>
                 Add new columns consisting in submodels output in features.
              </div></li><li><div>
                *
     * Keep original features during training and propagate submodels input to aggregator during inference
     * using given function.
     * Note that if this object is on, training will be done on vector obtaining from
     * concatenating features passed to submodels trainers and outputs of submodels converted to vectors, this can,
     * for example influence aggregator model input vector dimension (if {@code IS = Vector}), or, more generally,
     * some {@code IS} parameters which are not reflected just by its type. So converter should be
     * written accordingly.
     *
     * @param submodelInput2AggregatingInputConverter Function used to propagate submodels input to aggregator.
     * @return This object.
     
              </div></li><li><div><div><b>comment:</b>  This method is never called, we override "update" instead.
                </div><div><b>label:</b> requirement
                </div></div></li><li><div>
                *
     * Drop original features during training and inference.
     *
     * @return This object.
     
              </div></li><li><div>
                *
     * Specify aggregator trainer.
     *
     * @param aggregatorTrainer Aggregator trainer.
     * @return This object.
     
              </div></li><li><div>
                * Trainers of submodels with converters from and to {@link Vector}. 
              </div></li><li><div>
                 Unsafely coerce DatasetTrainer&lt;M1, L&gt; to DatasetTrainer&lt;Model&lt;IS, IA&gt;, L&gt;, but we fully control
 usages of this unsafely coerced object, on the other hand this makes work with
 submodelTrainers easier.
              </div></li><li><div>
                *
     * Apply submodel to {@link Vector}.
     *
     * @param mdl Submodel.
     * @param submodelOutput2VectorConverter Function for conversion of submodel output to {@link Vector}.
     * @param vector2SubmodelInputConverter Function used for conversion of {@link Vector} to submodel input.
     * @param v Vector.
     * @param &lt;IS&gt; Type of submodel input.
     * @param &lt;IA&gt; Type of submodel output.
     * @return Result of application of {@code submodelOutput2VectorConverter . mdl . vector2SubmodelInputConverter}
     * where dot denotes functions composition.
     
              </div></li><li><div>
                *
     * Set function used for conversion of submodel output to {@link Vector}. This function is used during
     * building of dataset for training aggregator model. This dataset is augmented with results of submodels
     * converted to {@link Vector}.
     *
     * @param submodelOutput2VectorConverter Function used for conversion of submodel output to {@link Vector}.
     * @return This object.
     
              </div></li><li><div>
                *
     * Constructs instance of this class.
     
              </div></li><li><div>
                * Binary operator merging submodels outputs. 
              </div></li><li><div>
                * {@inheritDoc} 
              </div></li><li><div>
                * Submodels layer. 
              </div></li><li><div>
                *
     * Get submodels constituting first layer of this model.
     *
     * @return Submodels constituting first layer of this model.
     
              </div></li><li><div>
                * Models constituting submodels layer. 
              </div></li><li><div>
                
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 
              </div></li><li><div>
                *
 * Model consisting of two layers:
 * &lt;pre&gt;
 *     1. Submodels layer {@code (IS -&gt; IA)}.
 *     2. Aggregator layer {@code (IA -&gt; O)}.
 * &lt;/pre&gt;
 * Submodels layer is a "parallel" composition of several models {@code IS -&gt; IA} each of them getting same input
 * {@code IS} and produce own output, these outputs outputs {@code [IA]}
 * are combined into a single output with a given binary "merger" operator {@code IA -&gt; IA -&gt; IA}. Result of merge
 * is then passed to the aggregator layer.
 * Aggregator layer consists of a model {@code IA -&gt; O}.
 *
 * @param &lt;IS&gt; Type of submodels input.
 * @param &lt;IA&gt; Type of submodels output (same as aggregator model input).
 * @param &lt;O&gt; Type of aggregator model output.
 * @param &lt;AM&gt; Type of aggregator model.
 
              </div></li><li><div>
                *
     * Get aggregator model.
     *
     * @return Aggregator model.
     
              </div></li><li><div>
                * Aggregator model. 
              </div></li><li><div>
                *
     * Add submodel into first layer.
     *
     * @param subMdl Submodel to add.
     
              </div></li><li><div>
                *
     * Constructs instance of this class.
     *
     * @param aggregatorMdl Aggregator model.
     * @param aggregatingInputMerger Binary operator used to merge submodels outputs.
     * @param subMdlInput2AggregatingInput Function converting submodels input to aggregator input. (This function
     * is needed when in {@link StackedDatasetTrainer} option to keep original features is chosen).
     
              </div></li><li><div>
                * {@inheritDoc} 
              </div></li><li><div>
                *
     * Shortcut for adding trainer {@code Matrix -&gt; Matrix} where this trainer is treated as {@code Vector -&gt; Vector}, where
     * input {@link Vector} is turned into {@code 1 x cols} {@link Matrix} and output is a first row of output {@link Matrix}.
     *
     * @param trainer Submodel trainer.
     * @param &lt;M1&gt; Type of submodel trainer model.
     * @return This object.
     
              </div></li><li><div>
                *
     * Shortcut for adding trainer {@code Vector -&gt; Double} where this trainer is treated as {@code Vector -&gt; Vector}, where
     * output {@link Vector} is constructed by wrapping double value.
     *
     * @param trainer Submodel trainer.
     * @param &lt;M1&gt; Type of submodel trainer model.
     * @return This object.
     
              </div></li><li><div><div><b>comment:</b> TODO: IGNITE-10441 -- Look for options to avoid boilerplate overrides.
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 
              </div></li><li><div>
                *
 * {@link StackedDatasetTrainer} with {@link Vector} as submodels input and output.
 *
 * @param &lt;O&gt; Type of aggregator model output.
 * @param &lt;L&gt; Type of labels.
 * @param &lt;AM&gt; Type of aggregator model.
 
              </div></li><li><div>
                *
     * Constructs instance of this class.
     *
     * @param aggregatingTrainer Aggregator trainer.
     
              </div></li><li><div>
                *
     * Constructs instance of this class.
     
              </div></li><li><div>
                
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 
              </div></li><li><div>
                *
 * &lt;!-- Package description. --&gt;
 * Contains classes used for training with stacking technique.
 
              </div></li><li><div>
                *
     * Construct instance of this class.
     *
     * @param before Function applied before wrapped model.
     * @param mdl Inner model.
     * @param after Function applied after wrapped model.
     
              </div></li><li><div>
                * {@inheritDoc} 
              </div></li><li><div>
                *
 * Model which is composition of form {@code before `andThen` inner Mdl `andThen` after}.
 *
 * @param &lt;I&gt; Type of input of this model.
 * @param &lt;O&gt; Type of output of this model.
 * @param &lt;IW&gt; Type of input of inner model.
 * @param &lt;OW&gt; Type of output of inner model.
 * @param &lt;M&gt; Type of inner model.
 
              </div></li><li><div>
                *
     * Create new instance of this class with changed inner model.
     *
     * @param mdl Inner model.
     * @param &lt;M1&gt; Type of inner model.
     * @return New instance of this class with changed inner model.
     
              </div></li><li><div>
                * Function applied before inner model. 
              </div></li><li><div>
                * Function applied after inner model.
              </div></li><li><div>
                *
     * Get inner model.
     *
     * @return Inner model.
     
              </div></li><li><div>
                *
     * Result of this model application is a result of composition {@code before `andThen` inner mdl `andThen` after}.
     
              </div></li><li><div>
                
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 
              </div></li><li><div>
                *
     * Create new {@code AdaptableDatasetModel} which is a composition of the form {@code thisMdl . before}.
     *
     * @param before Function applied before this model.
     * @param &lt;I1&gt; Type of function applied before this model.
     * @return New {@code AdaptableDatasetModel} which is a composition of the form {@code thisMdl . before}.
     
              </div></li><li><div>
                * Inner model. 
              </div></li><li><div>
                * Wrapped trainer. 
              </div></li><li><div>
                *
     * Let this trainer produce model {@code mdl}. This method produces a trainer which produces {@code mdl1}, where
     * {@code mdl1 = f `andThen` mdl}.
     *
     * @param before Function inserted before produced model.
     * @param &lt;I1&gt; Type of produced model input.
     * @return New {@link DatasetTrainer} which produces composition of specified function and model produced by
     * original trainer.
     
              </div></li><li><div>
                * Function used to convert input type of wrapped trainer. 
              </div></li><li><div>
                * {@inheritDoc} 
              </div></li><li><div>
                *
     * Let this trainer produce model {@code mdl}. This method produces a trainer which produces {@code mdl1}, where
     * {@code mdl1 = mdl `andThen` after}.
     *
     * @param after Function inserted before produced model.
     * @param &lt;O1&gt; Type of produced model output.
     * @return New {@link DatasetTrainer} which produces composition of specified function and model produced by
     * original trainer.
     
              </div></li><li><div>
                * Function used to convert output type of wrapped trainer. 
              </div></li><li><div>
                
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 
              </div></li><li><div>
                *
     * Construct instance of this class with specified wrapped trainer and converter functions.
     *
     * @param before Function used to convert input type of wrapped trainer.
     * @param wrapped  Wrapped trainer.
     * @param after Function used to convert output type of wrapped trainer.
     
              </div></li><li><div>
                *
 * Type used to adapt input and output types of wrapped {@link DatasetTrainer}.
 * Produces model which is composition  of form {@code before `andThen` wMdl `andThen` after} where wMdl is model produced by
 * wrapped trainer.
 *
 * @param &lt;I&gt; Input type of model produced by this trainer.
 * @param &lt;O&gt; Output type of model produced by this trainer.
 * @param &lt;IW&gt; Input type of model produced by wrapped trainer.
 * @param &lt;OW&gt; Output type of model produced by wrapped trainer.
 * @param &lt;M&gt; Type of model produced by wrapped model.
 * @param &lt;L&gt; Type of labels.
 
              </div></li><li><div>
                *
     * Construct instance of this class from a given {@link DatasetTrainer}.
     *
     * @param wrapped Wrapped trainer.
     * @param &lt;I&gt; Input type of wrapped trainer.
     * @param &lt;O&gt; Output type of wrapped trainer.
     * @param &lt;M&gt; Type of model produced by wrapped trainer.
     * @param &lt;L&gt; Type of labels.
     * @return Instance of this class.
     
              </div></li><li><div>
                *
     * Tests simple stack training.
     
              </div></li><li><div>
                 Convert model trainer to produce Vector -&gt; Vector model
              </div></li><li><div>
                *
 * Tests stacked trainers.
 
              </div></li><li><div>
                * Rule to check exceptions. 
              </div></li><li><div>
                *
     * Tests that if there is no any way for input of first layer to propagate to second layer,
     * exception will be thrown.
     
              </div></li><li><div>
                
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 
              </div></li><li><div>
                *
     * Get a composition model of the form {@code x -&gt; after(mdl(x))}.
     *
     * @param after Function to apply after this model.
     * @param &lt;V1&gt; Type of input of function applied before this model.
     * @return Composition model of the form {@code x -&gt; after(mdl(x))}.
     
              </div></li><li><div>
                *
     * Identity function.
     *
     * @param &lt;T&gt; Type of input and output.
     * @return Identity function.
     
              </div></li><li><div><div><b>comment:</b>  TODO: IGNITE-10653 Maybe we should add toString description to identity and constant.
                </div><div><b>label:</b> documentation
                </div></div></li><li><div>
                *
     * Wrap specified value into vector.
     *
     * @param val Value to wrap.
     * @return Specified value wrapped into vector.
     
              </div></li><li><div>
                *
     * Turn number to 1-sized array.
     *
     * @param val Value to wrap in array.
     * @return Number wrapped in 1-sized array.
     
              </div></li><li><div>
                *
     * Concatenates given vectors.
     *
     * @param v1 First vector.
     * @param vs Other vectors.
     * @return Concatenation result.
     
              </div></li><li><div>
                *
     * Concatenates two given vectors.
     *
     * @param v1 First vector.
     * @param v2 Second vector.
     * @return Concatenation result.
     
              </div></li><li><div>
                *
     * Concatenates given vectors.
     *
     * @param vs Other vectors.
     * @return Concatenation result.
     
              </div></li><li><div>
                
              </div></li><li><div>
                *
     * Creates {@code DatasetTrainer} with same training logic, but able to accept labels of given new type
     * of labels.
     *
     * @param new2Old Converter of new labels to old labels.
     * @param &lt;L1&gt; New labels type.
     * @return {@code DatasetTrainer} with same training logic, but able to accept labels of given new type
     * of labels.
     
              </div></li><li><div>
                * {@inheritDoc} 
              </div></li><li><div>
                *
     * Returns trainer which independently of dataset outputs given model.
     *
     * @param ml Model.
     * @param &lt;I&gt; Type of model input.
     * @param &lt;O&gt; Type of model output.
     * @param &lt;M&gt; Type of model.
     * @param &lt;L&gt; Type of dataset labels.
     * @return Trainer which independently of dataset outputs given model.
     
              </div></li><li><div>
                * {@inheritDoc} 
              </div></li><li><div>
                * xor truth table. 
              </div></li><li><div>
                *
     * Create cache mock.
     *
     * @param vals Values for cache mock.
     * @return Cache mock.
     
              </div></li></ol></div><div><b>git_commits:</b> <ol><li><div><div><b>summary:</b> IGNITE-10480: [ML] Stacking for training and inference
                </div><div><b>message:</b> IGNITE-10480: [ML] Stacking for training and inference

This closes #5635

                </div></div></li></ol></div><div><b>github_issues:</b> <ol></ol></div><div><b>github_issues_comments:</b> <ol></ol></div><div><b>github_pulls:</b> <ol><li><div><div><b>title:</b> IGNITE-10480: [ML] Stacking for training and inference
                </div><div><b>body:</b> 
                </div></div></li></ol></div><div><b>github_pulls_comments:</b> <ol></ol></div><div><b>github_pulls_reviews:</b> <ol><li><div>
                "No usages found in All Places"
              </div></li><li><div><div><b>body:</b> In my opinion such interface is not convenient. Combiner requires working with Monoids like List[Double], but use may expect working with Doubles. 
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                javadoc
              </div></li><li><div>
                it looks good but we don't use toString for functions)
              </div></li><li><div>
                -&gt; addModelTrainerWithDoubleOutput
              </div></li><li><div>
                s/withAdded/add/g
              </div></li><li><div>
                Agree, done.
              </div></li><li><div>
                Agree, done.
              </div></li><li><div><div><b>body:</b> Seems like this class in unnecessary, removed it completely.
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                Yeah, got StackedVectorDatasetTrainer#addTrainerWithDoubleOutput for this which essentially lifts `Double` to `Vector` monoid (with concatenation as `mappend`).
              </div></li><li><div>
                you provide composition interface through andThen-function 
"f1 andThen f2" works as "f2(f1(x))" but  "f1 compose f2" as "f1(f2())"
In my opinion you should provide uniform semantic (preferably "andThen") in all comments to avoid problems of understanding and using of such interface
              </div></li><li><div>
                javadoc
              </div></li><li><div>
                javadoc
              </div></li><li><div>
                I think "the most general stacked trainer" will be better
              </div></li><li><div>
                it is just wrapper without additional logic
what is the reason of using it?
              </div></li><li><div><div><b>body:</b> maybe we should rewrite updateModel function from abstract form to form like this to avoid such code:

class DatasetTrainer {
....
protected ... updateModel(...) {
   throw NotImplementedException() 
}
....
}

?
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                May you merge update and fit logic?
              </div></li><li><div><div><b>body:</b> please avoid functional composition notation in Java world) 
in this wild world there are a lot of non-functional programmers may to beat you))
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                Agree, done.
              </div></li><li><div>
                Fixed.
              </div></li><li><div>
                Fixed.
              </div></li><li><div>
                Agree, done.
              </div></li><li><div>
                Ok, since we have `andThen`, I'll use it.
~~P.S. I will camouflage in a State monad to look imperativish~~ 
              </div></li><li><div><div><b>body:</b> Yes, intention was to make debugging less painful with at least some of the lambdas listed with meaningful names, but maybe we should make a ticket for that.
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                Okay, let's add it on demand.
              </div></li><li><div><div><b>body:</b> Reason is to convert everything into `DatasetTrainer&lt;Model&lt;IS, IA&gt;, L&gt;` (in contrast to `DatasetTrainer&lt;? extends Model&lt;IS, IA&gt;, L&gt;`) to make work with the list of `submodelTrainers` less painful. This is unsafe conversion, but since we have control of all `sumbodelTrainers` list usages inside our class, it's IMHO a reasanoble tradeoff.
                </div><div><b>label:</b> code-design
                </div></div></li><li><div><div><b>body:</b> Hmm... We will avoid boilerplate, but seems like it will make code more error prone. Developer can forget to override this method for trainer which potentially supports updating and get an error while trying to update this model in the future whereas keeping it abstract forces developer to think if this trainer supports update and insert `NotImplementedException` more cautiously. 
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                Agree, done.
              </div></li><li><div>
                to (avoid numbers)
              </div></li><li><div>
                the same thing
              </div></li><li><div>
                ?
              </div></li><li><div>
                Do we really need this?
              </div></li><li><div>
                to
              </div></li><li><div>
                to
              </div></li><li><div>
                new20 old? newToOld or something better
              </div></li><li><div>
                withTrainer
              </div></li><li><div>
                StackedModel getting looks pretty, many thanks!
              </div></li><li><div>
                ConvertedLabels seems like reinvention of labelExtractor sometimes
              </div></li><li><div><div><b>body:</b> Maybe we need a preprocessor like LabelTransformer with map function to change them
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                This is shortcut "specially" for MLP :)
              </div></li><li><div><div><b>body:</b> The reasons behind "2" are
1. I saw in code some methods with such naming, and decided to be consistent
2. "2" Is a good visual separator (at least for me) between "from" and "to" parts which (again, at least for me) rises readability, 
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                See https://github.com/apache/ignite/pull/5635#discussion_r241412240
              </div></li><li><div>
                This is a shortcut specially for people who prefer to pass all arguments via `with`s.
And the one with aggregator trainer as a single param is for IDE automatic type inference when introducing new variable.
              </div></li><li><div>
                Thanks! As for `withTrainer`, it was a tough choice: `withTrainer` looks like we substitute new trainer in place of the old trainer, not adding it. Previously it was `withAddedTrainer`, which looked a bit clumsy, so I went with `addTrainer`.
              </div></li><li><div>
                This is for the case when we use one `DatasetBuilder` for many trainers like we do in `StackedDatasetTrainer`. In this case we want the ability to adapt each of the trainers to be able to work with this dataset, this method is just for that.
              </div></li><li><div>
                If you don't mind, I wouldn't change it now because otherwise for consistency I should also change other such methods. I think it should be done atomically after some discussion.
              </div></li><li><div>
                See https://github.com/apache/ignite/pull/5635#discussion_r241417139
              </div></li></ol></div><div><b>jira_issues:</b> <ol><li><div><div><b>summary:</b> [ML] Stacking for training and inference
                </div><div><b>description:</b> Stacking is an ensemble learning technique that combines multiple classification or regression models via a meta-classifier or a meta-regressor. The base level models are trained based on a complete training set, then the meta-model is trained on the outputs of the base level model as features.
                </div></div></li></ol></div><div><b>jira_issues_comments:</b> <ol><li><div>
                GitHub user artemmalykh opened a pull request:

    https://github.com/apache/ignite/pull/5635

    IGNITE-10480: [ML] Stacking for training and inference

    

You can merge this pull request into a Git repository by running:

    $ git pull https://github.com/gridgain/apache-ignite ignite-10480

Alternatively you can review and apply these changes as the patch at:

    https://github.com/apache/ignite/pull/5635.patch

To close this pull request, make a commit to your master/trunk branch
with (at least) the following in the commit message:

    This closes #5635
    
----

----

              </div></li><li><div>
                reviewed by [~aplatonov], [~zaleslaw] and [~chief]

merged
              </div></li><li><div>
                Github user asfgit closed the pull request at:

    https://github.com/apache/ignite/pull/5635

              </div></li></ol></div></div></html>