<!DOCTYPE html><html><div class="item-title">
        Item 139
      </div> <div class="item-details"><div><b>git_comments:</b> <ol></ol></div><div><b>git_commits:</b> <ol><li><div><div><b>summary:</b> HDFS-4180. Update TestFileCreation for HDFS-4122.  Contributed by Jing Zhao
                </div><div><b>message:</b> HDFS-4180. Update TestFileCreation for HDFS-4122.  Contributed by Jing Zhao


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1@1409070 13f79535-47bb-0310-9956-ffa450edef68

                </div></div></li></ol></div><div><b>github_issues:</b> <ol></ol></div><div><b>github_issues_comments:</b> <ol></ol></div><div><b>github_pulls:</b> <ol></ol></div><div><b>github_pulls_comments:</b> <ol></ol></div><div><b>github_pulls_reviews:</b> <ol></ol></div><div><b>jira_issues:</b> <ol><li><div><div><b>summary:</b> TestFileCreation fails in branch-1 but not branch-1.1
                </div><div><b>description:</b> {noformat}
Testcase: testFileCreation took 3.419 sec
	Caused an ERROR
java.io.IOException: Cannot create /test_dir; already exists as a directory
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1374)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:1334)
	...
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1387)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: Cannot create /test_dir; already exists as a directory
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1374)
	...
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:443)
	at org.apache.hadoop.hdfs.TestFileCreation.checkFileCreation(TestFileCreation.java:249)
	at org.apache.hadoop.hdfs.TestFileCreation.testFileCreation(TestFileCreation.java:179)
{noformat}

                </div></div></li></ol></div><div><b>jira_issues_comments:</b> <ol><li><div><div><b>body:</b> The error is caused by the inconsistency between real exception msg and expected exception msg. A simple change can fix the error and the local TestFileCreation now passed.
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                +1 patch looks good.  The patch works well.
              </div></li><li><div>
                I have committed this.  Thanks, Jing!
              </div></li><li><div>
                Pardon the above thrash.  This problem only happens in 1.2.0 because it was caused by HDFS-4122 which is only committed to branch-1.
              </div></li><li><div>
                Closed upon release of Hadoop 1.2.0.
              </div></li></ol></div></div></html>