<!DOCTYPE html><html><div class="item-title">
        Item 228
      </div> <div class="item-details"><div><b>git_comments:</b> <ol><li><div>
                 A default DFS, which should have set via linkFallback
              </div></li><li><div>
                TODO: Need to revisit.
              </div></li><li><div>
                 A mounting file system.
              </div></li><li><div>
                 DFS only API.
              </div></li><li><div>
                 Regular DFS behavior
              </div></li><li><div>
                 No path available in filter. Let's try to shoot to all child fs.
              </div></li><li><div>
                 whenever we see negative result.
              </div></li><li><div>
                 Just proovided the same implementation as default in dfs as thats just
 delegated to FileSystem parent class.
              </div></li><li><div>
                Ony for HDFS users
              </div></li><li><div>
                 DFS specific API
              </div></li><li><div>
                Let applications call getDelegationTokenIssuers and get respective
 delegation tokens from child fs.
              </div></li><li><div>
                 Previous super.initialize would have skipped the dfsclient init and
 setWorkingDirectory as we planned to initialize vfs. Since vfs init
 failed, let's init dfsClient now.
              </div></li><li><div>
                *
   * Returns only default cluster getHedgedReadMetrics.
   
              </div></li><li><div>
                 No path available in CacheDirectiveInfo, Let's shoot to all child fs.
              </div></li><li><div>
                 Works only for HDFS
              </div></li><li><div>
                Make sure your target fs supports this API, otherwise you will get
 Unsupported operation exception.
              </div></li><li><div>
                Check both in same cluster.
              </div></li><li><div>
                 A child DFS with the current initialized URI. This must be same as
 fallback fs. The fallback must point to root of your filesystems.
 Some APIs(without path in argument, for example isInSafeMode) will
 support only for base cluster filesystem. Only that APIs will use this
 fs.
              </div></li><li><div>
                 Please don't access internal dfs client directly except in tests.
              </div></li><li><div>
                *
 * The ViewDistributedFileSystem is an extended class to DistributedFileSystem
 * with additional mounting functionality. The goal is to have better API
 * compatibility for HDFS users when using mounting
 * filesystem(ViewFileSystemOverloadScheme).
 * The ViewFileSystemOverloadScheme{@link ViewFileSystemOverloadScheme} is a new
 * filesystem with inherited mounting functionality from ViewFileSystem.
 * For the user who is using ViewFileSystemOverloadScheme by setting
 * fs.hdfs.impl=org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme, now
 * they can set fs.hdfs.impl=org.apache.hadoop.hdfs.ViewDistributedFileSystem.
 * So, that the hdfs users will get closely compatible API with mount
 * functionality. For the rest of all other schemes can continue to use
 * ViewFileSystemOverloadScheme class directly for mount functionality. Please
 * note that ViewFileSystemOverloadScheme provides only
 * ViewFileSystem{@link ViewFileSystem} APIs.
 * If user configured this class but no mount point configured? Then it will
 * simply work as existing DistributedFileSystem class. If user configured both
 * fs.hdfs.impl to this class and mount configurations, then users will be able
 * to make calls the APIs available in this class, they are nothing but DFS
 * APIs, but they will be delegated to viewfs functionality. Please note, APIs
 * without any path in arguments( ex: isInSafeMode), will be delegated to
 * default filesystem only, that is the configured fallback link. If you want to
 * make these API calls on specific child filesystem, you may want to initialize
 * them separately and call. In ViewDistributedFileSystem, we strongly recommend
 * to configure linkFallBack when you add mount links and it's recommended to
 * point be to your base cluster, usually your current fs.defaultFS if that's
 * pointing to hdfs.
 
              </div></li><li><div>
                Currently Cache pool APIs supported only in default cluster.
              </div></li><li><div>
                 TODO: revisit for correct implementation.
              </div></li><li><div>
                *
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 * &lt;p&gt;
 * http://www.apache.org/licenses/LICENSE-2.0
 * &lt;p&gt;
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 
              </div></li><li><div>
                *
   * Gets all erasure coding policies from all available child file systems.
   
              </div></li><li><div>
                 TODO: revisit
              </div></li><li><div>
                 Since we plan to initialize vfs in this class, we will not need to
 initialize DFS client.
              </div></li><li><div>
                *
   * Returns the results from default DFS (fallback). If you want the results
   * from specific clusters, please invoke them on child fs instance directly.
   
              </div></li><li><div>
                Below API provided implementations are in ViewFS but not there in DFS.
              </div></li><li><div>
                DFS specific API
              </div></li><li><div>
                 Let's just return the last one.
              </div></li><li><div>
                 TODO: can we return null here?
              </div></li><li><div>
                 we can enabled later if we want to support symlinks.
              </div></li><li><div>
                *
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 
              </div></li><li><div>
                *
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 
              </div></li><li><div>
                *
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 
              </div></li><li><div>
                *
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 * &lt;p&gt;
 * http://www.apache.org/licenses/LICENSE-2.0
 * &lt;p&gt;
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 
              </div></li><li><div>
                *
   * Gets the mount path info, which contains the target file system and
   * remaining path to pass to the target file system.
   
              </div></li><li><div>
                *
   * A class to maintain the target file system and a path to pass to the target
   * file system.
   
              </div></li><li><div>
                 No link configured with passed path.
              </div></li><li><div>
                *
   * @return Gets the fallback file system configured. Usually, this will be the
   * default cluster.
   
              </div></li><li><div>
                *
   * Sets whether to add fallback automatically when no mount points found.
   
              </div></li><li><div>
                *
   * @return configuration.
   
              </div></li><li><div>
                *
   * sets configuration.
   
              </div></li><li><div>
                *
   * @return the dfs instance for nnIdx.
   
              </div></li><li><div>
                *
   * @return the dfs instance.
   
              </div></li><li><div>
                *
   * @return the configuration.
   
              </div></li></ol></div><div><b>git_commits:</b> <ol><li><div><div><b>summary:</b> HDFS-15533: Provide DFS API compatible class, but use ViewFileSystemOverloadScheme inside. (#2229). Contributed by Uma Maheswara Rao G.
                </div><div><b>message:</b> HDFS-15533: Provide DFS API compatible class, but use ViewFileSystemOverloadScheme inside. (#2229). Contributed by Uma Maheswara Rao G.

(cherry picked from commit dd013f2fdf1ecbeb6c877e26951cd0d8922058b0)

                </div></div></li></ol></div><div><b>github_issues:</b> <ol></ol></div><div><b>github_issues_comments:</b> <ol></ol></div><div><b>github_pulls:</b> <ol><li><div><div><b>title:</b> HDFS-15533: Provide DFS API compatible class, but use ViewFileSystemOverloadScheme inside.
                </div><div><b>body:</b> https://issues.apache.org/jira/browse/HDFS-15533
                </div></div></li></ol></div><div><b>github_pulls_comments:</b> <ol><li><div>
                Updated a draft PR to show the idea of this JIRA. 
              </div></li><li><div>
                :broken_heart: **-1 overall**






| Vote | Subsystem | Runtime | Comment |
|:----:|----------:|--------:|:--------|
| +0 :ok: |  reexec  |   1m  2s |  Docker mode activated.  |
||| _ Prechecks _ |
| +1 :green_heart: |  dupname  |   0m  1s |  No case conflicting files found.  |
| +1 :green_heart: |  @author  |   0m  0s |  The patch does not contain any @author tags.  |
| +1 :green_heart: |  test4tests  |   0m  0s |  The patch appears to include 6 new or modified test files.  |
||| _ trunk Compile Tests _ |
| +0 :ok: |  mvndep  |   3m 32s |  Maven dependency ordering for branch  |
| +1 :green_heart: |  mvninstall  |  25m 57s |  trunk passed  |
| +1 :green_heart: |  compile  |  19m 16s |  trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1  |
| +1 :green_heart: |  compile  |  16m 39s |  trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01  |
| +1 :green_heart: |  checkstyle  |   2m 41s |  trunk passed  |
| +1 :green_heart: |  mvnsite  |   4m  3s |  trunk passed  |
| +1 :green_heart: |  shadedclient  |  21m 14s |  branch has no errors when building and testing our client artifacts.  |
| +1 :green_heart: |  javadoc  |   2m 30s |  trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1  |
| +1 :green_heart: |  javadoc  |   3m 59s |  trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01  |
| +0 :ok: |  spotbugs  |   2m 32s |  Used deprecated FindBugs config; considering switching to SpotBugs.  |
| +1 :green_heart: |  findbugs  |   7m 49s |  trunk passed  |
||| _ Patch Compile Tests _ |
| +0 :ok: |  mvndep  |   0m 26s |  Maven dependency ordering for patch  |
| +1 :green_heart: |  mvninstall  |   2m 45s |  the patch passed  |
| +1 :green_heart: |  compile  |  18m 35s |  the patch passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1  |
| -1 :x: |  javac  |  18m 35s |  root-jdkUbuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 generated 13 new + 2043 unchanged - 9 fixed = 2056 total (was 2052)  |
| +1 :green_heart: |  compile  |  16m 37s |  the patch passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01  |
| -1 :x: |  javac  |  16m 37s |  root-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 generated 12 new + 1939 unchanged - 8 fixed = 1951 total (was 1947)  |
| -0 :warning: |  checkstyle  |   2m 44s |  root: The patch generated 27 new + 217 unchanged - 0 fixed = 244 total (was 217)  |
| +1 :green_heart: |  mvnsite  |   4m  1s |  the patch passed  |
| +1 :green_heart: |  whitespace  |   0m  0s |  The patch has no whitespace issues.  |
| +1 :green_heart: |  shadedclient  |  14m  1s |  patch has no errors when building and testing our client artifacts.  |
| +1 :green_heart: |  javadoc  |   2m 28s |  the patch passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1  |
| -1 :x: |  javadoc  |   0m 50s |  hadoop-hdfs-project_hadoop-hdfs-client-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0)  |
| -1 :x: |  findbugs  |   2m 20s |  hadoop-common-project/hadoop-common generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0)  |
| -1 :x: |  findbugs  |   2m 42s |  hadoop-hdfs-project/hadoop-hdfs-client generated 2 new + 0 unchanged - 0 fixed = 2 total (was 0)  |
||| _ Other Tests _ |
| +1 :green_heart: |  unit  |   9m 59s |  hadoop-common in the patch passed.  |
| +1 :green_heart: |  unit  |   2m 18s |  hadoop-hdfs-client in the patch passed.  |
| -1 :x: |  unit  | 118m 22s |  hadoop-hdfs in the patch passed.  |
| +1 :green_heart: |  asflicense  |   1m  4s |  The patch does not generate ASF License warnings.  |
|  |   | 313m 14s |   |


| Reason | Tests |
|-------:|:------|
| FindBugs | module:hadoop-common-project/hadoop-common |
|  |  Should org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme$MountPathInfo be a _static_ inner class?  At ViewFileSystemOverloadScheme.java:inner class?  At ViewFileSystemOverloadScheme.java:[lines 320-329] |
| FindBugs | module:hadoop-hdfs-project/hadoop-hdfs-client |
|  |  Arguments in wrong order for invocation of checkNotNull in org.apache.hadoop.hdfs.ViewDistributedFileSystem.initialize(URI, Configuration)  At ViewDistributedFileSystem.java:invocation of checkNotNull in org.apache.hadoop.hdfs.ViewDistributedFileSystem.initialize(URI, Configuration)  At ViewDistributedFileSystem.java:[line 154] |
|  |  There is an apparent infinite recursive loop in org.apache.hadoop.hdfs.ViewDistributedFileSystem.getMountPoints()  At ViewDistributedFileSystem.java:recursive loop in org.apache.hadoop.hdfs.ViewDistributedFileSystem.getMountPoints()  At ViewDistributedFileSystem.java:[line 1844] |
| Failed junit tests | hadoop.fs.viewfs.TestViewFSOverloadSchemeWithMountTableConfigInHDFS |
|   | hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader |
|   | hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier |
|   | hadoop.hdfs.server.datanode.TestBPOfferService |
|   | hadoop.hdfs.TestViewDistributedFileSystem |
|   | hadoop.hdfs.server.namenode.TestNameNodeRetryCacheMetrics |


| Subsystem | Report/Notes |
|----------:|:-------------|
| Docker | ClientAPI=1.40 ServerAPI=1.40 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/1/artifact/out/Dockerfile |
| GITHUB PR | https://github.com/apache/hadoop/pull/2229 |
| JIRA Issue | HDFS-15533 |
| Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient findbugs checkstyle |
| uname | Linux 81085b36ee1d 4.15.0-112-generic #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | personality/hadoop.sh |
| git revision | trunk / b93dd7c281c |
| Default Java | Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |
| Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |
| javac | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/1/artifact/out/diff-compile-javac-root-jdkUbuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1.txt |
| javac | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/1/artifact/out/diff-compile-javac-root-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01.txt |
| checkstyle | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/1/artifact/out/diff-checkstyle-root.txt |
| javadoc | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/1/artifact/out/diff-javadoc-javadoc-hadoop-hdfs-project_hadoop-hdfs-client-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01.txt |
| findbugs | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/1/artifact/out/new-findbugs-hadoop-common-project_hadoop-common.html |
| findbugs | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/1/artifact/out/new-findbugs-hadoop-hdfs-project_hadoop-hdfs-client.html |
| unit | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/1/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/1/testReport/ |
| Max. process+thread count | 3404 (vs. ulimit of 5500) |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs U: . |
| Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/1/console |
| versions | git=2.17.1 maven=3.6.0 findbugs=4.0.6 |
| Powered by | Apache Yetus 0.13.0-SNAPSHOT https://yetus.apache.org |


This message was automatically generated.


              </div></li><li><div>
                :broken_heart: **-1 overall**






| Vote | Subsystem | Runtime | Comment |
|:----:|----------:|--------:|:--------|
| +0 :ok: |  reexec  |   1m  8s |  Docker mode activated.  |
||| _ Prechecks _ |
| +1 :green_heart: |  dupname  |   0m  0s |  No case conflicting files found.  |
| +1 :green_heart: |  @author  |   0m  0s |  The patch does not contain any @author tags.  |
| +1 :green_heart: |  test4tests  |   0m  0s |  The patch appears to include 6 new or modified test files.  |
||| _ trunk Compile Tests _ |
| +0 :ok: |  mvndep  |   3m 18s |  Maven dependency ordering for branch  |
| +1 :green_heart: |  mvninstall  |  28m  1s |  trunk passed  |
| +1 :green_heart: |  compile  |  20m 52s |  trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1  |
| +1 :green_heart: |  compile  |  17m 34s |  trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01  |
| +1 :green_heart: |  checkstyle  |   2m 53s |  trunk passed  |
| +1 :green_heart: |  mvnsite  |   3m 49s |  trunk passed  |
| +1 :green_heart: |  shadedclient  |  22m 40s |  branch has no errors when building and testing our client artifacts.  |
| +1 :green_heart: |  javadoc  |   2m  9s |  trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1  |
| +1 :green_heart: |  javadoc  |   3m 35s |  trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01  |
| +0 :ok: |  spotbugs  |   2m 36s |  Used deprecated FindBugs config; considering switching to SpotBugs.  |
| +1 :green_heart: |  findbugs  |   8m  3s |  trunk passed  |
||| _ Patch Compile Tests _ |
| +0 :ok: |  mvndep  |   0m 22s |  Maven dependency ordering for patch  |
| +1 :green_heart: |  mvninstall  |   2m 47s |  the patch passed  |
| +1 :green_heart: |  compile  |  20m  3s |  the patch passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1  |
| -1 :x: |  javac  |  20m  3s |  root-jdkUbuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 generated 4 new + 2049 unchanged - 0 fixed = 2053 total (was 2049)  |
| +1 :green_heart: |  compile  |  17m 33s |  the patch passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01  |
| -1 :x: |  javac  |  17m 33s |  root-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 generated 4 new + 1943 unchanged - 0 fixed = 1947 total (was 1943)  |
| -0 :warning: |  checkstyle  |   2m 53s |  root: The patch generated 5 new + 217 unchanged - 0 fixed = 222 total (was 217)  |
| +1 :green_heart: |  mvnsite  |   4m  5s |  the patch passed  |
| +1 :green_heart: |  whitespace  |   0m  0s |  The patch has no whitespace issues.  |
| +1 :green_heart: |  shadedclient  |  17m 26s |  patch has no errors when building and testing our client artifacts.  |
| +1 :green_heart: |  javadoc  |   2m 43s |  the patch passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1  |
| -1 :x: |  javadoc  |   0m 52s |  hadoop-hdfs-project_hadoop-hdfs-client-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0)  |
| +1 :green_heart: |  findbugs  |   9m 44s |  the patch passed  |
||| _ Other Tests _ |
| +1 :green_heart: |  unit  |  11m  6s |  hadoop-common in the patch passed.  |
| +1 :green_heart: |  unit  |   2m 27s |  hadoop-hdfs-client in the patch passed.  |
| -1 :x: |  unit  | 110m 27s |  hadoop-hdfs in the patch passed.  |
| +1 :green_heart: |  asflicense  |   0m 55s |  The patch does not generate ASF License warnings.  |
|  |   | 319m 42s |   |


| Reason | Tests |
|-------:|:------|
| Failed junit tests | hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier |
|   | hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFSStriped |
|   | hadoop.hdfs.TestMultipleNNPortQOP |
|   | hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader |
|   | hadoop.hdfs.web.TestWebHdfsWithMultipleNameNodes |
|   | hadoop.hdfs.TestGetFileChecksum |
|   | hadoop.hdfs.server.namenode.ha.TestHAAppend |


| Subsystem | Report/Notes |
|----------:|:-------------|
| Docker | ClientAPI=1.40 ServerAPI=1.40 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/2/artifact/out/Dockerfile |
| GITHUB PR | https://github.com/apache/hadoop/pull/2229 |
| JIRA Issue | HDFS-15533 |
| Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient findbugs checkstyle |
| uname | Linux 91b04bc0f0fc 4.15.0-112-generic #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | personality/hadoop.sh |
| git revision | trunk / b93dd7c281c |
| Default Java | Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |
| Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |
| javac | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/2/artifact/out/diff-compile-javac-root-jdkUbuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1.txt |
| javac | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/2/artifact/out/diff-compile-javac-root-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01.txt |
| checkstyle | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/2/artifact/out/diff-checkstyle-root.txt |
| javadoc | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/2/artifact/out/diff-javadoc-javadoc-hadoop-hdfs-project_hadoop-hdfs-client-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01.txt |
| unit | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/2/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/2/testReport/ |
| Max. process+thread count | 3318 (vs. ulimit of 5500) |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs U: . |
| Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/2/console |
| versions | git=2.17.1 maven=3.6.0 findbugs=4.0.6 |
| Powered by | Apache Yetus 0.13.0-SNAPSHOT https://yetus.apache.org |


This message was automatically generated.


              </div></li><li><div>
                :broken_heart: **-1 overall**






| Vote | Subsystem | Runtime | Comment |
|:----:|----------:|--------:|:--------|
| +0 :ok: |  reexec  |   1m  2s |  Docker mode activated.  |
||| _ Prechecks _ |
| +1 :green_heart: |  dupname  |   0m  0s |  No case conflicting files found.  |
| +1 :green_heart: |  @author  |   0m  0s |  The patch does not contain any @author tags.  |
| +1 :green_heart: |  test4tests  |   0m  0s |  The patch appears to include 6 new or modified test files.  |
||| _ trunk Compile Tests _ |
| +0 :ok: |  mvndep  |   3m 20s |  Maven dependency ordering for branch  |
| +1 :green_heart: |  mvninstall  |  25m 47s |  trunk passed  |
| +1 :green_heart: |  compile  |  19m 12s |  trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1  |
| +1 :green_heart: |  compile  |  16m 42s |  trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01  |
| +1 :green_heart: |  checkstyle  |   2m 42s |  trunk passed  |
| +1 :green_heart: |  mvnsite  |   4m  1s |  trunk passed  |
| +1 :green_heart: |  shadedclient  |  20m 58s |  branch has no errors when building and testing our client artifacts.  |
| +1 :green_heart: |  javadoc  |   2m 31s |  trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1  |
| +1 :green_heart: |  javadoc  |   3m 54s |  trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01  |
| +0 :ok: |  spotbugs  |   2m 32s |  Used deprecated FindBugs config; considering switching to SpotBugs.  |
| +1 :green_heart: |  findbugs  |   7m 52s |  trunk passed  |
||| _ Patch Compile Tests _ |
| +0 :ok: |  mvndep  |   0m 26s |  Maven dependency ordering for patch  |
| +1 :green_heart: |  mvninstall  |   2m 44s |  the patch passed  |
| +1 :green_heart: |  compile  |  18m 38s |  the patch passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1  |
| -1 :x: |  javac  |  18m 38s |  root-jdkUbuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 generated 13 new + 2043 unchanged - 9 fixed = 2056 total (was 2052)  |
| +1 :green_heart: |  compile  |  16m 39s |  the patch passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01  |
| -1 :x: |  javac  |  16m 39s |  root-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 generated 12 new + 1939 unchanged - 8 fixed = 1951 total (was 1947)  |
| -0 :warning: |  checkstyle  |   2m 44s |  root: The patch generated 3 new + 217 unchanged - 0 fixed = 220 total (was 217)  |
| +1 :green_heart: |  mvnsite  |   4m  0s |  the patch passed  |
| +1 :green_heart: |  whitespace  |   0m  0s |  The patch has no whitespace issues.  |
| +1 :green_heart: |  shadedclient  |  14m  4s |  patch has no errors when building and testing our client artifacts.  |
| +1 :green_heart: |  javadoc  |   2m 30s |  the patch passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1  |
| -1 :x: |  javadoc  |   0m 50s |  hadoop-hdfs-project_hadoop-hdfs-client-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0)  |
| +1 :green_heart: |  findbugs  |   8m 20s |  the patch passed  |
||| _ Other Tests _ |
| +1 :green_heart: |  unit  |  10m  1s |  hadoop-common in the patch passed.  |
| +1 :green_heart: |  unit  |   2m 18s |  hadoop-hdfs-client in the patch passed.  |
| -1 :x: |  unit  | 118m  8s |  hadoop-hdfs in the patch passed.  |
| +1 :green_heart: |  asflicense  |   1m  4s |  The patch does not generate ASF License warnings.  |
|  |   | 312m 26s |   |


| Reason | Tests |
|-------:|:------|
| Failed junit tests | hadoop.hdfs.server.namenode.TestAddOverReplicatedStripedBlocks |
|   | hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader |
|   | hadoop.hdfs.server.namenode.ha.TestEditLogTailer |
|   | hadoop.hdfs.TestMultipleNNPortQOP |


| Subsystem | Report/Notes |
|----------:|:-------------|
| Docker | ClientAPI=1.40 ServerAPI=1.40 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/3/artifact/out/Dockerfile |
| GITHUB PR | https://github.com/apache/hadoop/pull/2229 |
| JIRA Issue | HDFS-15533 |
| Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient findbugs checkstyle |
| uname | Linux 173beb1a3a39 4.15.0-112-generic #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | personality/hadoop.sh |
| git revision | trunk / 5092ea62ecb |
| Default Java | Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |
| Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |
| javac | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/3/artifact/out/diff-compile-javac-root-jdkUbuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1.txt |
| javac | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/3/artifact/out/diff-compile-javac-root-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01.txt |
| checkstyle | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/3/artifact/out/diff-checkstyle-root.txt |
| javadoc | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/3/artifact/out/diff-javadoc-javadoc-hadoop-hdfs-project_hadoop-hdfs-client-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01.txt |
| unit | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/3/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/3/testReport/ |
| Max. process+thread count | 3883 (vs. ulimit of 5500) |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs U: . |
| Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/3/console |
| versions | git=2.17.1 maven=3.6.0 findbugs=4.0.6 |
| Powered by | Apache Yetus 0.13.0-SNAPSHOT https://yetus.apache.org |


This message was automatically generated.


              </div></li><li><div>
                :broken_heart: **-1 overall**






| Vote | Subsystem | Runtime | Comment |
|:----:|----------:|--------:|:--------|
| +0 :ok: |  reexec  |   1m  0s |  Docker mode activated.  |
||| _ Prechecks _ |
| +1 :green_heart: |  dupname  |   0m  0s |  No case conflicting files found.  |
| +1 :green_heart: |  @author  |   0m  0s |  The patch does not contain any @author tags.  |
| +1 :green_heart: |  test4tests  |   0m  0s |  The patch appears to include 6 new or modified test files.  |
||| _ trunk Compile Tests _ |
| +0 :ok: |  mvndep  |   3m 21s |  Maven dependency ordering for branch  |
| +1 :green_heart: |  mvninstall  |  26m  0s |  trunk passed  |
| +1 :green_heart: |  compile  |  19m 14s |  trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1  |
| +1 :green_heart: |  compile  |  16m 43s |  trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01  |
| +1 :green_heart: |  checkstyle  |   2m 46s |  trunk passed  |
| +1 :green_heart: |  mvnsite  |   4m  2s |  trunk passed  |
| +1 :green_heart: |  shadedclient  |  21m 28s |  branch has no errors when building and testing our client artifacts.  |
| +1 :green_heart: |  javadoc  |   2m 29s |  trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1  |
| +1 :green_heart: |  javadoc  |   3m 55s |  trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01  |
| +0 :ok: |  spotbugs  |   2m 32s |  Used deprecated FindBugs config; considering switching to SpotBugs.  |
| +1 :green_heart: |  findbugs  |   7m 49s |  trunk passed  |
||| _ Patch Compile Tests _ |
| +0 :ok: |  mvndep  |   0m 26s |  Maven dependency ordering for patch  |
| +1 :green_heart: |  mvninstall  |   2m 41s |  the patch passed  |
| +1 :green_heart: |  compile  |  18m 35s |  the patch passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1  |
| -1 :x: |  javac  |  18m 35s |  root-jdkUbuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 generated 13 new + 2043 unchanged - 9 fixed = 2056 total (was 2052)  |
| +1 :green_heart: |  compile  |  16m 38s |  the patch passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01  |
| -1 :x: |  javac  |  16m 38s |  root-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 generated 12 new + 1939 unchanged - 8 fixed = 1951 total (was 1947)  |
| -0 :warning: |  checkstyle  |   2m 42s |  root: The patch generated 2 new + 217 unchanged - 0 fixed = 219 total (was 217)  |
| +1 :green_heart: |  mvnsite  |   3m 57s |  the patch passed  |
| +1 :green_heart: |  whitespace  |   0m  0s |  The patch has no whitespace issues.  |
| +1 :green_heart: |  shadedclient  |  14m  3s |  patch has no errors when building and testing our client artifacts.  |
| +1 :green_heart: |  javadoc  |   2m 28s |  the patch passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1  |
| -1 :x: |  javadoc  |   0m 49s |  hadoop-hdfs-project_hadoop-hdfs-client-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0)  |
| +1 :green_heart: |  findbugs  |   8m 18s |  the patch passed  |
||| _ Other Tests _ |
| +1 :green_heart: |  unit  |   9m 57s |  hadoop-common in the patch passed.  |
| +1 :green_heart: |  unit  |   2m 17s |  hadoop-hdfs-client in the patch passed.  |
| -1 :x: |  unit  | 118m 35s |  hadoop-hdfs in the patch passed.  |
| +1 :green_heart: |  asflicense  |   1m  3s |  The patch does not generate ASF License warnings.  |
|  |   | 313m 10s |   |


| Reason | Tests |
|-------:|:------|
| Failed junit tests | hadoop.hdfs.TestGetFileChecksum |
|   | hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFSStriped |
|   | hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader |
|   | hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier |


| Subsystem | Report/Notes |
|----------:|:-------------|
| Docker | ClientAPI=1.40 ServerAPI=1.40 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/4/artifact/out/Dockerfile |
| GITHUB PR | https://github.com/apache/hadoop/pull/2229 |
| JIRA Issue | HDFS-15533 |
| Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient findbugs checkstyle |
| uname | Linux 93f8c0ae6bdf 4.15.0-112-generic #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | personality/hadoop.sh |
| git revision | trunk / 5092ea62ecb |
| Default Java | Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |
| Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |
| javac | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/4/artifact/out/diff-compile-javac-root-jdkUbuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1.txt |
| javac | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/4/artifact/out/diff-compile-javac-root-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01.txt |
| checkstyle | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/4/artifact/out/diff-checkstyle-root.txt |
| javadoc | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/4/artifact/out/diff-javadoc-javadoc-hadoop-hdfs-project_hadoop-hdfs-client-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01.txt |
| unit | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/4/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/4/testReport/ |
| Max. process+thread count | 3674 (vs. ulimit of 5500) |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs U: . |
| Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/4/console |
| versions | git=2.17.1 maven=3.6.0 findbugs=4.0.6 |
| Powered by | Apache Yetus 0.13.0-SNAPSHOT https://yetus.apache.org |


This message was automatically generated.


              </div></li><li><div>
                :broken_heart: **-1 overall**






| Vote | Subsystem | Runtime | Comment |
|:----:|----------:|--------:|:--------|
| +0 :ok: |  reexec  |  30m 14s |  Docker mode activated.  |
||| _ Prechecks _ |
| +1 :green_heart: |  dupname  |   0m  0s |  No case conflicting files found.  |
| +1 :green_heart: |  @author  |   0m  0s |  The patch does not contain any @author tags.  |
| +1 :green_heart: |  test4tests  |   0m  0s |  The patch appears to include 8 new or modified test files.  |
||| _ trunk Compile Tests _ |
| +0 :ok: |  mvndep  |   3m 17s |  Maven dependency ordering for branch  |
| +1 :green_heart: |  mvninstall  |  29m 23s |  trunk passed  |
| -1 :x: |  compile  |  18m 18s |  root in trunk failed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1.  |
| +1 :green_heart: |  compile  |  19m 48s |  trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01  |
| +1 :green_heart: |  checkstyle  |   3m 12s |  trunk passed  |
| +1 :green_heart: |  mvnsite  |   3m 56s |  trunk passed  |
| +1 :green_heart: |  shadedclient  |  23m 34s |  branch has no errors when building and testing our client artifacts.  |
| +1 :green_heart: |  javadoc  |   2m 18s |  trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1  |
| +1 :green_heart: |  javadoc  |   3m 31s |  trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01  |
| +0 :ok: |  spotbugs  |   2m 45s |  Used deprecated FindBugs config; considering switching to SpotBugs.  |
| +1 :green_heart: |  findbugs  |   8m 40s |  trunk passed  |
||| _ Patch Compile Tests _ |
| +0 :ok: |  mvndep  |   0m 27s |  Maven dependency ordering for patch  |
| +1 :green_heart: |  mvninstall  |   2m 57s |  the patch passed  |
| +1 :green_heart: |  compile  |  21m 47s |  the patch passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1  |
| -1 :x: |  javac  |  21m 47s |  root-jdkUbuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 generated 223 new + 1833 unchanged - 9 fixed = 2056 total (was 1842)  |
| +1 :green_heart: |  compile  |  20m 22s |  the patch passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01  |
| -1 :x: |  javac  |  20m 22s |  root-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 generated 12 new + 1939 unchanged - 8 fixed = 1951 total (was 1947)  |
| -0 :warning: |  checkstyle  |   3m 11s |  root: The patch generated 7 new + 242 unchanged - 0 fixed = 249 total (was 242)  |
| +1 :green_heart: |  mvnsite  |   4m  7s |  the patch passed  |
| +1 :green_heart: |  whitespace  |   0m  0s |  The patch has no whitespace issues.  |
| +1 :green_heart: |  shadedclient  |  16m 13s |  patch has no errors when building and testing our client artifacts.  |
| +1 :green_heart: |  javadoc  |   2m 20s |  the patch passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1  |
| +1 :green_heart: |  javadoc  |   3m 49s |  the patch passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01  |
| +1 :green_heart: |  findbugs  |   9m 27s |  the patch passed  |
||| _ Other Tests _ |
| +1 :green_heart: |  unit  |  10m 22s |  hadoop-common in the patch passed.  |
| +1 :green_heart: |  unit  |   2m 17s |  hadoop-hdfs-client in the patch passed.  |
| -1 :x: |  unit  | 121m  7s |  hadoop-hdfs in the patch passed.  |
| +1 :green_heart: |  asflicense  |   0m 54s |  The patch does not generate ASF License warnings.  |
|  |   | 363m 23s |   |


| Reason | Tests |
|-------:|:------|
| Failed junit tests | hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier |
|   | hadoop.hdfs.TestRollingUpgrade |
|   | hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader |


| Subsystem | Report/Notes |
|----------:|:-------------|
| Docker | ClientAPI=1.40 ServerAPI=1.40 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/5/artifact/out/Dockerfile |
| GITHUB PR | https://github.com/apache/hadoop/pull/2229 |
| JIRA Issue | HDFS-15533 |
| Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient findbugs checkstyle |
| uname | Linux 15aa57e15bf5 4.15.0-112-generic #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | dev-support/bin/hadoop.sh |
| git revision | trunk / b65e43fe386 |
| Default Java | Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |
| Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |
| compile | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/5/artifact/out/branch-compile-root-jdkUbuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1.txt |
| javac | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/5/artifact/out/diff-compile-javac-root-jdkUbuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1.txt |
| javac | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/5/artifact/out/diff-compile-javac-root-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01.txt |
| checkstyle | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/5/artifact/out/diff-checkstyle-root.txt |
| unit | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/5/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/5/testReport/ |
| Max. process+thread count | 3269 (vs. ulimit of 5500) |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs U: . |
| Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2229/5/console |
| versions | git=2.17.1 maven=3.6.0 findbugs=4.0.6 |
| Powered by | Apache Yetus 0.13.0-SNAPSHOT https://yetus.apache.org |


This message was automatically generated.


              </div></li><li><div>
                Thanks a lot @ayushtkn for the reviews.
Yes, javac popped up from many other unrelated test files as well. There are two related test files, but they are related to deprecated API usage. Since we want to support all existing DFS apis, that may be unavoidable and no harm.
Test failures are unrelated.
There are 2 checkstyles for longer length. They both also can't be avoided as they are same in DFS class as well. API name itself has longer length.
              </div></li></ol></div><div><b>github_pulls_reviews:</b> <ol><li><div>
                Do we need to initialize twice? It is already done above at L132
              </div></li><li><div>
                Does this make having a fallback mandatory and that too, to HDFS? May be people would want to have a different FS fallback, or not have a fallback, and they might not be using non-path API's as well. Can't we just not throw `UnsupportedOperationException` if `defaultDFS` is null?
              </div></li><li><div>
                Why are we removing this? The logic still stays, Namenode Can not get initialized with a Non-DFS filesystems? Will HDFS-15450, not resurface, if something ViewFileSystemOverloadScheme is configured, not this new one?
It shouldn't be done with new one available, but still we should have logics to handle if not
              </div></li><li><div>
                Can give result from DefaultDFS?
If not, correct the API name
              </div></li><li><div>
                I doubt this. Shouldn't enable/disable/add/remove EC Policy go to all underlying child DFS rather than defaultDFS?
              </div></li><li><div>
                API name in exception.
Why can't we support cache commands, similar to other ones?
              </div></li><li><div>
                The idea was, the first initialization should initing DFSClient as we may initialize vfs. Later if we failed to init vfs, then we will continue to initialize DfsClient to get regular DFS behavior. 
I corrected few things now and that may clear you things. Why I tried to init at first line was to make sure statistics initialized with correct class names. Otherwise I noticed, InternalViewFS also getting inited in statistics with hdfs scheme, that may create issues for the correctness.. 
              </div></li><li><div>
                Why I tried to make this mandatory was, there are few APIs currently we are delegating to defaultfs. I am just worried we will have too many behaviors. :-)
Let me think on it. 
              </div></li><li><div>
                Actually in ViewFileSystemOverloadScheme, we started auto assigning fallback link. So, we will have at least one link so, NN side init will succeed with that behavior. The tests added in HDFS-15450 passes now even with removing above line.
              </div></li><li><div>
                For now just delegated to defaultFS.
              </div></li><li><div>
                This is one point I was thinking what to do. One way I agree that running on all child hdfs-s make sense. But other I was thinking that if a user working on a specific mount and wants to call would make the call goes and disturb all other clusters also. However, Unfortunately  we don't have choice to choose specific cluster from the current API signatures.
Whats your opinion? 
Ideally they should be done from admins command line as they are not part of FileSystem API. If they are from admin, users can use -fs option to run on specific child clusters.

              </div></li><li><div>
                Other cache related APIs passing CacheDirectInfo which has path. But CachePool api are not passing. Any I just delegated them to defaultFS currently.
              </div></li><li><div>
                Well in any case, I think making a call to `defaultDFS` isn't going to help much. Somebody does an `enablePolicy` and post that if he tries `setPolicy` which goes to another `FS` it will fail, he might try `listPolicies` which will again go to `defaultDFS` and the policy would show as `enabled` there, so this behavior would be very confusing in that case.
There are two ways only IMO, we let the admin only do it using `-fs` and throw an `UnsupportedExceptions` for these API's, 
Second solution is shooting calls to all `child FS`, This is what is done in case of `RBF` as well, I think in `ViewFileSystem` the `getAllStoragePolicies` API also does something like this. 
Personally, I feel the second option would be little better, as post that the client operations shall work without any restrictions/issues 
              </div></li><li><div>
                if the `cachePool` API's are going to `defaultDFS`, it may impact the `cacheDirective` API's as well, I think while adding a `cacheDirective` there is an option of `setPool` in `cacheDirectiveBuilder`, so if we do a `listCachePools` it will show the `cachePools` from `defaultDFS` which eventually might not work for the other FS.
IIRC `listCachePools` doesn't seems to have a `superuser` check as well, if so, we shouldn't block this call as well.
              </div></li><li><div>
                Should be fine then, Thanx
              </div></li><li><div>
                @ayushtkn , Thank you for your opinion. I attempted to delegate EC calls to all child filesystems. 

To the other approach the APIs delegated only defaultFS: if we don't delegate to defaultFS and simply throw USOE and if defautFS is same as the fs.defaultFS uri, then we will never be able to call this defaultFS. Because it will be resolved to same VDFS class and find mount points configured with same authority.
So, if we delegate to defaultFS in the current instance and for all other childFS, users can use -fs option. That will work as otherFS authority most probably will be different and they will be able to initialized successfully, but without any mounts.

              </div></li><li><div>
                Thanx @umamaheswararao 
I have a small doubt-
``  // A default DFS, which should have set via linkFallback
  private DistributedFileSystem defaultDFS;``
The defaultDFS is the FS set via fallback, Correct?

`    viewFs.setSupportAutoAddingFallbackOnNoMounts(false);`
Now here we have disabled Auto adding fallback, So, in case corresponding mount entry isn't there, will a normal(read/write) call go to this defaultDFS? I think no?
* If not then why to bother `defaultDFS`, if it is not handling client calls?
* if not, Why are we not allowing fallback? is it a planned followup, or some issues with it.
* if the fallback fs is there and is present amongst as a `childFS`, We could have eliminated the `defaultDFS` logic completely? Since now a call will go to that `FS` as well?

&gt; So, if we delegate to defaultFS in the current instance and for all other childFS

With  `and` you mean shoot calls to all childFS and then make a call to defaultDFS as well?

&gt; defautFS is same as the fs.defaultFS uri, then we will never be able to call this defaultFS. Because it will be resolved to same VDFS class and find mount points configured with same authority.

Isn't this a client mis-config then? He configured it to get overloaded?

Well seems like, I have bothered  you too much on this, If stuff above doesn't make sense, you can have same logic as EC for `cachePool` API's as well, since `listCachePool` seems a non-Admin API. Post that you can proceed ahead with concluding this. I don't think `defaultDFS` would be bothering much in prod cases, and rest everything already is pretty cool :-)
              </div></li><li><div>
                @ayushtkn  Thanks a lot for your time and review. You made lot of good points, no issues let's conversations going on until things are making sense. :-)

&gt; The defaultDFS is the FS set via fallback, Correct?

Yes, you are right.

&gt; viewFs.setSupportAutoAddingFallbackOnNoMounts(false);

Why I disabled this was, in ViewDistributedFileSystem, if no mount points configured in the system, everything should work as regular DistributedFileSystem. So, we can eventually make this class (fs.hdfs.impl=ViewDistributedFileSystem) enabled by default and just don't add mount points if they don't need mounting functionality. The existing users will not see any impact as this will work same as DistributedFileSystem as the existing users would not have configured any mount points. That's the expectation here. So, if we auto add fallback, vfs#init will never fail and we always go into mount way of functionality. 
That's why every api checks vfs==null, and they use super.API() calls to get exactly same DistributedFileSystem Functionality.
Hope this clears your doubt.

&gt; Now here we have disabled Auto adding fallback, So, in case corresponding mount entry isn't there, will a normal(read/write) call go to this defaultDFS? I think no?

Case 1: user did not configure any mounts : works same as DistributedFileSystem.
Case 2: user did configured mounts, but no fallback configured :  Whatever mount paths matching will delegate call to that fs. If no matches, it will fail with NotInMountPoint Exceptions. APIs like IsInSafeMode will fail as there is no defaultFS( that is fallback). User's can make use -fs from command line and call to specific child fs. 
Case 3: user did configured mounts and as well as fallback: Now whatever paths matching will go to target fs. If no matches, then fallback. For APIs without paths in argument like IsInSafeMode will simply make calls on that fallback fs. For the rest of other child file systems, they may need to do from command like with -fs option.

&gt; if the fallback fs is there and is present amongst as a childFS, We could have eliminated the defaultDFS logic completely? Since now a call will go to that FS as well?

That's why I tried tp make it mandatory config from user perspective. But we did not auto configure for the above reason, where we can enable by default(in future) fs.hdfs.impl pointing ViewDistributedFileSystem without any impact to existing users.


&gt;With and you mean shoot calls to all childFS and then make a call to defaultDFS as well?

What I meant was: example: you have 
fs.defaultFS = hdfs://ns1
 fallback(defaultFS) -&gt; hdfs://ns1
/user --&gt; hdfs://ns2

when you call isInSafeMode, you will get result from default cluster(fallback).
To get from other child's, you will get FileSystem.get(otherClusterURI, conf).isInSafeMode().

Incase if we simply throw USOE without giving from defaultCluster, we can never call to default cluster because FileSystem.get(fallbackUri, conf).isInSafeMode() will always gets USOE because the fallback and fs.defaultFS uris are same. 

&gt; Isn't this a client mis-config then? He configured it to get overloaded?

One of the important use case is, if you have an existing cluster and you want to add mount points with respective to that cluster. Then you will use that existing cluster as fallback and you will continue to use same fs.defaultFS.
So, all ops go to your default cluster except the paths matching to mount points. That way existing users need not change uri, but they can simply add mounts with respective to that cluster by simply adding current cluster as fallback.


&gt;you can have same logic as EC for cachePool API's as well, since listCachePool seems a non-Admin API.

I am thinking in similar lines. Let me add cachePool API shoot to all fss.

BTW, please note currently getChildFileSystems does not include, fallback fs. It will be fixed with HDFS-15529    
Thanks again for your review.    
                            
              </div></li><li><div>
                Thanx for the details. Makes sense.
              </div></li><li><div>
                I did attempt to shoot to all child fs for cache pool apis. Please check if they are making sense.
              </div></li><li><div>
                Thanks
              </div></li><li><div>
                Yahh, That looks good
              </div></li></ol></div><div><b>jira_issues:</b> <ol></ol></div><div><b>jira_issues_comments:</b> <ol></ol></div></div></html>