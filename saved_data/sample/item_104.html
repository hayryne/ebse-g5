<!DOCTYPE html><html><div class="item-title">
        Item 104
      </div> <div class="item-details"><div><b>git_comments:</b> <ol></ol></div><div><b>git_commits:</b> <ol><li><div><div><b>summary:</b> CLOUDSTACK-118 Status of host resorce stuck in ErrorInMaintenance
                </div><div><b>message:</b> CLOUDSTACK-118 Status of host resorce stuck in ErrorInMaintenance

                </div></div></li></ol></div><div><b>github_issues:</b> <ol></ol></div><div><b>github_issues_comments:</b> <ol></ol></div><div><b>github_pulls:</b> <ol></ol></div><div><b>github_pulls_comments:</b> <ol></ol></div><div><b>github_pulls_reviews:</b> <ol></ol></div><div><b>jira_issues:</b> <ol><li><div><div><b>summary:</b> Status of host resorce  stuck in "ErrorInMaintenance"
                </div><div><b>description:</b> In a cluster of 2 host if  you try to put master in maintenance mode ,resource state will be stuck in "ErrorInMaintenance"   

Step to reproduce:
-----------------------------
------------------------------
1-Create an advance zone-&gt;pod-&gt;cluster.
2-Add 2 hosts in same cluster.
3-Deploy a HA enabled VM .
4-put host(one which is pool master ) in maintenance mode .

Expected result : 
--------------------------
--------------------------
status =UP;
resource status =maintenance  

Actual result:
------------------------
------------------------
status=UP;
resource state=ErrorInMaintenance
                </div></div></li></ol></div><div><b>jira_issues_comments:</b> <ol><li><div>
                Management Server logs:
  1-access_log.2012-09-17.txt
  2-api-server.log
  3-catalina.out
  4-management-server.log
  5-management-server.log.2012-09-16.gz

Database backup:
1-cloud-backup.dmp
              </div></li><li><div>
                I don't know if this bug is supposed to be fixed before 4.0, so preempting it right now. 
              </div></li><li><div>
                Prashant,

What version of CS did you find this in?

--Alex
              </div></li><li><div>
                it's CloudStack--4.0.59
              </div></li><li><div>
                I ran into same problem when there is not enough available resource on other hosts, host will stuck in ErrorInMaintenance state and cannot cancel; but this is an exceptional scenario, for normal scenario there is no error.

[error log]
WARN  [cloud.ha.HighAvailabilityManagerImpl] (HA-Worker-0:work-16) Insufficient capacity for migrating a VM.

Prashant,
i cant find any PrepareForMaintenanceCmd or related log in your mgmt server log, can you verify the steps to reproduce it? 
              </div></li><li><div>
                Please find the right resource to work on this one.
              </div></li><li><div>
                I tried  with a fresh install of management server using new build and getting same problem( ErrorinMaintenance)

Log
------------------
------------------
 Resource state update: [id = 2; name = xenserver-srsufcmy; old state = PrepareForMaintenance; event = UnableToMigrate; new state = ErrorInMaintenance]

I am  also atteched log file "management-server.log" it may help to look into problem.
              </div></li><li><div>
                Resource state update: [id = 2; name = xenserver-srsufcmy; old state = PrepareForMaintenance; event = UnableToMigrate; new state = ErrorInMaintenance]
------------------
------------------

this is caused by :

2012-09-25 01:54:42,491 DEBUG [cloud.deploy.FirstFitPlanner] (HA-Worker-1:work-2) Cannot allocate cluster list [1] for vm creation since their allocated percentage crosses the disable capacity threshold: 0.85 for capacity Type : 1, skipping these clusters
2012-09-25 01:54:42,492 DEBUG [cloud.deploy.FirstFitPlanner] (HA-Worker-1:work-2) Could not find suitable Deployment Destination for this VM under any clusters, returning.
------------------
------------------

capacity type 1 is CPU, thread [HA-Worker-1:work-2] is trying to migrate i-2-5-VM to another host, free CPU 3800, requested CPU 4000

if migrating fails, maintenance will fail, IMO this is the expected result.

              </div></li><li><div>
                this may be a reason (capacity Threshold) and to rule out this Today i  tested  on fresh install (xs6.0.2,MS Rhl6.3) where i got same error (ErrorInMaintenance ) . I am attaching MS log and screenshot of dashboard (it will give idea of resource used)   

Log:
-----------
-----------
012-09-26 03:03:15,540 DEBUG [cloud.deploy.FirstFitPlanner] (HA-Worker-0:work-1) Trying to allocate a host and storage pools from dc:1, pod:1,cluster:1, requested cpu: 500, requested ram: 268435456
2012-09-26 03:03:15,540 DEBUG [cloud.deploy.FirstFitPlanner] (HA-Worker-0:work-1) Is ROOT volume READY (pool already allocated)?: No
2012-09-26 03:03:15,540 DEBUG [cloud.deploy.FirstFitPlanner] (HA-Worker-0:work-1) This VM has last host_id specified, trying to choose the same host: 5
2012-09-26 03:03:15,541 DEBUG [cloud.deploy.FirstFitPlanner] (HA-Worker-0:work-1) The last host of this VM is in avoid set
2012-09-26 03:03:15,546 DEBUG [cloud.deploy.FirstFitPlanner] (HA-Worker-0:work-1) Cannot choose the last host to deploy this VM 
2012-09-26 03:03:15,546 DEBUG [cloud.deploy.FirstFitPlanner] (HA-Worker-0:work-1) Searching resources only under specified Cluster: 1
2012-09-26 03:03:15,553 DEBUG [cloud.deploy.FirstFitPlanner] (HA-Worker-1:work-2) DeploymentPlanner allocation algorithm: random
2012-09-26 03:03:15,554 DEBUG [cloud.deploy.FirstFitPlanner] (HA-Worker-1:work-2) Trying to allocate a host and storage pools from dc:1, pod:1,cluster:1, requested cpu: 4000, requested ram: 1048576000
2012-09-26 03:03:15,554 DEBUG [cloud.deploy.FirstFitPlanner] (HA-Worker-1:work-2) Is ROOT volume READY (pool already allocated)?: No
2012-09-26 03:03:15,554 DEBUG [cloud.deploy.FirstFitPlanner] (HA-Worker-1:work-2) This VM has last host_id specified, trying to choose the same host: 5
2012-09-26 03:03:15,558 DEBUG [cloud.deploy.FirstFitPlanner] (HA-Worker-1:work-2) The last host of this VM is in avoid set
2012-09-26 03:03:15,558 DEBUG [cloud.deploy.FirstFitPlanner] (HA-Worker-1:work-2) Cannot choose the last host to deploy this VM 
2012-09-26 03:03:15,558 DEBUG [cloud.deploy.FirstFitPlanner] (HA-Worker-1:work-2) Searching resources only under specified Cluster: 1
2012-09-26 03:03:15,567 INFO  [cloud.ha.HighAvailabilityManagerImpl] (HA-Worker-3:work-3) Processing HAWork[3-Migration-5-Running-Scheduled

              </div></li><li><div>
                Today's  MS log(9/26/2012)
              </div></li><li><div>
                I am facing same error "ErrorInMaintenance" with KVM host also.

**********************************************
Details
***********************************************
Setup
-------------------
-------------------
MS :Rhel6.3
Hypervisor : KVM(Rhl6.3)
Advance Zone

Build :CloudStack-oss-4.0.0-184.tar.bz2 

Git Revision: 995bab60385f7d663680ef6f5342056c6db3d305
Git URL: https://git-wip-us.apache.org/repos/asf/incubator-cloudstack.git

--------------------------------------------------------------------------------------------------------------------------------------
Step to reproduce:
-----------------------------
------------------------------
1-Create an advance zone-&gt;pod-&gt;cluster.
2-Add 2 hosts in same cluster.
3-Deploy a HA enabled VM .
4-put host(on which SSVM ,CPVM and VR are running  ) in maintenance mode . 


Expected result :
--------------------------
--------------------------
resource status =maintenance

Actual result:
------------------------
------------------------

resource state=ErrorInMaintenance


              </div></li><li><div>
                MS Log for CS + KVM host setup
              </div></li><li><div><div><b>body:</b> Prashant,

From this exception, it looks like the problem has to do with the XenServer pool.  It is having trouble to migrate VMs off.  That's why the host went into errorinmaintenance state.  Please reinstall the xenservers as well and retry this.


2012-09-26 03:03:33,726 WARN  [xen.resource.CitrixResourceBase] (DirectAgent-116:null) Catch Exception com.cloud.utils.exception.CloudRuntimeException: Migration failed due to com.cloud.utils.exception.CloudRuntimeException: Unable to migrate VM(s-3-VM) from host(10cb6099-2ff1-48ee-9901-b519636c4f4a) due to Task failed! Task record:                 uuid: a6f653da-1c7f-91e7-d657-eb7eb7bfe35f
           nameLabel: Async.VM.pool_migrate
     nameDescription: 
   allowedOperations: []
   currentOperations: {}
             created: Wed Sep 26 08:34:49 EDT 2012
            finished: Wed Sep 26 08:34:49 EDT 2012
              status: FAILURE
          residentOn: com.xensource.xenapi.Host@9d5af48a
            progress: 1.0
                type: &lt;none/&gt;
              result: 
           errorInfo: [VM_REQUIRES_NETWORK, OpaqueRef:0868caeb-de65-daf8-cd31-d51661fba707, OpaqueRef:f2922672-9b02-dea5-2388-420a60b4bdc0]
         otherConfig: {}
           subtaskOf: com.xensource.xenapi.Task@aaf13f6f
            subtasks: []

com.cloud.utils.exception.CloudRuntimeException: Unable to migrate VM(s-3-VM) from host(10cb6099-2ff1-48ee-9901-b519636c4f4a) due to Task failed! Task record:                 uuid: a6f653da-1c7f-91e7-d657-eb7eb7bfe35f
           nameLabel: Async.VM.pool_migrate
     nameDescription: 
   allowedOperations: []
   currentOperations: {}
             created: Wed Sep 26 08:34:49 EDT 2012
            finished: Wed Sep 26 08:34:49 EDT 2012
              status: FAILURE
          residentOn: com.xensource.xenapi.Host@9d5af48a
            progress: 1.0
                type: &lt;none/&gt;
              result: 
           errorInfo: [VM_REQUIRES_NETWORK, OpaqueRef:0868caeb-de65-daf8-cd31-d51661fba707, OpaqueRef:f2922672-9b02-dea5-2388-420a60b4bdc0]
         otherConfig: {}
           subtaskOf: com.xensource.xenapi.Task@aaf13f6f
            subtasks: []

	at com.cloud.hypervisor.xen.resource.CitrixResourceBase.migrateVM(CitrixResourceBase.java:3303)
	at com.cloud.hypervisor.xen.resource.CitrixResourceBase.execute(CitrixResourceBase.java:2845)
	at com.cloud.hypervisor.xen.resource.CitrixResourceBase.executeRequest(CitrixResourceBase.java:451)
	at com.cloud.hypervisor.xen.resource.XenServer56Resource.executeRequest(XenServer56Resource.java:73)
	at com.cloud.agent.manager.DirectAgentAttache$Task.run(DirectAgentAttache.java:191)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$101(ScheduledThreadPoolExecutor.java:165)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                Based on the logs, it looks like a XenServer configuration issue.  Moved this to 4.1.0 and lowered the priority.
              </div></li><li><div>
                I am getting same error with  KVM(Rhl6.3) setup also i presume there would not be the configuration(pool) problem .
              </div></li><li><div>
                @Prashant, this a very special case and most likely your storage or KVM configuration. I tried to read through the logs but was unable to diagnose the problem. As you suggest this bug may not be caught everytime, it is may be time/thread/sync issue.

For KVM, how are disk names set? I see it fails while trying to set uid/gid over a file that does not exist, and has internal name with patchdisk suffix, instead of uuid/guid which is the case for Xen.

2012-10-05 12:27:35,585 ERROR [cloud.vm.VirtualMachineManagerImpl] (HA-Worker-0:work-5) Unable to migrate due to unable to set user and group to '0:0' on '/mnt/6e8264c6-4591-399b-b4b0-123f61342208/s-1-VM-patchdisk': No such file or directory

@Sudha: can anyone in BLR/SC be assigned to verify this bug?
Triaging to Edison or anyone on KVM.

Thanks.
              </div></li><li><div>
                no clue for the exception which xenserver throws, but indeed there is a race condition between migrating thread and delta sync thread, i.e. delta sync thread might force-update VM's status during VM migration, and that will cause migrating thread fail to update VM status.

Plus, can not cancel maintenance because there is no such state transition in resource state machine.
              </div></li><li><div>
                commit master a5bca0999aa010252b1390c4db6dc5023967ab06

resolve race condition issue,
add state transition for cancelMaintenance

Please verify
              </div></li><li><div>
                closing since 4.1.0 is now released
              </div></li></ol></div></div></html>