<!DOCTYPE html><html><div class="item-title">
        Item 333
      </div> <div class="item-details"><div><b>git_comments:</b> <ol><li><div>
                *
   * Sends ratis command to destroy pipeline on the given datanode.
   *
   * @param dn         - Datanode on which pipeline needs to be destroyed
   * @param pipelineID - ID of pipeline to be destroyed
   * @param ozoneConf  - Ozone configuration
   * @param grpcTlsConfig - grpc tls configuration
   * @throws IOException
   
              </div></li><li><div>
                *
 * Utility class for Ratis pipelines. Contains methods to create and destroy
 * ratis pipelines.
 
              </div></li><li><div>
                
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 *  with the License.  You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 *  Unless required by applicable law or agreed to in writing, software
 *  distributed under the License is distributed on an "AS IS" BASIS,
 *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *  See the License for the specific language governing permissions and
 *  limitations under the License.
 
              </div></li><li><div>
                *
   * Removes pipeline from SCM. Sends ratis command to destroy pipeline on all
   * the datanodes.
   *
   * @param pipeline        - Pipeline to be destroyed
   * @param ozoneConf       - Ozone configuration
   * @param grpcTlsConfig
   * @throws IOException
   
              </div></li><li><div>
                 Setting to zero by default means this limit doesn't take effect.
              </div></li><li><div>
                 Upper limit for how many pipelines can be created.
 Only for test purpose now.
              </div></li><li><div>
                 Datanodes from pipeline in some states can also be considered available
 for pipeline allocation. Thus the number of these pipeline shall be
 deducted from total heaviness calculation.
              </div></li><li><div>
                 no limit applied.
              </div></li><li><div>
                 Randomly picks nodes when all nodes are equal or factor is ONE.
              </div></li><li><div>
                 Per datanode limit
              </div></li><li><div>
                 Global limit
              </div></li><li><div>
                 Only put limits for Factor THREE pipelines.
              </div></li><li><div>
                *
   * Get the number of pipeline created.
   * @return number of pipeline
   
              </div></li><li><div>
                 pipeline creation failed this time.
              </div></li><li><div>
                 allow only one FACTOR THREE pipeline.
              </div></li><li><div>
                *
     * Sets the total number of pipelines to create.
     * @param val number of pipelines
     * @return MiniOzoneCluster.Builder
     
              </div></li><li><div>
                 MiniOzoneCluster should have global pipeline upper limit.
              </div></li></ol></div><div><b>git_commits:</b> <ol><li><div><div><b>summary:</b> HDDS-1569 Support creating multiple pipelines with same datanode. Contributed by Li Cheng. 
                </div><div><b>message:</b> HDDS-1569 Support creating multiple pipelines with same datanode. Contributed by Li Cheng. 

This closes #28 
                </div></div></li></ol></div><div><b>github_issues:</b> <ol></ol></div><div><b>github_issues_comments:</b> <ol></ol></div><div><b>github_pulls:</b> <ol><li><div><div><b>title:</b> HDDS-1569 Support creating multiple pipelines with same datanode
                </div><div><b>body:</b> ## NOTICE
https://issues.apache.org/jira/browse/HDDS-1569
related PR: https://github.com/apache/hadoop/pull/1431

Changes:
1. Use PipelinePlacementPolicy as default for Factor THREE Ratis pipeline.
2. Handle differently in some parts for Factor ONE and Factor THREE pipeline.
3. Add limits for pipeline creation.
4. Adjust a bunch of unit tests accordingly.

                </div></div></li></ol></div><div><b>github_pulls_comments:</b> <ol><li><div>
                /retest
              </div></li><li><div>
                /retest
              </div></li><li><div>
                /retest
              </div></li><li><div>
                /retest
              </div></li><li><div>
                +1, pending CI. Thanks for the update @timmylicheng 
              </div></li></ol></div><div><b>github_pulls_reviews:</b> <ol><li><div><div><b>body:</b> .datanode can be removed. 
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                If this property is only for test,  suggest remove it from the ozone-default.xml
              </div></li><li><div>
                Any change here? 
              </div></li><li><div>
                Don't change this level.  The action is "close pipeline" due to some error happened on Datanode side. 
              </div></li><li><div>
                should we divide the "heavyNodeCriteria * nodeManager.getNodeCount(HddsProtos.NodeState.HEALTHY" using the "factor" ? 
              </div></li><li><div>
                define  a new resultcode for this case or use FAILED_TO_FIND_SUITABLE_NODE
              </div></li><li><div>
                Suggest change Node2PipelineMap, use Pipeline instead of PipelineID as the value of the Map, to simpify this query. 
              </div></li><li><div>
                Import * is not recommended. 
              </div></li><li><div>
                 !p.getPipelineState().equals(PipelineState.CLOSED)
              </div></li><li><div><div><b>body:</b> line longer than 80 chars
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                SCMException is a generic exception, please use specific exception if possible
              </div></li><li><div>
                setPipelineNumberLimit? 
              </div></li><li><div><div><b>body:</b> &gt; Any change here?

Not effective changes. It was due to complaints from checkstyle


                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                Ok. Will remove from ozone-default.xml
              </div></li><li><div>
                Ok sure
              </div></li><li><div>
                Rolled it back
              </div></li><li><div>
                IDE did it. Change it manually
              </div></li><li><div><div><b>body:</b> Haven't made logical changes to it. Just quiet off checkstyle. Intend to keep it this way.
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                Good point. Should divide by factor number.
              </div></li><li><div><div><b>body:</b> checkstyle doesn't seem to check imports. Don't bother to adjust it until checkstyle complains.
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                Updated.
              </div></li><li><div>
                So all the policies including ContainerPlacementPolicy are throwing out SCMException with specified reason in messages. The PipelinePlacementPolicy follows them and so as upstream SCMPipelineManager. So here I align the old InsufficientDatanodesException with SCMException. I believe with specified error message, it's ok to use a general exception since the test is specifically testing pipeline creation.
              </div></li><li><div>
                Ok 
              </div></li><li><div>
                As I looked a little deeper, changing Node2PipelineMap mapping may affect more than this commit. Shall we have a separate discussion on the internal data structure for NodeStateManager?
              </div></li><li><div>
                I switch to traverse the list from node manager side.
              </div></li><li><div><div><b>body:</b> why do we need to add the dn-&gt;pipelineId in 75 since line 73 already add it?
                </div><div><b>label:</b> code-design
                </div></div></li><li><div><div><b>body:</b> Can we add some description for the meaning of default 0? 
                </div><div><b>label:</b> documentation
                </div></div></li><li><div>
                This seems to be a case where the PipelineStateMap mismatch with the Node2PipelineMap. Do you see cases from unit tests or cluster?  
              </div></li><li><div><div><b>body:</b> NIT: suggest rename heavyNodeCriteria to maxPipelinePerDatanode. heavyNodeCriteria can be a function name using maxPipelinePerDatanode.
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                Or should we consider only OPEN pipeline here?
              </div></li><li><div>
                Do we still assume one RATIS.ONE pipeline per DN here?
              </div></li><li><div><div><b>body:</b> Should we move this logic into RatisPipelineProvider so that the exception handling will natually fit into the try/final?
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                Can we use assertEquals with some message so that when it fails, we can see the difference in the ResultCode.
              </div></li><li><div>
                Do we have specific exception result code to check here?
              </div></li><li><div>
                Is there a reason that we need to set a large per DN pipeline limit here?
              </div></li><li><div><div><b>body:</b> Can you add more comments here? If the # of SCM pipeline limit is 3, should we set OZONE_SCM_PIPELINE_NUMBER_LIMIT to 3 instead of 2 * numOfDatanodes?
                </div><div><b>label:</b> documentation
                </div></div></li><li><div><div><b>body:</b> NIT: can we expand the wildcard import?
                </div><div><b>label:</b> code-design
                </div></div></li><li><div><div><b>body:</b> NIT: expand wildcard import
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                Should we expose a method for MiniOzoneCluster to set per DN pipeline limit?
              </div></li><li><div><div><b>body:</b> NIT: rename to setTotalPipelineNumLimit
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                Line 73 is adding v to new keyset when key is absent and line 75 is adding v to the existing keyset. Reason why we don't have to have extra if here is computeIfAbsent and computeIfPresent are both judging if key is present or not. So we don't have to see if Map.get(k) is null.
              </div></li><li><div>
                Sure.
              </div></li><li><div>
                Sure
              </div></li><li><div>
                Yes. The RATIS ONE pipeline is still using old fashion of picking up nodes. Only RATIS THREE pipeline is using the complex new fashion in PipelinePlacementPolicy.
              </div></li><li><div>
                Good point. Updating.
              </div></li><li><div>
                Sure
              </div></li><li><div>
                It doesn't have one before, while I can add some check here.
              </div></li><li><div>
                I can make it smaller.
              </div></li><li><div>
                3 means the default number pipelineNumLimit, which means there is no use-set limit. I should've made this a global reference. 
              </div></li><li><div>
                IDE did this. Fixing
              </div></li><li><div>
                Conf setting is universal way of setting the limit. The current way in MiniOzoneCluster to set the global pipeline limit is rather a convenient method for internal use. 
              </div></li><li><div>
                Sure
              </div></li><li><div>
                IDE did this. Fixing
              </div></li><li><div>
                Correct me if I'm wrong, dn2ObjectMap.computeIfAbsent(dnId, k -&gt; ConcurrentHashMap.newKeySet()) ensures for a dnId we will have a KeySet().

Then the returned value (KeySet) allows line 73 to continue the operation to add pipeline id with a .add(pipeline.getId).

JDK document can be found here: https://docs.oracle.com/javase/8/docs/api/java/util/Map.html#computeIfAbsent-K-java.util.function.Function-
              </div></li><li><div>
                Make sense to me. 
              </div></li><li><div>
                I'm fine with current approach. I'm asking because I see a few other mini ozone cluster based tests require similar settings, adding a wrapper can make this easier. But we can do that as a follow up jira.
              </div></li><li><div>
                Other pipelines like STALE pipelines would possibly turn into OPEN at any time. So here I just deduct out CLOSED pipelines.
              </div></li><li><div>
                Not from test, but it's an exception thrown from stateManager.getPipeline method. So I figured adding some error messages for it because the pipeline creation won't stop here. 
              </div></li><li><div>
                Yea. Line 75 is for when we already one existing keyset. For multi pipeline case, the keyset may be created by previous pipeline allocation and the new one would just be added into the existing keyset.
              </div></li><li><div>
                The document says existing value(keyset) will be returned. So the line 74-75 is not necessary.
 
Returns:
the current (existing or computed) value associated with the specified key,

A good example can be found here: https://stackoverflow.com/a/39268896

              </div></li><li><div>
                I see. Thanks for the tipping. Based on the example here, Shall I update the removePipeline method? I'm making a change and please take a look.
              </div></li></ol></div><div><b>jira_issues:</b> <ol><li><div><div><b>summary:</b> Add ability to SCM for creating multiple pipelines with same datanode
                </div><div><b>description:</b> - Refactor _RatisPipelineProvider.create()_ to be able to create pipelines with datanodes that are not a part of sufficient pipelines
- Define soft and hard upper bounds for pipeline membership
- Create SCMAllocationManager that can be leveraged to get a candidate set of datanodes based on placement policies
- Add the datanodes to internal datastructures

                </div></div></li></ol></div><div><b>jira_issues_comments:</b> <ol><li><div>
                -- 'Define soft and hard upper bounds for pipeline membership'

Assuming it's talking about how many pipelines every datanode can be engaged in, it's defined as node heaviness in #HDDS-1577 as in pipeline placement policy. And the current default hard upper limit is 5. That's said, the max number of pipelines where every datanode can be placed may vary after sufficient field testing.&nbsp;
              </div></li><li><div>
                [~xyao] [~Sammi] [~swagle]

In terms of the 'SCMAllocationManager', do we need to support concurrent pipeline placement? Or we just support concurrent request and use a blocking queue to do sequential allocation?

One major cost for concurrent allocation is that info in datanode (like datanode &lt;-&gt; pipeline mapping) must have locks, which could add complexity to failure handling in pipeline placement since counts + 1 has to happen before ultimate placement success and the fallback process would require the lock again. There is absolutely some solution to it (like count + 1 upon registry and mapping + 1 upon placement success, which makes it only lock count + 1). I'm just having questions on whether it's necessary because usually these larger resource control plane action can be sequential as long as it's reasonably quick.
              </div></li><li><div>
                [~swagle]

One more question, what do you mean by "internal datastructures"? What data structures do you think datanodes (assuming DatanodeDetails) should be part of?
              </div></li><li><div>
                [~timmylicheng] I believe by internal data structures, I meant the _PipelineStateMap_ but I will take a look at the doc/code and get back if any other data structures that need an update.

The only way new pipelines are created should be through the Background pipeline creator job. We should not create any pipelines on client requests, in fact, we should assume pipelines are available to SCM already and no ad-hoc pipelines will be created. If a single thread creates pipelines, no need of blocking queues or synchronization, except the utilization counters used for selecting pipeline need to be Atomic (current its round-robin allocation).  
              </div></li><li><div><div><b>body:</b> I separate&nbsp;SCMAllocationManager to another Jira&nbsp;https://issues.apache.org/jira/browse/HDDS-2116.

I think the current BackgroundCreator has a sync way to create pipeline and we can start from there. As [~swagle]&nbsp;mentioned, we now don't assume many ad-hoc pipeline creation operations, the current sync call from background shall be able to handle this. Once we hit performance bottle neck for pipeline creation, we can invest to have a&nbsp;SCMAllocationManager with self-managed thread model.
                </div><div><b>label:</b> code-design
                </div></div></li><li><div>
                PR&nbsp;[https://github.com/apache/hadoop-ozone/pull/28]&nbsp;is under review.
              </div></li><li><div>
                Thanks [~timmylicheng]&nbsp;for the contribution and all for the reviews. I've merged the PR to feature branch.&nbsp;
              </div></li></ol></div></div></html>